---
phase: 05-run-analytics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/core/src/datasets/run/analytics/types.ts
  - packages/core/src/datasets/run/analytics/aggregate.ts
  - packages/core/src/datasets/run/analytics/compare.ts
  - packages/core/src/datasets/run/analytics/index.ts
  - packages/core/src/datasets/run/index.ts
  - packages/core/src/datasets/index.ts
autonomous: true

must_haves:
  truths:
    - "User can compare two runs and see score deltas per scorer"
    - "Comparison returns hasRegression flag for CI quick check"
    - "Comparison warns when dataset versions differ"
    - "Stats include error rate, pass rate, avg score per scorer"
  artifacts:
    - path: "packages/core/src/datasets/run/analytics/types.ts"
      provides: "ComparisonResult, ScorerComparison, ScorerStats, ItemComparison types"
      exports: ["ComparisonResult", "ScorerComparison", "ScorerStats", "ItemComparison"]
    - path: "packages/core/src/datasets/run/analytics/compare.ts"
      provides: "compareRuns function for explicit pair comparison"
      exports: ["compareRuns"]
    - path: "packages/core/src/datasets/run/analytics/aggregate.ts"
      provides: "Aggregation helpers for stats computation"
      exports: ["computeScorerStats", "isRegression"]
  key_links:
    - from: "packages/core/src/datasets/run/analytics/compare.ts"
      to: "RunsStorage.listResults, ScoresStorage.listScoresByRunId"
      via: "storage.getStore() calls"
      pattern: "getStore\\('runs'\\)|getStore\\('scores'\\)"
    - from: "packages/core/src/datasets/index.ts"
      to: "packages/core/src/datasets/run/analytics/index.ts"
      via: "export * from './run/analytics'"
      pattern: "export.*from.*analytics"
---

<objective>
Implement run comparison and analytics for regression detection.

Purpose: Users need to compare two runs side-by-side with score deltas to detect quality regressions when prompts or models change.

Output: `compareRuns()` function returning nested-by-scorer structure with regression flags, plus aggregation helpers for computing error rate, pass rate, and avg score.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase context (locked decisions)
@.planning/phases/05-run-analytics/05-CONTEXT.md
@.planning/phases/05-run-analytics/05-RESEARCH.md

# Existing types and patterns
@packages/core/src/storage/types.ts (Run, RunResult, ListRunResultsOutput)
@packages/core/src/storage/domains/runs/base.ts (RunsStorage.listResults)
@packages/core/src/storage/domains/scores/base.ts (ScoresStorage.listScoresByRunId)
@packages/core/src/evals/types.ts (ScoreRowData)
@packages/core/src/datasets/run/index.ts (existing runDataset structure)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analytics types</name>
  <files>packages/core/src/datasets/run/analytics/types.ts</files>
  <action>
    Create TypeScript types for comparison and aggregation results.

    From CONTEXT.md decisions:
    - Nested-by-scorer structure for scalability
    - Three metrics per scorer: error rate, pass rate, avg score
    - Regression flags at both levels (top-level hasRegression, per-scorer regressed)

    Types to create:

    1. **ScorerStats** - Per-scorer aggregation
       - errorRate: number (items with errors / total)
       - errorCount: number
       - passRate: number (items >= threshold / items with scores)
       - passCount: number
       - avgScore: number (mean of scores, errors excluded)
       - scoreCount: number
       - totalItems: number

    2. **ScorerComparison** - Per-scorer comparison
       - statsA: ScorerStats
       - statsB: ScorerStats
       - delta: number (avgB - avgA)
       - regressed: boolean (delta below threshold)
       - threshold: number

    3. **ItemComparison** - Per-item detail
       - itemId: string
       - inBothRuns: boolean
       - scoresA: Record<scorerId, number | null>
       - scoresB: Record<scorerId, number | null>

    4. **ComparisonResult** - Top-level return
       - runA: { id: string; datasetVersion: Date }
       - runB: { id: string; datasetVersion: Date }
       - versionMismatch: boolean
       - hasRegression: boolean (any scorer regressed)
       - scorers: Record<string, ScorerComparison>
       - items: ItemComparison[]
       - warnings: string[] (e.g., "Runs have different dataset versions")

    5. **CompareRunsConfig** - Function input
       - runIdA: string
       - runIdB: string
       - thresholds?: Record<scorerId, { value: number; direction?: 'higher-is-better' | 'lower-is-better' }>
  </action>
  <verify>pnpm typecheck (no errors in packages/core)</verify>
  <done>All analytics types exported from types.ts</done>
</task>

<task type="auto">
  <name>Task 2: Create aggregation helpers</name>
  <files>packages/core/src/datasets/run/analytics/aggregate.ts</files>
  <action>
    Create pure functions for computing stats from raw data.

    From CONTEXT.md:
    - Basic stats only: mean score, count (no percentiles)
    - Filter nulls before computing avgScore
    - Track error count separately

    Functions to create:

    1. **computeMean(values: number[]): number**
       - Return 0 for empty array
       - Standard mean calculation

    2. **computeScorerStats(scores: ScoreRowData[], threshold: number): ScorerStats**
       - Filter out null scores for avgScore
       - errorCount = scores where score is null
       - errorRate = errorCount / totalItems
       - passCount = scores >= threshold
       - passRate = passCount / (totalItems - errorCount)
       - avgScore = mean of non-null scores

    3. **isRegression(delta: number, threshold: number, direction: 'higher-is-better' | 'lower-is-better'): boolean**
       - higher-is-better: negative delta is regression (delta < -threshold)
       - lower-is-better: positive delta is regression (delta > threshold)
       - Default direction: 'higher-is-better'

    All functions should be pure (no side effects) and well-typed.
  </action>
  <verify>pnpm typecheck (no errors in packages/core)</verify>
  <done>Aggregation helpers exported from aggregate.ts</done>
</task>

<task type="auto">
  <name>Task 3: Create compareRuns function</name>
  <files>packages/core/src/datasets/run/analytics/compare.ts, packages/core/src/datasets/run/analytics/index.ts, packages/core/src/datasets/run/index.ts, packages/core/src/datasets/index.ts</files>
  <action>
    Implement the main comparison function.

    From CONTEXT.md:
    - Explicit pair comparison: user provides both run IDs
    - When versions differ: warn and proceed, compare only overlapping items
    - Return both item-level diffs AND aggregate summary

    **compare.ts - compareRuns function:**

    ```typescript
    export async function compareRuns(
      storage: MastraCompositeStore,
      config: CompareRunsConfig,
    ): Promise<ComparisonResult>
    ```

    Implementation steps:
    1. Load both runs via RunsStorage.getRunById
    2. Handle edge cases:
       - Either run not found -> throw Error with clear message
       - Empty runs -> return comparison with empty arrays + warning
    3. Load results for both runs via RunsStorage.listResults (perPage: false for all)
    4. Load scores for both runs via ScoresStorage.listScoresByRunId (perPage: false)
    5. Check version mismatch: runA.datasetVersion !== runB.datasetVersion
    6. Find overlapping items by itemId (present in both runs)
    7. Group scores by scorerId and itemId for both runs
    8. For each unique scorer found:
       - Compute ScorerStats for each run using computeScorerStats
       - Compute delta = statsB.avgScore - statsA.avgScore
       - Check regression using isRegression with config.thresholds
       - Build ScorerComparison
    9. Build ItemComparison array for overlapping items
    10. Set hasRegression = any scorer has regressed
    11. Build warnings array (version mismatch, no overlapping items, etc.)
    12. Return ComparisonResult

    **index.ts (analytics):**
    Re-export all types and functions

    **run/index.ts:**
    Add export for analytics: `export * from './analytics'`

    **datasets/index.ts:**
    Ensure analytics are exported (run/index.ts already re-exports)
  </action>
  <verify>pnpm typecheck && pnpm build:core</verify>
  <done>compareRuns function exported and callable, all exports wired</done>
</task>

</tasks>

<verification>
Run these commands to verify the phase is complete:

```bash
# Type check passes
pnpm typecheck

# Core package builds
pnpm build:core

# Verify exports (grep for key exports)
grep -r "compareRuns" packages/core/src/datasets/
grep -r "ComparisonResult" packages/core/src/datasets/
```
</verification>

<success_criteria>
1. Types compile without errors
2. compareRuns function exported from packages/core/src/datasets
3. No storage schema changes (pure computation layer)
4. All CONTEXT.md decisions implemented:
   - Nested-by-scorer structure
   - Three metrics per scorer (error rate, pass rate, avg score)
   - hasRegression flag at top level
   - versionMismatch warning when versions differ
</success_criteria>

<output>
After completion, create `.planning/phases/05-run-analytics/05-01-SUMMARY.md`
</output>
