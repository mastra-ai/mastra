---
phase: 02-execution-core
plan: 04
type: tdd
wave: 3
depends_on: ['02-02', '02-03']
files_modified:
  - packages/core/src/storage/domains/runs/__tests__/runs.test.ts
  - packages/core/src/datasets/run/__tests__/runDataset.test.ts
autonomous: true

must_haves:
  truths:
    - 'RunsInMemory tests validate CRUD lifecycle'
    - 'runDataset tests verify status transitions'
    - 'runDataset tests verify scorer application'
    - 'runDataset tests verify error handling and continue-on-error'
    - 'AbortSignal cancellation tested'
  artifacts:
    - path: 'packages/core/src/storage/domains/runs/__tests__/runs.test.ts'
      provides: 'RunsInMemory test suite'
      contains: 'describe.*RunsInMemory'
    - path: 'packages/core/src/datasets/run/__tests__/runDataset.test.ts'
      provides: 'runDataset integration tests'
      contains: 'describe.*runDataset'
  key_links:
    - from: 'packages/core/src/datasets/run/__tests__/runDataset.test.ts'
      to: 'packages/core/src/datasets/run/index.ts'
      via: 'tests runDataset()'
      pattern: 'runDataset'
---

<objective>
Create test suites validating RunsInMemory storage and runDataset orchestration.

Purpose: Verify run lifecycle, scoring, and error handling work correctly before Phase 3
Output: Test suites for RunsInMemory and runDataset with full coverage
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-execution-core/02-02-SUMMARY.md
@.planning/phases/02-execution-core/02-03-SUMMARY.md

# Reference patterns

@packages/core/src/storage/domains/datasets/**tests**/datasets.test.ts
@packages/core/src/evals/run/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create RunsInMemory test suite</name>
  <files>packages/core/src/storage/domains/runs/__tests__/runs.test.ts</files>
  <action>
Create test suite following DatasetsInMemory test pattern:

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { RunsInMemory } from '../inmemory';

describe('RunsInMemory', () => {
  let storage: RunsInMemory;

  beforeEach(async () => {
    storage = new RunsInMemory();
    await storage.dangerouslyClearAll();
  });

  describe('createRun', () => {
    it('creates run with pending status', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date('2024-01-01'),
        targetType: 'agent',
        targetId: 'agent-1',
        totalItems: 10,
      });

      expect(run.id).toBeDefined();
      expect(run.status).toBe('pending');
      expect(run.succeededCount).toBe(0);
      expect(run.failedCount).toBe(0);
      expect(run.startedAt).toBeNull();
      expect(run.completedAt).toBeNull();
    });

    it('uses provided id if given', async () => {
      const run = await storage.createRun({
        id: 'custom-run-id',
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'workflow',
        targetId: 'wf-1',
        totalItems: 5,
      });

      expect(run.id).toBe('custom-run-id');
    });

    it('stores datasetVersion as Date', async () => {
      const version = new Date('2024-06-15T10:30:00Z');
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: version,
        targetType: 'agent',
        targetId: 'agent-1',
        totalItems: 1,
      });

      expect(run.datasetVersion).toBeInstanceOf(Date);
      expect(run.datasetVersion.getTime()).toBe(version.getTime());
    });
  });

  describe('updateRun', () => {
    it('updates status to running', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'agent-1',
        totalItems: 3,
      });

      const updated = await storage.updateRun({
        id: run.id,
        status: 'running',
        startedAt: new Date(),
      });

      expect(updated.status).toBe('running');
      expect(updated.startedAt).toBeInstanceOf(Date);
    });

    it('updates counts and status to completed', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'agent-1',
        totalItems: 10,
      });

      const updated = await storage.updateRun({
        id: run.id,
        status: 'completed',
        succeededCount: 8,
        failedCount: 2,
        completedAt: new Date(),
      });

      expect(updated.status).toBe('completed');
      expect(updated.succeededCount).toBe(8);
      expect(updated.failedCount).toBe(2);
      expect(updated.completedAt).toBeInstanceOf(Date);
    });

    it('throws for non-existent run', async () => {
      await expect(storage.updateRun({ id: 'non-existent', status: 'running' })).rejects.toThrow('Run not found');
    });
  });

  describe('getRunById', () => {
    it('returns run by id', async () => {
      const created = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'agent-1',
        totalItems: 5,
      });

      const fetched = await storage.getRunById({ id: created.id });
      expect(fetched).not.toBeNull();
      expect(fetched?.id).toBe(created.id);
    });

    it('returns null for non-existent id', async () => {
      const result = await storage.getRunById({ id: 'does-not-exist' });
      expect(result).toBeNull();
    });
  });

  describe('listRuns', () => {
    it('lists all runs', async () => {
      await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });
      await storage.createRun({
        datasetId: 'ds-2',
        datasetVersion: new Date(),
        targetType: 'workflow',
        targetId: 'w1',
        totalItems: 2,
      });

      const result = await storage.listRuns({ pagination: { offset: 0, limit: 10 } });
      expect(result.runs).toHaveLength(2);
      expect(result.pagination.total).toBe(2);
    });

    it('filters by datasetId', async () => {
      await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });
      await storage.createRun({
        datasetId: 'ds-2',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });

      const result = await storage.listRuns({
        datasetId: 'ds-1',
        pagination: { offset: 0, limit: 10 },
      });
      expect(result.runs).toHaveLength(1);
      expect(result.runs[0].datasetId).toBe('ds-1');
    });

    it('sorts by createdAt descending', async () => {
      const run1 = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });
      // Small delay to ensure different timestamps
      await new Promise(r => setTimeout(r, 10));
      const run2 = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });

      const result = await storage.listRuns({ pagination: { offset: 0, limit: 10 } });
      expect(result.runs[0].id).toBe(run2.id); // Most recent first
      expect(result.runs[1].id).toBe(run1.id);
    });

    it('respects pagination', async () => {
      for (let i = 0; i < 5; i++) {
        await storage.createRun({
          datasetId: 'ds-1',
          datasetVersion: new Date(),
          targetType: 'agent',
          targetId: `a${i}`,
          totalItems: 1,
        });
      }

      const page1 = await storage.listRuns({ pagination: { offset: 0, limit: 2 } });
      expect(page1.runs).toHaveLength(2);
      expect(page1.pagination.total).toBe(5);

      const page2 = await storage.listRuns({ pagination: { offset: 2, limit: 2 } });
      expect(page2.runs).toHaveLength(2);
    });
  });

  describe('deleteRun', () => {
    it('deletes run and its results', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 2,
      });

      await storage.addResult({
        runId: run.id,
        itemId: 'item-1',
        itemVersion: new Date(),
        input: { prompt: 'test' },
        output: { response: 'result' },
        expectedOutput: null,
        latency: 100,
        error: null,
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 0,
      });

      await storage.deleteRun({ id: run.id });

      expect(await storage.getRunById({ id: run.id })).toBeNull();
      const results = await storage.listResults({
        runId: run.id,
        pagination: { offset: 0, limit: 10 },
      });
      expect(results.results).toHaveLength(0);
    });
  });

  describe('addResult', () => {
    it('adds result with all fields', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });

      const result = await storage.addResult({
        runId: run.id,
        itemId: 'item-1',
        itemVersion: new Date('2024-01-01'),
        input: { prompt: 'Hello' },
        output: { text: 'Hi there' },
        expectedOutput: { text: 'Hello!' },
        latency: 150.5,
        error: null,
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 0,
      });

      expect(result.id).toBeDefined();
      expect(result.runId).toBe(run.id);
      expect(result.input).toEqual({ prompt: 'Hello' });
      expect(result.output).toEqual({ text: 'Hi there' });
      expect(result.latency).toBe(150.5);
    });

    it('stores error for failed item', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 1,
      });

      const result = await storage.addResult({
        runId: run.id,
        itemId: 'item-1',
        itemVersion: new Date(),
        input: { prompt: 'test' },
        output: null,
        expectedOutput: null,
        latency: 50,
        error: 'Agent timeout',
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 2,
      });

      expect(result.error).toBe('Agent timeout');
      expect(result.output).toBeNull();
      expect(result.retryCount).toBe(2);
    });
  });

  describe('listResults', () => {
    it('lists results for a run', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 2,
      });

      await storage.addResult({
        runId: run.id,
        itemId: 'item-1',
        itemVersion: new Date(),
        input: 'a',
        output: 'b',
        expectedOutput: null,
        latency: 100,
        error: null,
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 0,
      });
      await storage.addResult({
        runId: run.id,
        itemId: 'item-2',
        itemVersion: new Date(),
        input: 'c',
        output: 'd',
        expectedOutput: null,
        latency: 200,
        error: null,
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 0,
      });

      const result = await storage.listResults({
        runId: run.id,
        pagination: { offset: 0, limit: 10 },
      });

      expect(result.results).toHaveLength(2);
      expect(result.pagination.total).toBe(2);
    });

    it('returns empty for non-existent run', async () => {
      const result = await storage.listResults({
        runId: 'non-existent',
        pagination: { offset: 0, limit: 10 },
      });

      expect(result.results).toHaveLength(0);
      expect(result.pagination.total).toBe(0);
    });
  });

  describe('deleteResultsByRunId', () => {
    it('deletes all results for a run', async () => {
      const run = await storage.createRun({
        datasetId: 'ds-1',
        datasetVersion: new Date(),
        targetType: 'agent',
        targetId: 'a1',
        totalItems: 2,
      });

      await storage.addResult({
        runId: run.id,
        itemId: 'item-1',
        itemVersion: new Date(),
        input: 'a',
        output: 'b',
        expectedOutput: null,
        latency: 100,
        error: null,
        startedAt: new Date(),
        completedAt: new Date(),
        retryCount: 0,
      });

      await storage.deleteResultsByRunId({ runId: run.id });

      const result = await storage.listResults({
        runId: run.id,
        pagination: { offset: 0, limit: 10 },
      });
      expect(result.results).toHaveLength(0);
    });
  });
});
```

  </action>
  <verify>cd packages/core && pnpm test -- runs.test.ts --run</verify>
  <done>RunsInMemory tests pass covering full CRUD lifecycle</done>
</task>

<task type="auto">
  <name>Task 2: Create runDataset integration tests</name>
  <files>packages/core/src/datasets/run/__tests__/runDataset.test.ts</files>
  <action>
Create integration tests for runDataset function:

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest';
import { Mastra } from '../../../mastra';
import { DatasetsInMemory } from '../../../storage/domains/datasets/inmemory';
import { RunsInMemory } from '../../../storage/domains/runs/inmemory';
import { runDataset } from '../index';
import type { MastraScorer } from '../../../evals/base';

// Mock agent that returns predictable output
const createMockAgent = (response: string, shouldFail = false) => ({
  id: 'test-agent',
  name: 'Test Agent',
  getModel: vi.fn().mockResolvedValue({ type: 'mock' }),
  generate: vi.fn().mockImplementation(async () => {
    if (shouldFail) {
      throw new Error('Agent error');
    }
    return { text: response };
  }),
});

// Mock scorer that returns score based on output
const createMockScorer = (scorerId: string, scorerName: string): MastraScorer<any, any, any, any> => ({
  id: scorerId,
  name: scorerName,
  description: 'Mock scorer',
  run: vi.fn().mockImplementation(async ({ output }) => ({
    score: output ? 1.0 : 0.0,
    reason: output ? 'Has output' : 'No output',
  })),
});

describe('runDataset', () => {
  let mastra: Mastra;
  let datasetsStorage: DatasetsInMemory;
  let runsStorage: RunsInMemory;

  beforeEach(async () => {
    datasetsStorage = new DatasetsInMemory();
    runsStorage = new RunsInMemory();
    await datasetsStorage.dangerouslyClearAll();
    await runsStorage.dangerouslyClearAll();

    // Create test dataset with items
    const dataset = await datasetsStorage.createDataset({
      name: 'Test Dataset',
      description: 'For testing',
    });

    await datasetsStorage.addItem({
      datasetId: dataset.id,
      input: { prompt: 'Hello' },
      expectedOutput: { text: 'Hi' },
    });
    await datasetsStorage.addItem({
      datasetId: dataset.id,
      input: { prompt: 'Goodbye' },
      expectedOutput: { text: 'Bye' },
    });

    // Create Mastra with storage and mock agent
    const mockAgent = createMockAgent('Response');
    mastra = {
      getStorage: () => ({
        stores: {
          datasets: datasetsStorage,
          runs: runsStorage,
        },
      }),
      getAgent: vi.fn().mockReturnValue(mockAgent),
      getAgentById: vi.fn().mockReturnValue(mockAgent),
      getScorerById: vi.fn(),
    } as unknown as Mastra;
  });

  describe('basic execution', () => {
    it('executes all items and returns summary', async () => {
      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'test-agent',
      });

      expect(result.runId).toBeDefined();
      expect(result.status).toBe('completed');
      expect(result.totalItems).toBe(2);
      expect(result.succeededCount).toBe(2);
      expect(result.failedCount).toBe(0);
      expect(result.results).toHaveLength(2);
    });

    it('includes item details in results', async () => {
      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'test-agent',
      });

      const itemResult = result.results[0];
      expect(itemResult.itemId).toBeDefined();
      expect(itemResult.input).toBeDefined();
      expect(itemResult.output).toBeDefined();
      expect(itemResult.latency).toBeGreaterThan(0);
      expect(itemResult.error).toBeNull();
      expect(itemResult.startedAt).toBeInstanceOf(Date);
      expect(itemResult.completedAt).toBeInstanceOf(Date);
    });
  });

  describe('status transitions', () => {
    it('creates run with pending status then transitions to completed', async () => {
      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'test-agent',
      });

      // Verify final status
      expect(result.status).toBe('completed');

      // Verify run was persisted
      const storedRun = await runsStorage.getRunById({ id: result.runId });
      expect(storedRun?.status).toBe('completed');
      expect(storedRun?.succeededCount).toBe(2);
      expect(storedRun?.failedCount).toBe(0);
    });
  });

  describe('error handling', () => {
    it('continues on item error (continue-on-error semantics)', async () => {
      // Create agent that fails on first call, succeeds on second
      let callCount = 0;
      const flakyAgent = {
        id: 'flaky-agent',
        name: 'Flaky Agent',
        getModel: vi.fn().mockResolvedValue({ type: 'mock' }),
        generate: vi.fn().mockImplementation(async () => {
          callCount++;
          if (callCount === 1) {
            throw new Error('First call fails');
          }
          return { text: 'Success' };
        }),
      };

      mastra.getAgent = vi.fn().mockReturnValue(flakyAgent);
      mastra.getAgentById = vi.fn().mockReturnValue(flakyAgent);

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'flaky-agent',
        maxConcurrency: 1, // Sequential to ensure order
      });

      // Run should complete (not fail) with partial success
      expect(result.status).toBe('completed');
      expect(result.succeededCount).toBe(1);
      expect(result.failedCount).toBe(1);

      // Check individual results
      const failedItem = result.results.find(r => r.error !== null);
      const successItem = result.results.find(r => r.error === null);

      expect(failedItem?.error).toBe('First call fails');
      expect(successItem?.output).toEqual({ text: 'Success' });
    });

    it('marks run as failed when all items fail', async () => {
      const failingAgent = createMockAgent('', true);
      mastra.getAgent = vi.fn().mockReturnValue(failingAgent);
      mastra.getAgentById = vi.fn().mockReturnValue(failingAgent);

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'failing-agent',
      });

      expect(result.status).toBe('failed');
      expect(result.succeededCount).toBe(0);
      expect(result.failedCount).toBe(2);
    });

    it('throws for non-existent dataset', async () => {
      await expect(
        runDataset(mastra, {
          datasetId: 'non-existent',
          targetType: 'agent',
          targetId: 'test-agent',
        }),
      ).rejects.toThrow('Dataset not found');
    });

    it('throws for non-existent target', async () => {
      mastra.getAgent = vi.fn().mockReturnValue(null);
      mastra.getAgentById = vi.fn().mockReturnValue(null);

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      await expect(
        runDataset(mastra, {
          datasetId,
          targetType: 'agent',
          targetId: 'missing-agent',
        }),
      ).rejects.toThrow('Target not found');
    });
  });

  describe('scoring', () => {
    it('applies scorers and includes results', async () => {
      const mockScorer = createMockScorer('accuracy', 'Accuracy');

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'test-agent',
        scorers: [mockScorer],
      });

      // Each item should have scores
      expect(result.results[0].scores).toHaveLength(1);
      expect(result.results[0].scores[0].scorerId).toBe('accuracy');
      expect(result.results[0].scores[0].score).toBe(1.0); // Has output
    });

    it('handles scorer errors gracefully', async () => {
      const failingScorer: MastraScorer<any, any, any, any> = {
        id: 'failing-scorer',
        name: 'Failing Scorer',
        description: 'Always fails',
        run: vi.fn().mockRejectedValue(new Error('Scorer crashed')),
      };

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      const result = await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'test-agent',
        scorers: [failingScorer],
      });

      // Run should still complete
      expect(result.status).toBe('completed');

      // Scorer error should be captured in score result
      expect(result.results[0].scores[0].error).toBe('Scorer crashed');
      expect(result.results[0].scores[0].score).toBeNull();
    });
  });

  describe('cancellation', () => {
    it('respects AbortSignal', async () => {
      const controller = new AbortController();

      // Abort immediately
      controller.abort();

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      await expect(
        runDataset(mastra, {
          datasetId,
          targetType: 'agent',
          targetId: 'test-agent',
          signal: controller.signal,
        }),
      ).rejects.toThrow('Aborted');
    });
  });

  describe('concurrency', () => {
    it('respects maxConcurrency setting', async () => {
      const callTimestamps: number[] = [];
      const slowAgent = {
        id: 'slow-agent',
        name: 'Slow Agent',
        getModel: vi.fn().mockResolvedValue({ type: 'mock' }),
        generate: vi.fn().mockImplementation(async () => {
          callTimestamps.push(Date.now());
          await new Promise(r => setTimeout(r, 50));
          return { text: 'Done' };
        }),
      };

      mastra.getAgent = vi.fn().mockReturnValue(slowAgent);
      mastra.getAgentById = vi.fn().mockReturnValue(slowAgent);

      const datasets = await datasetsStorage.listDatasets({ pagination: { offset: 0, limit: 1 } });
      const datasetId = datasets.datasets[0].id;

      await runDataset(mastra, {
        datasetId,
        targetType: 'agent',
        targetId: 'slow-agent',
        maxConcurrency: 1, // Sequential
      });

      // With maxConcurrency=1, calls should be sequential
      // Second call should start after first (50ms gap)
      if (callTimestamps.length === 2) {
        const gap = callTimestamps[1] - callTimestamps[0];
        expect(gap).toBeGreaterThanOrEqual(40); // Allow some tolerance
      }
    });
  });
});
```

  </action>
  <verify>cd packages/core && pnpm test -- runDataset.test.ts --run</verify>
  <done>runDataset tests verify status transitions, scoring, error handling, cancellation</done>
</task>

</tasks>

<verification>
1. `cd packages/core && pnpm test -- runs.test.ts --run` passes
2. `cd packages/core && pnpm test -- runDataset.test.ts --run` passes
3. All test cases cover Phase 2 success criteria
</verification>

<success_criteria>

- RunsInMemory tests cover CRUD lifecycle
- runDataset tests verify status transitions (pending -> running -> completed/failed)
- runDataset tests verify scorer application with error isolation
- runDataset tests verify continue-on-error semantics
- AbortSignal cancellation tested
  </success_criteria>

<output>
After completion, create `.planning/phases/02-execution-core/02-04-SUMMARY.md`
</output>
