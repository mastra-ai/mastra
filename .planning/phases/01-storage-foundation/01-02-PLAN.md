---
phase: 01-storage-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - packages/core/src/storage/domains/datasets/inmemory.ts
  - packages/core/src/storage/domains/inmemory-db.ts
  - packages/core/src/storage/domains/datasets/index.ts
  - packages/core/src/storage/domains/index.ts
  - packages/core/src/storage/base.ts
autonomous: true

must_haves:
  truths:
    - "DatasetsInMemory implements all abstract methods from DatasetsStorage"
    - "InMemoryDB has datasets and datasetItems Maps"
    - "Adding/updating/deleting items updates dataset version timestamp"
    - "DatasetsStorage is exported from domains/index.ts"
    - "StorageDomains type includes optional datasets field"
  artifacts:
    - path: "packages/core/src/storage/domains/datasets/inmemory.ts"
      provides: "DatasetsInMemory class"
      exports: ["DatasetsInMemory"]
    - path: "packages/core/src/storage/domains/inmemory-db.ts"
      provides: "datasets and datasetItems Maps"
      contains: "datasets"
    - path: "packages/core/src/storage/domains/index.ts"
      provides: "datasets domain export"
      contains: "datasets"
    - path: "packages/core/src/storage/base.ts"
      provides: "datasets in StorageDomains"
      contains: "DatasetsStorage"
  key_links:
    - from: "packages/core/src/storage/domains/datasets/inmemory.ts"
      to: "packages/core/src/storage/domains/inmemory-db.ts"
      via: "constructor db parameter"
      pattern: "db: InMemoryDB"
    - from: "packages/core/src/storage/base.ts"
      to: "packages/core/src/storage/domains/datasets/base.ts"
      via: "StorageDomains type import"
      pattern: "DatasetsStorage"
---

<objective>
Implement DatasetsInMemory class and register datasets domain in core storage.

Purpose: Provide working in-memory implementation for testing and development, integrate into core storage system.
Output: Working DatasetsInMemory class, updated InMemoryDB, registered in StorageDomains
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-storage-foundation/01-RESEARCH.md
@.planning/phases/01-storage-foundation/01-01-SUMMARY.md

# Patterns to follow
@packages/core/src/storage/domains/scores/inmemory.ts
@packages/core/src/storage/domains/inmemory-db.ts
@packages/core/src/storage/domains/index.ts
@packages/core/src/storage/base.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add datasets Maps to InMemoryDB</name>
  <files>packages/core/src/storage/domains/inmemory-db.ts</files>
  <action>
Add two new Maps to InMemoryDB class for datasets and items:

1. Import Dataset and DatasetItem types at top:
```typescript
import type { Dataset, DatasetItem } from '../types';
```

2. Add Maps inside the class:
```typescript
readonly datasets = new Map<string, Dataset>();
readonly datasetItems = new Map<string, DatasetItem>();
```

3. Add clear calls in the clear() method:
```typescript
this.datasets.clear();
this.datasetItems.clear();
```

Follow existing pattern - Maps are readonly, clear() method clears all.
  </action>
  <verify>
Grep for `readonly datasets` in inmemory-db.ts confirms Map exists.
Grep for `this.datasets.clear()` confirms clear() updated.
  </verify>
  <done>
InMemoryDB has datasets and datasetItems Maps, clear() method clears them.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement DatasetsInMemory class</name>
  <files>
packages/core/src/storage/domains/datasets/inmemory.ts
packages/core/src/storage/domains/datasets/index.ts
  </files>
  <action>
Create **inmemory.ts** following ScoresInMemory pattern:

```typescript
import { calculatePagination, normalizePerPage } from '../../base';
import type {
  Dataset,
  DatasetItem,
  CreateDatasetInput,
  UpdateDatasetInput,
  AddDatasetItemInput,
  UpdateDatasetItemInput,
  ListDatasetsInput,
  ListDatasetsOutput,
  ListDatasetItemsInput,
  ListDatasetItemsOutput,
} from '../../types';
import type { InMemoryDB } from '../inmemory-db';
import { DatasetsStorage } from './base';

export class DatasetsInMemory extends DatasetsStorage {
  private db: InMemoryDB;

  constructor({ db }: { db: InMemoryDB }) {
    super();
    this.db = db;
  }

  async dangerouslyClearAll(): Promise<void> {
    this.db.datasets.clear();
    this.db.datasetItems.clear();
  }

  // Dataset CRUD
  async createDataset(input: CreateDatasetInput): Promise<Dataset> {
    const id = crypto.randomUUID();
    const now = new Date();
    const dataset: Dataset = {
      id,
      name: input.name,
      description: input.description,
      metadata: input.metadata,
      version: now,  // Timestamp-based versioning
      createdAt: now,
      updatedAt: now,
    };
    this.db.datasets.set(id, dataset);
    return dataset;
  }

  async getDatasetById({ id }: { id: string }): Promise<Dataset | null> {
    return this.db.datasets.get(id) ?? null;
  }

  async updateDataset(args: UpdateDatasetInput): Promise<Dataset> {
    const existing = this.db.datasets.get(args.id);
    if (!existing) {
      throw new Error(`Dataset not found: ${args.id}`);
    }
    const updated: Dataset = {
      ...existing,
      name: args.name ?? existing.name,
      description: args.description ?? existing.description,
      metadata: args.metadata ?? existing.metadata,
      updatedAt: new Date(),
    };
    this.db.datasets.set(args.id, updated);
    return updated;
  }

  async deleteDataset({ id }: { id: string }): Promise<void> {
    // Delete all items for this dataset first
    for (const [itemId, item] of this.db.datasetItems) {
      if (item.datasetId === id) {
        this.db.datasetItems.delete(itemId);
      }
    }
    this.db.datasets.delete(id);
  }

  async listDatasets(args: ListDatasetsInput): Promise<ListDatasetsOutput> {
    const datasets = Array.from(this.db.datasets.values());
    // Sort by createdAt descending (newest first)
    datasets.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());

    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? datasets.length : start + perPage;

    return {
      datasets: datasets.slice(start, end),
      pagination: {
        total: datasets.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : datasets.length > end,
      },
    };
  }

  // Item CRUD with auto-versioning (timestamp-based)
  async addItem(args: AddDatasetItemInput): Promise<DatasetItem> {
    const dataset = this.db.datasets.get(args.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }

    // New version timestamp
    const now = new Date();
    this.db.datasets.set(args.datasetId, {
      ...dataset,
      version: now,
      updatedAt: now,
    });

    const id = crypto.randomUUID();
    const item: DatasetItem = {
      id,
      datasetId: args.datasetId,
      version: now,  // Item stores the version timestamp when added
      input: args.input,
      expectedOutput: args.expectedOutput,
      context: args.context,
      createdAt: now,
      updatedAt: now,
    };
    this.db.datasetItems.set(id, item);
    return item;
  }

  async updateItem(args: UpdateDatasetItemInput): Promise<DatasetItem> {
    const existing = this.db.datasetItems.get(args.id);
    if (!existing) {
      throw new Error(`Item not found: ${args.id}`);
    }
    if (existing.datasetId !== args.datasetId) {
      throw new Error(`Item ${args.id} does not belong to dataset ${args.datasetId}`);
    }

    const dataset = this.db.datasets.get(args.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }

    // New version timestamp
    const now = new Date();
    this.db.datasets.set(args.datasetId, {
      ...dataset,
      version: now,
      updatedAt: now,
    });

    const updated: DatasetItem = {
      ...existing,
      version: now,  // Update item's version timestamp
      input: args.input ?? existing.input,
      expectedOutput: args.expectedOutput ?? existing.expectedOutput,
      context: args.context ?? existing.context,
      updatedAt: now,
    };
    this.db.datasetItems.set(args.id, updated);
    return updated;
  }

  async deleteItem({ id, datasetId }: { id: string; datasetId: string }): Promise<void> {
    const existing = this.db.datasetItems.get(id);
    if (!existing) {
      throw new Error(`Item not found: ${id}`);
    }
    if (existing.datasetId !== datasetId) {
      throw new Error(`Item ${id} does not belong to dataset ${datasetId}`);
    }

    const dataset = this.db.datasets.get(datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${datasetId}`);
    }

    // New version timestamp on delete
    const now = new Date();
    this.db.datasets.set(datasetId, {
      ...dataset,
      version: now,
      updatedAt: now,
    });

    this.db.datasetItems.delete(id);
  }

  async getItemById({ id }: { id: string }): Promise<DatasetItem | null> {
    return this.db.datasetItems.get(id) ?? null;
  }

  async listItems(args: ListDatasetItemsInput): Promise<ListDatasetItemsOutput> {
    let items = Array.from(this.db.datasetItems.values()).filter(
      item => item.datasetId === args.datasetId
    );

    // Filter by version if specified (snapshot semantics: items at or before this version timestamp)
    if (args.version !== undefined) {
      const versionTime = args.version.getTime();
      items = items.filter(item => item.version.getTime() <= versionTime);
    }

    // Sort by createdAt descending
    items.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());

    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? items.length : start + perPage;

    return {
      items: items.slice(start, end),
      pagination: {
        total: items.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : items.length > end,
      },
    };
  }

  async getItemsByVersion({ datasetId, version }: { datasetId: string; version: Date }): Promise<DatasetItem[]> {
    // Snapshot semantics: return items that existed at or before this version timestamp
    const versionTime = version.getTime();
    const items = Array.from(this.db.datasetItems.values()).filter(
      item => item.datasetId === datasetId && item.version.getTime() <= versionTime
    );
    items.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());
    return items;
  }
}
```

Update **index.ts** to also export inmemory:
```typescript
export * from './base';
export * from './inmemory';
```
  </action>
  <verify>
File exists: packages/core/src/storage/domains/datasets/inmemory.ts
Grep for `class DatasetsInMemory` confirms implementation exists.
Grep for `version + 1` confirms auto-versioning logic exists.
  </verify>
  <done>
DatasetsInMemory implements all CRUD methods with auto-versioning on item mutations.
  </done>
</task>

<task type="auto">
  <name>Task 3: Register datasets domain in core storage</name>
  <files>
packages/core/src/storage/domains/index.ts
packages/core/src/storage/base.ts
  </files>
  <action>
1. Update **domains/index.ts** to export datasets:
```typescript
export * from './datasets';
```

2. Update **base.ts** to include datasets in StorageDomains type:

Add import at top (with other domain imports):
```typescript
import type { AgentsStorage, ScoresStorage, WorkflowsStorage, MemoryStorage, ObservabilityStorage, DatasetsStorage } from './domains';
```

Update StorageDomains type:
```typescript
export type StorageDomains = {
  workflows: WorkflowsStorage;
  scores: ScoresStorage;
  memory: MemoryStorage;
  observability?: ObservabilityStorage;
  agents?: AgentsStorage;
  datasets?: DatasetsStorage;  // Add as optional
};
```

Update MastraCompositeStore.init() method to initialize datasets:
```typescript
if (this.stores?.datasets) {
  initTasks.push(this.stores.datasets.init());
}
```

Update MastraCompositeStore constructor's composition logic (in the `if (config.default || config.domains)` block):
```typescript
this.stores = {
  memory: domainOverrides.memory ?? defaultStores?.memory,
  workflows: domainOverrides.workflows ?? defaultStores?.workflows,
  scores: domainOverrides.scores ?? defaultStores?.scores,
  observability: domainOverrides.observability ?? defaultStores?.observability,
  agents: domainOverrides.agents ?? defaultStores?.agents,
  datasets: domainOverrides.datasets ?? defaultStores?.datasets,
} as StorageDomains;
```
  </action>
  <verify>
Grep for `datasets` in domains/index.ts confirms export.
Grep for `DatasetsStorage` in base.ts confirms type registration.
Grep for `stores?.datasets` in base.ts confirms init integration.
`pnpm typecheck` from packages/core passes.
  </verify>
  <done>
DatasetsStorage is exported from domains/index.ts.
StorageDomains type includes optional datasets field.
MastraCompositeStore initializes datasets domain when present.
  </done>
</task>

</tasks>

<verification>
1. `pnpm typecheck` from packages/core passes
2. DatasetsInMemory is importable: `import { DatasetsInMemory } from './domains/datasets'`
3. InMemoryDB has datasets and datasetItems Maps
4. StorageDomains type includes datasets?: DatasetsStorage
5. MastraCompositeStore.init() calls datasets.init() when present
</verification>

<success_criteria>
- [ ] InMemoryDB has datasets and datasetItems Maps
- [ ] DatasetsInMemory implements all abstract methods
- [ ] Auto-versioning: addItem, updateItem, deleteItem all increment dataset.version
- [ ] listItems supports optional version filter (snapshot semantics)
- [ ] getItemsByVersion returns items at or before specified version
- [ ] datasets/index.ts exports both base and inmemory
- [ ] domains/index.ts exports datasets
- [ ] StorageDomains type has datasets?: DatasetsStorage
- [ ] MastraCompositeStore.init() initializes datasets
- [ ] Typecheck passes
</success_criteria>

<output>
After completion, create `.planning/phases/01-storage-foundation/01-02-SUMMARY.md`
</output>
