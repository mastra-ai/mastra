# Mastra Memory

Memory in Mastra provides a robust system for storing, retrieving, and utilizing conversation history and contextual information in your AI applications. This documentation will guide you through understanding and effectively implementing memory features.

## What You'll Find Here

- [Overview](./1-overview/index.md) - Understand what memory is and how Mastra handles it
- [Getting Started](./2-getting-started/index.md) - Quick setup instructions to add memory to your agents
- [Using Memory](./3-using-memory/index.md) - Detailed guides on memory features and use cases
- [Memory Threads](./4-memory-threads/index.md) - Working with conversation threads and resources
- [Configuring Memory](./5-configuring-memory/index.md) - Storage options and customization
- [Debugging Memory](./6-debugging-memory/index.md) - Troubleshooting and optimization
- [Examples](./examples/index.md) - Code examples for common memory scenarios

## Why Memory Matters

Effective memory management is crucial for creating agents that can maintain context, recall relevant information, and provide consistent experiences across interactions. Mastra's memory system offers:

- Persistent storage of conversation history
- Semantic search for finding relevant past messages
- Working memory for maintaining continuously relevant information
- Flexible storage backend options
- Optimized context management for different LLM models

Navigate to the [Overview](./1-overview/index.md) to begin learning about Mastra's memory system. 