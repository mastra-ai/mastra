# Last Messages: Turn-Based Interactions

The most fundamental form of memory in Mastra is the ability to maintain conversation context through recent message history. This section covers how Mastra handles turn-based interactions using the "last messages" feature.

## Understanding Last Messages

When agents engage in conversations, they need access to the recent exchanges to maintain context. The "last messages" feature:

- Automatically retrieves the most recent messages from a conversation thread
- Includes these messages in the agent's context window
- Ensures conversational continuity across multiple turns
- Works without any additional configuration

## How Last Messages Work

Each time you call an agent with a `resourceId` and `threadId`:

1. The agent automatically queries memory for recent messages from that thread
2. By default, the 40 most recent messages are retrieved (this number is configurable)
3. These messages are added to the agent's context window
4. The agent can then respond with awareness of the recent conversation

Here's a minimal example of setting up an agent with last messages:

```typescript
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

// Create an agent with memory
const agent = new Agent({
  name: "ConversationAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory(), // Default memory configuration
});
```

When a conversation grows longer than the `lastMessages` setting, older messages will no longer be included in the context window. For example, with the default setting of 40 messages, the 41st oldest message will drop out of the context window when a new message is added.

```text
                   ┌─────────────────────┐
                   │  New User Message   │
                   └─────────┬───────────┘
                             │
                             ▼
                   ┌─────────────────────┐
                   │  Agent with Memory  │
                   └─────────┬───────────┘
                             │ invokes
                             ▼
                ┌────────────────────────────┐
                │    Memory Last Messages    │
                │    Retrieval Function      │
                └────────────┬───────────────┘
                             │ queries
                             ▼
         ┌─────────────────────────────────────┐
         │       Thread Message Storage        │
         │  ───────────────────────────────    │
         │  Message 40 (oldest) - timestamp    │
         │  Message 39        - timestamp      │
         │  ...                                │
         │  Message 2         - timestamp      │
         │  Message 1 (newest) - timestamp     │
         └────────────────────┬────────────────┘
                              │ returns last 40 messages
                              ▼
           ┌───────────────────────────────┐
           │       Context Window          │
           │  ─────────────────────────    │
           │  System Instructions          │
           │  Last 40 Messages             │
           │  Current User Message         │
           └───────────────┬───────────────┘
                           │ sent to
                           ▼
                  ┌──────────────────┐
                  │    LLM Provider  │
                  └──────────────────┘
```

## When to Use Last Messages

Last messages are the foundation of conversational memory and provide essential context for most agent interactions:

- **Conversational Agents** – All chat-based interactions benefit from conversation history
- **Multi-turn Tasks** – When users need to refer to previous messages ("as I mentioned earlier...")
- **Context-Dependent Questions** – When responses depend on previous exchanges
- **Information Collection** – When gathering information across multiple questions

### Configuration Considerations

For most agents, you'll want to keep last messages enabled but might need to adjust the configuration:

- **Extremely Long Conversations** – Reduce the `lastMessages` count to focus on the most recent exchanges
- **Complex Topics** – Increase the `lastMessages` count to provide more detailed context
- **Simple Interactions** – Use a smaller number of messages for straightforward exchanges
- **One-off Processing** – For pure text processing without conversation, you could disable last messages

Even for simple tasks, having a few recent messages often improves the quality and consistency of responses.

## Configuring Last Messages

While the default configuration works well for most use cases, you can adjust how many messages are included in the context window based on your specific needs.

You can customize how many recent messages are included:

```typescript
// Global configuration with agent creation
const agent = new Agent({
  name: "LimitedContextAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory({
    options: {
      lastMessages: 20, // Retrieve 20 most recent messages instead of default 40
    },
  }),
});

// Or per-request configuration
await agent.stream("Hello again", {
  resourceId: "user_123",    // Identifies the user
  threadId: "thread_456",    // Identifies the conversation
  memoryOptions: {
    lastMessages: 10,        
  },
});
```

### Disabling Last Messages

Disabling last messages is rarely recommended for conversational agents, but if you have a specific reason (such as one-off text processing), here's how to do it for a specific request:

```typescript
// Disable last messages for a specific request only
await agent.stream("Summarize this text without conversation context", {
  resourceId: "user_123",
  threadId: "thread_456",
  memoryOptions: {
    lastMessages: false, // No conversation history for this specific request
  },
});
```

When last messages is disabled:
- No conversation history will be included in the context window
- The agent will only see the current message and system instructions
- Messages are still stored in memory for future use

This is primarily useful for stateless operations like summarization or classification tasks where conversation history isn't relevant. For these types of operations, consider creating a separate agent without memory entirely rather than disabling it per request.

## Token Considerations

The more messages you include with the `lastMessages` setting, the more tokens will be consumed. Consider your model's context window limitations when configuring this setting.

**Guidelines for different conversation types:**

| Conversation Type     | Recommended Setting | Reasoning                                   |
|-----------------------|---------------------|---------------------------------------------|
| Simple Q&A            | 5-10 messages       | Short exchanges need minimal context        |
| Customer Service      | 15-20 messages      | Balance between history and token usage     |
| Complex Discussions   | 30-40 messages      | Detailed context helps with complex topics  |

You can also use the [Token Limiter memory processor](../5-configuring-memory/5.2-memory-processors.md) to automatically manage token usage.

## Related Features

Last messages provide the foundation for conversational memory, but Mastra offers additional memory features that can complement or enhance this functionality:

- **[Semantic Recall](./3.2-semantic-recall.md)**: Find relevant messages from anywhere in conversation history, not just recent messages
- **[Working Memory](./3.3-working-memory.md)**: Store persistent user information in a structured format
- **[Token Management](./3.5-token-management.md)**: Optimize token usage across different memory features
- **[Memory Processors](../5-configuring-memory/5.2-memory-processors.md)**: Filter or transform messages before they're sent to the LLM 