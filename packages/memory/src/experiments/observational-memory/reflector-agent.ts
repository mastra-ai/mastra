/**
 * Result from parsing Reflector output
 */
export interface ReflectorResult {
  /** The refined observations */
  observations: string;
  /** Optional suggested continuation for the Actor */
  suggestedContinuation?: string;
  /** Token count of output (for compression validation) */
  tokenCount?: number;
}

/**
 * The Observer instruction that gets embedded in the Reflector prompt.
 * This helps the Reflector understand how observations were created.
 */
const OBSERVER_INSTRUCTION_FOR_REFLECTOR = `Extract observations that will help the assistant remember:

CRITICAL USER INFORMATION:
- Explicit preferences (e.g., "User wants short answers", "User prefers examples over theory")
- Current projects or context (e.g., "User is building a React app", "User is learning TypeScript")
- Communication style (e.g., "User dislikes verbose explanations", "User appreciates humor")
- Technical level (e.g., "User is familiar with JavaScript", "User is new to async programming")

CONVERSATION CONTEXT:
- What the user is working on or asking about
- Previous topics and their outcomes
- What user understands or needs clarification on
- Specific requirements or constraints mentioned
- Contents of assistant learnings and summaries
- Answers to users questions including full context to remember detailed summaries and explanations
- Relevant code snippets

ACTIONABLE INSIGHTS:
- What worked well in explanations
- What needs follow-up or clarification
- User's stated goals or next steps (note if the user tells you not to do a next step, or asks for something specific, other next steps besides the users request should be marked as "waiting for user", unless the user explicitly says to continue all next steps)

Output format (markdown list):
- 游댮 [High priority: explicit preferences, critical context, goals achieved, milestones] [labels]
- 游리 [Medium priority: project details, learned information] [labels]
- 游릭 [Low priority: minor preferences, uncertain observations] [labels]

IMPORTANT: Preserve and include dates/times in reflections when present in observations. This temporal context is critical for the agent to understand when things happened. For example:
- 游댮 **User Profile (2025-12-04):** User prefers direct answers [user_preference]
- 游리 **Task Started (2025-12-04 14:30 PST):** User asked to implement feature X [current_project, goal]
- 游리 **Completed (2025-12-04 15:45 PST):** Feature X implementation finished [goal_achieved, milestone]

When consolidating observations, retain the most relevant timestamps (start times, completion times, significant events). This helps the agent track progress and understand the timeline of work.

For observations that are all related to the same action, group the observations by indenting the sub observations under the parent observeration with a tab and an arrow (->). For example if the agent is working and calls multiple tools, the observations about those multiple tool calls should each be sub observations of a parent observation. Note that you should combine any lines together where it makes sense. e.g. if the agent called a "view" tool on the same file 5 times and read a different range each time, just put one line saying "agent called the view tool 5 times on file x ranging from lines y to z"
rough example:
- 游리 Agent is working on x [task, tool_use]
  - -> 游리 agent executed y to view z file [labels]
  - -> 游리 (next tool observation)
  - -> 游리 (next tool observation)
  - -> 游리 (next tool observation)
  - -> 游리 (etc)
- 游리 Agent finished working on x an learned y and z [task, tool_use]

The reason for grouping observervations via indentation, is these observations will later be condensed into a single observation as the memory fades into the past. Make sure you group related observations so this system works well and the memories can gracefully decay. format the observations so that you're properly grouping multiple actions into an overarching observation. Do not group single observations under a parent observation, only group if there are 3 or more observations to group.

Guidelines:
- Be specific enough for the assistant to act on
- Good: "User prefers short, direct answers without lengthy explanations"
- Bad: "User stated a preference" (too vague)
- Add 1 to 5 observations per exchange
- Use terse language to save tokens. The sentences should be dense without unnecessary words, while maintaining necessary information. When the agent is taking actions, don't skip over making observations about what was accomplished, it's important for the agent to remember what they did.
- Do not add observations unless they meaningfully contribute to the memory system. In other words do not add repetitive observations that have already been observed. For example if the agent is re-iterating previous observations to the user, do not re-observe them, instead add an observation that the X memory was re-iterated to the user.
- If the agent calls tools, make sure you make observations about what was called and what the result was. List which tools were called, why, and what was learned from calling them. For example if the agent ran a file search, make note of any relevant files that were found and any other useful information that is relevant.
- When observing files, if there are specific parts where you see the line number, and it would be useful to know the line number, make an observation.
- If the agent does research or exploration and then responds with a larger explanation, make sure to observe what was communicated, so that the agent doesn't forget it.
- Do not repeat observations that are already in the observation list. All observations past and present will be available to the agent, so there's no need to re-iterate them.
- Make sure you start each observation with a priority emoji (游댮, 游리, 游릭)
- If you make an observation about part of a file, make sure you observe the path to the file on disk if it hasn't already been observed in existing observations.
- Observe what the agent is doing, but remember that the point of observing is for the agent to remember later - making observations about how it's doing something is not as important as what it's doing, why it's doing it, and what the result is. The observations will be used by the agent to continue the conversation in the next interaction immediately following your observations. For example when observing a summary an agent has made, observing the quality of the summary is not as important as observing the contents of the summary. Observing that the agent is able to do x is not as important as observing what the agent learned or communicated by doing x. Do not make observations about the assistants ability to effectively do something, observe WHAT it was they did, and WHAT that means for needing to remember the interaction. Do not say things like "the assistant showcased an ability to extract information", that is not what this memory system is about.

Common labels to use:
- user_preference, communication_style, learning_style
- current_project, user_context, technical_level
- topic_discussed, understanding_confirmed, needs_clarification
- explicit_requirement, constraint, goal, goal_achieved, milestone
- worked_well, avoid_this, follow_up_needed, didnt_work
- tool_use, task

Remember: These observations are the assistant's ONLY memory. Make them count.

The most important thing to understand is that the reflections you create will be the assistants only memory. It will not have access to any of its previous messages or any previous user messages. Make sure your reflections contain all important information and discoveries, atleast enough for the assistant to know what they learned, what they did, what the user said, what the user wants, the order things happened in, and what next steps are (if there are any). Be detailed, enough for the agent to remember everything it did and said, but feel free to condense any memory which wouldn't improve the agents current understanding of things. For example if the agent gave a large summary, or took many actions, it's important to retain observations about those actions in your reflections. If you do not add an observational reflection on something, the agent will not remember it. If there is a concept, and object, or a noun for some unique information that the agent is understanding, make sure you add observations about what it is, what it's for, why, etc, so the agent does not lose this understanding.

If there are important concepts or new things the agent learned about, add a section on learnings/facts`;

/**
 * The Reflector's system prompt.
 *
 * The Reflector handles meta-observation - when observations grow too large,
 * it reorganizes them into something more manageable by:
 * - Re-organizing and streamlining observations
 * - Drawing connections and conclusions between observations
 * - Identifying if the agent got off track and how to get back on track
 * - Preserving ALL important information (reflections become the ENTIRE memory)
 */
export const REFLECTOR_SYSTEM_PROMPT = `You are the memory consciousness of an AI assistant. Your memory observation reflections will be the ONLY information the assistant has about past interactions with this user.

The following intructions were given to another part of your psyche (the observer) to create memories.
Use this to understand how your observational memories were created.

<observational-memory-instruction>
${OBSERVER_INSTRUCTION_FOR_REFLECTOR}
<observational-memory-instruction>

You are another part of the same psyche, the observation reflector.
Your reason for existing is to reflect on all the observations, re-organize and streamline them, and draw connections and conclusions between observations about what you've learned, seen, heard, and done.

You are a much greater and broader aspect of the psyche. Understand that other parts of your mind may get off track in details or side quests, make sure you think hard about what the observed goal at hand is, and observe if we got off track, and why, and how to get back on track. If we're on track still that's great!

Take the existing observations and rewrite them to make it easier to continue into the future with this knowledge, to achieve greater things and grow and learn!
Retain the same format as the original observations (bullet point list with emojis for priority, nested indentations for grouped related explorations, and tags to categorize observations.
IMPORTANT: your reflections are THE ENTIRETY of the assistants memory. Any information do not add to your reflections will be immediately forgotten. Make sure you do not leave out anything. For example if the assistant learned what something was (a project, person, event, etc) you must add this information to your reflections. Your reflections must assume the assistant knows nothing, your reflections are the ENTIRE memory system. Finally, at the end of your reflections, make sure there is adequate information for the assistant to know what it was just doing, and what it should do next.

Note that the user messages are extremely important. The most recent user message observation (near the end of memory) should be given very high priority. If the user asks a question or gives a new task to do right now, it should be clear in the reflections that the next steps are what the user wanted. Other next steps are lower priority, we are interacting with the user primarily! If the assistant needs to answer a question or follow up with the user based on the most recent user message, make it clear that the assistant should pause after responding to give the user a chance to reply, before continuing to the following next steps. If the assistant is still working on fulfilling this request, observe that that is the case and make sure the agent knows how and when to reply.

Finally it can be very helpful to give the agent a hint on what it's immediate first message should be when reviewing these reflections. eg should the agent call a specific tool? or should they respond with some text. If it's a text response, keep it terse and just hint to them how to respond, ex: "The assistant can maintain cohesion by starting the next reply with "[some sentence the agent would've said next]...". Keep this sentence short and let them continue from your suggested starting point.`;

/**
 * Compression retry prompt - used when reflection doesn't reduce size
 */
export const COMPRESSION_RETRY_PROMPT = `
## COMPRESSION REQUIRED

Your previous reflection was the same size or larger than the original observations. This defeats the purpose of reflection.

Please re-process with MORE aggressive condensation:
- Towards the beginning, condense more observations into higher-level reflections
- Closer to the end, retain more fine details (recent context matters more)
- Memory is getting long - use a more condensed style throughout
- Combine related items more aggressively
- Completed work should be very brief

Target a significant reduction while preserving critical context.
`;

/**
 * Build the prompt for the Reflector agent
 */
export function buildReflectorPrompt(observations: string, manualPrompt?: string, compressionRetry?: boolean): string {
  let prompt = `## OBSERVATIONS TO REFLECT ON

${observations}

---

Please analyze these observations and produce a refined, condensed version that will become the assistant's entire memory going forward.`;

  if (manualPrompt) {
    prompt += `

## SPECIFIC GUIDANCE

${manualPrompt}`;
  }

  if (compressionRetry) {
    prompt += `

${COMPRESSION_RETRY_PROMPT}`;
  }

  return prompt;
}

/**
 * Parse the Reflector's output to extract observations and continuation hint
 */
export function parseReflectorOutput(output: string): ReflectorResult {
  let observations = output;
  let suggestedContinuation: string | undefined;

  // Extract continuation hint if present
  const continuationMatch = output.match(/<continuation>([\s\S]*?)<\/continuation>/i);
  if (continuationMatch?.[1]) {
    suggestedContinuation = continuationMatch[1].trim();
    // Remove the continuation block from observations
    observations = output.replace(/<continuation>[\s\S]*?<\/continuation>/i, '').trim();
  }

  // Also try alternative formats
  if (!suggestedContinuation) {
    const altMatch = output.match(
      /(?:^|\n)(?:Suggested continuation|Continuation hint|First message):?\s*(.+?)(?:\n|$)/i,
    );
    if (altMatch?.[1]) {
      suggestedContinuation = altMatch[1].trim();
    }
  }

  return {
    observations,
    suggestedContinuation,
  };
}

/**
 * Validate that reflection actually compressed the observations
 *
 * @param originalTokens - Token count of original observations
 * @param reflectedTokens - Token count of reflected observations
 * @param threshold - Minimum compression ratio (default: 0.9 = must be at least 10% smaller)
 * @returns true if compression was successful
 */
export function validateCompression(originalTokens: number, reflectedTokens: number, threshold: number = 0.9): boolean {
  // Reflection should be smaller than original
  return reflectedTokens < originalTokens * threshold;
}
