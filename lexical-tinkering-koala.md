# Mastra Metrics & Logging Design Discussion

**Status:** Exploratory discussion phase - working through design decisions topic by topic

**Initial inputs:** `mastra-observability-metrics-logging-summary.md` (ChatGPT discussion notes)

**Decisions made:**

- Metric types: Counter, Gauge, Histogram (no UpDownCounter initially)
- Logging: Separate storage with auto-correlation
- For inflight/concurrency: Use started/finished counters pattern instead of UpDownCounter
- Temporality: Delta per interval for storage (normalize cumulative on ingestion)
- Cardinality: Denylist + UUID detection + runtime warnings (see 5.2)
- Storage model: Raw events with tiered retention, CLI-based aggregation
- Storage backends: LibSQL, PostgreSQL, ClickHouse (skip MongoDB/MSSQL initially)
- Future: Consider deprecating LibSQL/PostgreSQL for observability; document better alternatives
- Naming: Prometheus-style internally (`mastra_workflow_runs_total`), convert for OTLP export
- Retention: Per-signal with defaults (traces 14d, metrics raw 7d, aggregated 90d, logs 7d)
- Auto-instrumentation: Automatic when enabled, with override options
- Phasing: All metric types at once, metrics before logging

**Source documents:**

- `mastra-observability-metrics-logging-summary.md` - Overview and use cases
- `mastra-metrics-standards-notes.md` - Metric types, histograms, multi-writer concerns

---

## Current State Understanding

### Existing Observability Architecture

Mastra already has a mature **tracing** system:

**Span Types (18 total):**

- Agent: `AGENT_RUN`
- Model: `MODEL_GENERATION`, `MODEL_STEP`, `MODEL_CHUNK`
- Workflow: `WORKFLOW_RUN`, `WORKFLOW_STEP`, `WORKFLOW_CONDITIONAL`, `WORKFLOW_PARALLEL`, `WORKFLOW_LOOP`, `WORKFLOW_SLEEP`, `WORKFLOW_WAIT_EVENT`
- Tools: `TOOL_CALL`, `MCP_TOOL_CALL`
- Other: `PROCESSOR_RUN`, `GENERIC`

**Key Components:**

- `ObservabilityStorage` - Base class for span persistence (`packages/core/src/storage/domains/observability/`)
- Exporters: `DefaultExporter` (batched to storage), `ConsoleExporter`, `JSONExporter`, `CloudExporter`
- Sampling: ALWAYS, NEVER, RATIO, CUSTOM strategies
- Context propagation via JavaScript Proxies

**Storage Domain Pattern:**

```
packages/core/src/storage/domains/{domain}/
â”œâ”€â”€ base.ts      # Abstract class with interface
â”œâ”€â”€ types.ts     # Zod schemas, request/response types
â”œâ”€â”€ inmemory.ts  # In-memory implementation
â””â”€â”€ index.ts     # Exports

stores/{adapter}/src/storage/domains/{domain}/
â””â”€â”€ index.ts     # Database-specific implementation
```

---

## Design Decisions to Make

### 1. Metrics Storage Model

**Decision: Raw events with tiered retention**

**Industry validation:** Both Langfuse and Braintrust use raw events:

- Langfuse: "events-based architecture" with aggregation at query time
- Braintrust: Built custom DB (Brainstore) for fast queries on raw data
- Both invested in query infrastructure rather than pre-aggregation

**Mastra approach:**

```
Raw events (days) â†’ Aggregated buckets (long-term)
```

| Tier       | Retention           | Data                     | Use Case                  |
| ---------- | ------------------- | ------------------------ | ------------------------- |
| Raw        | Days (configurable) | Individual metric points | Debugging, ad-hoc queries |
| Aggregated | Months/years        | Time-bucketed rollups    | Dashboards, trends        |

**Aggregation strategy:**

- NOT in Mastra server (stateless, serverless-compatible)
- CLI command: `mastra db aggregate-metrics` (similar to trace cleanup work)
- Or storage-side: ClickHouse materialized views, Postgres pg_cron
- Runs periodically to roll up old raw data into buckets

**Client-side batching:**

- Long-lived processes: Batch in memory (1-10 seconds) before flush
- Serverless: Flush on exit (single batch per invocation)
- Aligns with existing tracing exporter batching pattern

**Serverless vs long-lived:**

- Both emit raw metric points
- Both use delta temporality (change since last flush)
- Batching duration differs, but storage sees same format

### 2. Logging Model

**Decision: Separate log storage with auto-correlation (Option B)**

**Conceptual distinction (Traces vs Logs):**

| Signal     | Primary Purpose                      | Primary Author   | Examples                                                          |
| ---------- | ------------------------------------ | ---------------- | ----------------------------------------------------------------- |
| **Traces** | How code runs through Mastra system  | Mastra internals | Agent runs, workflow steps, tool calls, model generations         |
| **Logs**   | How user's business logic is working | User code        | Tool validation messages, workflow decision points, error context |

Neither is exclusive:

- Users can add custom spans for their own instrumentation
- Mastra system can emit logs for internal events

But the mental model: **traces = execution flow, logs = application messages**

**Why separate storage:**

- Logs can exist without active span (startup, background jobs)
- Separate retention policies (logs often shorter than traces)
- Query logs independently without loading full traces
- Matches industry pattern (Grafana LGTM stack, OpenTelemetry signals)

**Log record schema:**

```typescript
interface LogRecord {
  // Core fields (indexed)
  id: string;
  timestamp: Date;
  level: 'debug' | 'info' | 'warn' | 'error' | 'fatal';
  message: string;

  // Auto-correlation (system-populated from context, indexed)
  traceId?: string;
  spanId?: string;
  entityType?: EntityType; // agent, workflow, tool, processor
  entityId?: string;
  entityName?: string;
  userId?: string;
  organizationId?: string;
  resourceId?: string;
  runId?: string;
  sessionId?: string;
  threadId?: string;
  requestId?: string;
  environment?: string;
  source?: string;
  serviceName?: string;

  // User data (single flexible bag, JSONB)
  data?: Record<string, unknown>;
}
```

**Why single `data` bag (not attributes + metadata):**

- Logs are user-generated (from tools, workflow steps)
- No system-defined "log types" with known attributes
- Correlation fields are the "system" part, `data` is all user content
- Simpler mental model

**Auto-correlation behavior:**

- Logger checks current tracing context
- Captures traceId, spanId, runId, threadId, etc. automatically
- User provides message + optional `data`

**Querying:**

- Filter by indexed fields (level, timestamp, traceId, runId, etc.) = fast
- Filter within `data` = JSONB query, flexible but slower

**Retention:** Configurable, independent from trace retention

**Log levels:** `debug | info | warn | error | fatal`

### 3. Metric Types to Support

**Decision: Counter, Gauge, Histogram** (no UpDownCounter initially)

| Type          | Use Case                                    | Multi-writer safe?             |
| ------------- | ------------------------------------------- | ------------------------------ |
| **Counter**   | Totals and rates (requests, errors, tokens) | âœ… Yes - additive              |
| **Gauge**     | Current state (queue depth, memory)         | âŒ No - needs single owner     |
| **Histogram** | Distributions (latency, token counts)       | âœ… Yes - with matching buckets |

**Why skip UpDownCounter?**

- Failure mode: missed `-1` deltas on crash cause drift
- Better pattern: Use `started_total` + `finished_total` counters, derive inflight
- Example: `inflight = mastra_runs_started_total - mastra_runs_finished_total`

### 3.1 Histogram Design (Critical - Most Design Impactful)

Histograms influence storage schema, aggregation, and query semantics.

**Bucket representation:** Explicit boundaries (v1), reserve for exponential later

```
Latency (ms): [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, +Inf]
Tokens: [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, +Inf]
```

**Datapoint payload:**

- `count` - number of observations
- `sum` - sum of all values
- `buckets[]` - count per bucket

**Merge rules (same bucket boundaries):**

- `count = Î£ count`
- `sum = Î£ sum`
- `bucket[i] = Î£ bucket[i]`

**Temporality:** Delta per interval (normalize cumulative on ingestion)

### 3.2 Cardinality Guardrails

**BANNED as labels** (cause cardinality explosion):

- `trace_id`, `span_id`, `run_id`, `request_id`, `user_id`
- Free-form strings

**ALLOWED labels** (small, stable dimensions):

- `workflow`, `agent`, `step`, `tool`, `model`, `status`, `env`, `service`

### 4. Storage Backend Support

**Decision: LibSQL, PostgreSQL, ClickHouse for initial implementation**

| Backend    | Tracing | Metrics/Logging | Notes                                    |
| ---------- | ------- | --------------- | ---------------------------------------- |
| LibSQL     | âœ…      | âœ…              | Local dev, low volume                    |
| PostgreSQL | âœ…      | âœ…              | Mid-size, with performance caveats       |
| ClickHouse | âœ…      | âœ…              | Production recommended, best performance |
| MongoDB    | âœ…      | âŒ Skip         | Not in initial implementation            |
| MSSQL      | âœ…      | âŒ Skip         | Not in initial implementation            |

**PostgreSQL/LibSQL performance caveat:**
Row-based storage is suboptimal for time-series analytics:

- PostgreSQL is ~6x slower than ClickHouse for aggregation queries
- Uses ~20x more disk than ClickHouse
- Acceptable for local dev and low-to-mid volume, but not recommended for production scale

**âš ï¸ Future deprecation consideration:**
PostgreSQL and LibSQL may be deprecated for observability (tracing, metrics, logging) in a future major version. Users requiring production-grade observability should plan to migrate to ClickHouse or a dedicated time-series backend.

Rationale:

- Maintaining multiple storage backends for observability is costly
- Performance gap is significant enough to impact user experience at scale
- ClickHouse provides a better foundation for future features (histograms, aggregations, retention)

### 4.1 Future Storage Backends to Consider

Backends that could be added for observability in future versions:

| Backend              | Type                 | Consideration                                                                  |
| -------------------- | -------------------- | ------------------------------------------------------------------------------ |
| **DuckDB**           | Embedded OLAP        | Could replace LibSQL for local dev; much better analytics performance          |
| **TimescaleDB**      | PostgreSQL extension | Middle ground between Postgres and ClickHouse; requires extension installation |
| **QuestDB**          | Time-series native   | High-performance time-series DB with SQL interface                             |
| **InfluxDB 3.0**     | Time-series native   | Purpose-built for metrics; InfluxQL/SQL support                                |
| **Prometheus/Mimir** | Metrics native       | Native PromQL support; OTLP export path                                        |

**Not recommended for future consideration:**

- MongoDB: Document-oriented, poor time-series performance
- MSSQL: Row-oriented, licensing costs, not optimized for telemetry
- Convex: Not suited for high-volume telemetry ingestion

### 5. Metric Identity & Naming

**Decision: Prometheus-style internally, convert for OTLP export**

**Internal storage format (Prometheus-style):**

```
mastra_{domain}_{metric}_{unit}

Examples:
mastra_workflow_runs_total
mastra_tool_latency_seconds
mastra_model_tokens_total
mastra_agent_generation_duration_seconds
```

**OTLP export format (dot-separated):**

```
mastra.workflow.runs
mastra.tool.latency
mastra.model.tokens
```

Exporter handles the conversion (drop `_total` suffix, convert underscores to dots).

**Metric identity:**

```
name + labels = unique series

Example:
mastra_workflow_runs_total{workflow="support_agent", env="prod", status="completed"}
```

**Naming conventions:**

- Snake_case throughout
- `_total` suffix for counters
- `_seconds` or `_ms` suffix for durations
- `_bytes` suffix for sizes

### 5.1 Label Guidelines

**Required labels:** None by default (all optional)

**Recommended labels (bounded cardinality):**

- `env` - environment (dev/staging/prod)
- `workflow` - workflow name
- `agent` - agent name
- `tool` - tool name
- `model` - model name (gpt-4o, claude-3-opus, etc.)
- `status` - outcome (success/error/timeout)
- `step` - workflow step name
- `error_type` - error category (not full message)

### 5.2 Cardinality Guards

**Decision: Denylist + UUID detection + runtime warnings**

**Layer 1: Blocked label keys (hard reject)**

```typescript
const BLOCKED_LABEL_KEYS = [
  'trace_id',
  'traceId',
  'span_id',
  'spanId',
  'run_id',
  'runId',
  'request_id',
  'requestId',
  'user_id',
  'userId',
  'session_id',
  'sessionId',
  'thread_id',
  'threadId',
  'message',
  'error_message',
  'errorMessage',
];
```

**Layer 2: Value pattern detection (warn)**

```typescript
// UUID pattern
const UUID_PATTERN = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;

// Long hex/digit strings (likely IDs)
const LIKELY_ID_PATTERN = /^[0-9a-f]{16,}$/i;
```

**Layer 3: Runtime cardinality monitoring (warn)**

- Track unique label combinations per metric
- Warn when exceeding threshold (e.g., 1,000 unique series)
- Log warning, don't block (user may have legitimate use case)

**Value length:** Cap at 128 characters (truncate with warning)

### 6. Built-in Metrics Catalog

Metrics Mastra should provide automatically (whether derived from traces or explicitly instrumented):

#### Workflow Metrics

| Metric                             | Type      | Labels                    | Description                     |
| ---------------------------------- | --------- | ------------------------- | ------------------------------- |
| `mastra_workflow_runs_total`       | Counter   | workflow, status, env     | Total workflow executions       |
| `mastra_workflow_duration_seconds` | Histogram | workflow, status, env     | Workflow execution time         |
| `mastra_workflow_steps_executed`   | Histogram | workflow, env             | Distribution of steps per run   |
| `mastra_workflow_errors_total`     | Counter   | workflow, error_type, env | Workflow failures by error type |

#### Agent Metrics

| Metric                           | Type      | Labels                 | Description                    |
| -------------------------------- | --------- | ---------------------- | ------------------------------ |
| `mastra_agent_runs_total`        | Counter   | agent, status, env     | Total agent executions         |
| `mastra_agent_duration_seconds`  | Histogram | agent, env             | Agent execution time           |
| `mastra_agent_generations_total` | Counter   | agent, model           | Model generations per agent    |
| `mastra_agent_steps_executed`    | Histogram | agent, env             | Steps/iterations per agent run |
| `mastra_agent_errors_total`      | Counter   | agent, error_type, env | Agent failures by error type   |

#### Tool Metrics

| Metric                         | Type      | Labels                   | Description                 |
| ------------------------------ | --------- | ------------------------ | --------------------------- |
| `mastra_tool_calls_total`      | Counter   | tool, agent, status, env | Total tool invocations      |
| `mastra_tool_duration_seconds` | Histogram | tool, agent, env         | Tool execution time         |
| `mastra_tool_errors_total`     | Counter   | tool, agent, error_type  | Tool failures by error type |

#### Model/LLM Metrics

| Metric                          | Type      | Labels               | Description           |
| ------------------------------- | --------- | -------------------- | --------------------- |
| `mastra_model_requests_total`   | Counter   | model, agent, status | Total model API calls |
| `mastra_model_duration_seconds` | Histogram | model, agent         | Model response time   |
| `mastra_model_input_tokens`     | Counter   | model, agent, type   | Input tokens by type  |
| `mastra_model_output_tokens`    | Counter   | model, agent, type   | Output tokens by type |

**Token type labels** (matching existing tracing schema):

Input types (`mastra_model_input_tokens{type="..."}`):

- `text` - Regular text tokens
- `cache_read` - Tokens served from cache
- `cache_write` - Tokens written to cache (Anthropic)
- `audio` - Audio input tokens
- `image` - Image input tokens (includes PDFs)

Output types (`mastra_model_output_tokens{type="..."}`):

- `text` - Regular text output
- `reasoning` - Reasoning/thinking tokens (o1, Claude thinking)
- `audio` - Audio output tokens
- `image` - Image output tokens (DALL-E)

**Note:** Cost is calculated at query time from token counts + current pricing, not stored as a metric.

#### Processor Metrics

| Metric                              | Type      | Labels                     | Description                      |
| ----------------------------------- | --------- | -------------------------- | -------------------------------- |
| `mastra_processor_calls_total`      | Counter   | processor, status, env     | Total processor invocations      |
| `mastra_processor_duration_seconds` | Histogram | processor, env             | Processor execution time         |
| `mastra_processor_errors_total`     | Counter   | processor, error_type, env | Processor failures by error type |

#### Aggregate Error Metrics

| Metric                | Type    | Labels                       | Description                    |
| --------------------- | ------- | ---------------------------- | ------------------------------ |
| `mastra_errors_total` | Counter | entity_type, error_type, env | All errors across entity types |

#### Future Consideration: Concurrency Metrics

Deferred from initial implementation. If needed later, use started/finished counter pattern:

- `mastra_workflow_started_total` / `mastra_workflow_finished_total`
- Inflight = started - finished (no UpDownCounter needed)

### 7. Grafana Integration

**Primary use case:** Backup/comparison UI during Mastra UI development.

**Approach:** Extend existing exporters to support all three signals, add Grafana Cloud support.

```typescript
// Existing pattern - exporters handle all signals they support
observability: new Observability({
  configs: {
    default: {
      serviceName: 'mastra',
      exporters: [
        new DefaultExporter(), // traces + metrics + logs â†’ storage
        new CloudExporter(), // traces + metrics + logs â†’ Mastra Cloud
        new GrafanaCloudExporter(), // traces + metrics + logs â†’ Grafana Cloud (future)
      ],
    },
  },
});
```

**Grafana Cloud receives:**

- Traces â†’ Tempo (OTLP)
- Metrics â†’ Mimir (OTLP)
- Logs â†’ Loki (OTLP)

**Note:** Exporter architecture is a separate discussion topic. Key principle: each exporter handles all signals it supports, not one exporter per signal type.

### 7.1 Exporter Architecture (To Be Discussed)

Current exporters need updates to support metrics & logging:

| Exporter             | Traces   | Metrics | Logs   | Notes                 |
| -------------------- | -------- | ------- | ------ | --------------------- |
| DefaultExporter      | âœ… Today | ğŸ†• Add  | ğŸ†• Add | Persists to storage   |
| CloudExporter        | âœ… Today | ğŸ†• Add  | ğŸ†• Add | Sends to Mastra Cloud |
| ConsoleExporter      | âœ… Today | ğŸ†• Add  | ğŸ†• Add | Debug output          |
| JSONExporter         | âœ… Today | ğŸ†• Add  | ğŸ†• Add | File output           |
| GrafanaCloudExporter | ğŸ†• New   | ğŸ†• New  | ğŸ†• New | OTLP to Grafana stack |

This requires designing:

- Common exporter interface for all three signals
- Signal-specific export methods
- Configuration for which signals each exporter handles

### 8. Retention Policies

**Decision: Per-signal retention with sensible defaults**

| Signal               | Default Retention | Notes                      |
| -------------------- | ----------------- | -------------------------- |
| Traces               | 14 days           | Expensive, debugging focus |
| Metrics (raw)        | 7 days            | High volume, debugging     |
| Metrics (aggregated) | 90 days           | Dashboards, compact        |
| Logs                 | 7 days            | Moderate volume            |

**CLI commands:**

```bash
mastra db cleanup-traces --older-than 14d
mastra db cleanup-metrics --older-than 7d
mastra db aggregate-metrics --older-than 3d
mastra db cleanup-logs --older-than 7d
```

**Configuration override:**

```typescript
observability: new Observability({
  retention: {
    traces: '14d',
    metricsRaw: '7d',
    metricsAggregated: '90d',
    logs: '7d',
  },
});
```

### 9. Auto-Instrumentation

**Decision: Automatic when observability is enabled, with override options**

- Enable observability â†’ automatically get traces + metrics + logs
- Built-in metrics from catalog are emitted without additional config
- **Users can always override or opt-out**

**Override options:**

```typescript
observability: new Observability({
  // Opt-out of specific signals
  signals: {
    traces: true, // default: true
    metrics: true, // default: true
    logs: true, // default: true
  },

  // Log level control
  logging: {
    level: 'info', // debug | info | warn | error | fatal
  },

  // Disable specific built-in metrics
  metrics: {
    disabled: ['mastra_model_input_tokens'], // opt-out of specific metrics
  },
});
```

**User-defined metrics/logs:** Always explicit

```typescript
// User must call these explicitly
mastra.metrics.counter('my_custom_metric').add(1);
mastra.logger.info('My custom log message', { data: foo });
```

**Sampling:** Shares config with traces (can be extended per-signal if needed)

```typescript
observability: new Observability({
  sampling: {
    strategy: 'ratio',
    ratio: 0.1, // 10% sampling
  },
});
```

### 10. Implementation Phasing

**Decision: All metric types at once, metrics before logging**

#### Phase 1: Metrics (Counter + Gauge + Histogram)

- Implement all three metric types together
- Storage domain for metrics
- Built-in metrics catalog
- Exporter updates (DefaultExporter, etc.)
- LibSQL, PostgreSQL, ClickHouse support

#### Phase 2: Logging

- Storage domain for logs
- Logger API with auto-correlation
- Exporter updates for logging
- Same backend support as metrics

#### Phase 3: Enhancements

- Grafana Cloud exporter
- CLI aggregation commands
- Advanced retention management
- Additional exporters as needed

---

## Open Questions for Discussion

### âš ï¸ KEY ARCHITECTURAL DECISION: Metrics Source

**Should Mastra have separate metrics, or derive them from traces?**

This is a fundamental decision that affects the entire metrics architecture. Document both options for team discussion:

#### Option A: Separate Metrics Signal (Traditional)

```typescript
// Explicit instrumentation
metrics.counter('mastra_workflow_runs_total').add(1, { workflow: 'foo' });
metrics.histogram('mastra_tool_latency_seconds').record(0.5, { tool: 'bar' });
```

- Separate metrics storage
- Standard metrics patterns (Prometheus/OTel style)
- Works for non-trace scenarios
- More instrumentation code needed
- Duplicate data capture

#### Option B: Derive All Metrics from Traces (Braintrust/Langfuse approach)

```sql
-- Metrics computed at query time from span data
SELECT count(*) as runs_total, avg(duration_ms) as avg_duration
FROM spans WHERE span_type = 'WORKFLOW_RUN'
GROUP BY workflow_name, time_bucket('1 minute', timestamp)
```

- Single source of truth (traces)
- Zero extra instrumentation for system metrics
- Requires good indexing / materialized views for dashboard perf
- Some metrics hard to derive (gauges, custom business metrics)

#### Option C: Hybrid

- Auto-derive system metrics from traces (latency, counts, errors)
- Explicit metrics API for user-defined metrics (gauges, custom counters)
- Best of both worlds, but more complex model

**Industry context:**

- Braintrust/Langfuse: Derive from traces
- Traditional observability (Prometheus): Separate metrics
- OpenTelemetry: Supports both as separate signals

---

### Other Open Questions

~~1. **Storage model**: Raw events vs aggregated vs hybrid?~~ â†’ **Decided: Raw events with tiered retention**
~~2. **Log relationship**: Span events only, or separate storage?~~ â†’ **Decided: Separate storage with auto-correlation**
~~3. **Phasing**: All metric types at once, or start with Counter/Gauge?~~ â†’ **Decided: All types, metrics first**
~~4. **LibSQL support**: Include for local dev, or PostgreSQL minimum?~~ â†’ **Decided: Include LibSQL**
~~5. **Auto-instrumentation**: How much should be automatic vs opt-in?~~ â†’ **Decided: Automatic when enabled**
~~6. **Cardinality guards**: Enforce limits, warn, or trust users?~~ â†’ **Decided: Denylist + detection + warnings**
~~7. **Retention**: Same as traces, or separate retention policies?~~ â†’ **Decided: Per-signal with defaults**
~~8. **Metric naming**: Enforce convention? Required vs optional labels?~~ â†’ **Decided: Prometheus-style, convert for OTLP**
~~9. **Grafana integration**: SQL-based, PromQL translation, OTLP export, or custom plugin?~~ â†’ **Decided: Extend exporters for all signals**
~~10. **Built-in metrics catalog**: Which metrics should Mastra emit automatically?~~ â†’ **Decided: See section 6**

---

## Signal Relationships & Diagnostic Workflows

### The Three Pillars

| Signal      | Purpose                   | Answers                                             |
| ----------- | ------------------------- | --------------------------------------------------- |
| **Metrics** | Aggregate health & trends | "Is something wrong? How bad? Where?"               |
| **Logs**    | Specific events & context | "What happened? What was the input/output?"         |
| **Traces**  | Causal structure & timing | "How did it flow? What was slow? What called what?" |

### Correlation

**Traces â†” Logs:** Direct correlation via IDs

- Logs have `traceId`, `spanId`, `runId`, `threadId`, `sessionId`
- Click a log entry â†’ jump to the exact trace/span
- Expand a trace span â†’ see attached logs

**Metrics â†” Traces/Logs:** Correlation via shared dimensions

- Metrics have labels like `agent`, `tool`, `workflow`, `model`, `env`
- No trace/span IDs on metrics (cardinality constraint)
- Navigate by filtering: "Show traces where agent=X and tool=Y"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  METRICS (aggregated)                                       â”‚
â”‚  â””â”€â”€ Labels: agent="support", tool="search", env="prod"     â”‚
â”‚      â””â”€â”€ Filter traces/logs by these dimensions             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LOGS (per-event)                                           â”‚
â”‚  â””â”€â”€ traceId, spanId, runId + agent, tool, etc.             â”‚
â”‚      â””â”€â”€ Click to navigate to trace                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TRACES (structured)                                        â”‚
â”‚  â””â”€â”€ traceId, spanId hierarchy                              â”‚
â”‚      â””â”€â”€ Expand spans to see logs                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Correlation fields by signal:**

| Field      | Metrics    | Logs | Traces         |
| ---------- | ---------- | ---- | -------------- |
| `traceId`  | âŒ         | âœ…   | âœ…             |
| `spanId`   | âŒ         | âœ…   | âœ…             |
| `runId`    | âŒ         | âœ…   | âœ…             |
| `agent`    | âœ… (label) | âœ…   | âœ… (attribute) |
| `tool`     | âœ… (label) | âœ…   | âœ… (attribute) |
| `workflow` | âœ… (label) | âœ…   | âœ… (attribute) |
| `model`    | âœ… (label) | âœ…   | âœ… (attribute) |
| `env`      | âœ… (label) | âœ…   | âœ… (attribute) |

### Diagnostic Workflows

**Workflow 1: Metrics â†’ Logs â†’ Traces** (Top-down)

1. **Metrics**: Dashboard shows error spike or latency increase
   - "Error rate jumped 20% at 2pm"
   - "p95 latency increased from 500ms to 2s"
2. **Logs**: Filter by time range, find specific errors
   - "Tool 'web_search' failed with timeout"
   - "Input was: {query: '...'}"
3. **Traces**: Click through to full execution trace
   - See exact sequence of calls
   - Identify which step was slow
   - See parent/child relationships

**Workflow 2: Traces â†’ Logs â†’ Metrics** (Bottom-up)

1. **Traces**: User reports slow response, look up specific trace
   - See workflow took 8 seconds
   - Model call took 6 seconds (the culprit)
2. **Logs**: Check logs attached to that span
   - "Large context: 15000 tokens"
   - "Model: gpt-4o-mini"
3. **Metrics**: Check if this is a pattern
   - "Token counts have been high all day"
   - "This model's latency trending up"

**Workflow 3: Cross-signal investigation**

```
Question: "Why are my agent runs slow today?"

1. Metrics (mastra_agent_duration_seconds)
   â†’ Histogram shows p95 went from 2s to 8s
   â†’ Breakdown by agent shows "support_agent" is the problem

2. Metrics (mastra_model_duration_seconds{agent="support_agent"})
   â†’ Model latency is normal
   â†’ Not the model's fault

3. Metrics (mastra_tool_duration_seconds{agent="support_agent"})
   â†’ Tool "database_query" latency spiked
   â†’ Found the root cause

4. Logs (filter: agent="support_agent", tool="database_query")
   â†’ "Query took 5.2s: SELECT * FROM large_table..."
   â†’ Missing index identified

5. Traces (for specific slow request)
   â†’ Full execution shows the query was called 3 times
   â†’ Optimization opportunity
```

### UI Navigation

The observability UI should enable seamless navigation:

| From             | To           | Via                                        |
| ---------------- | ------------ | ------------------------------------------ |
| Metric dashboard | Logs         | Time range + filters (agent, tool, status) |
| Metric dashboard | Traces       | Click "View traces" for time range         |
| Log entry        | Trace        | Click traceId link                         |
| Log entry        | Related logs | Filter by runId/threadId                   |
| Trace span       | Logs         | Expand span to see attached logs           |
| Trace span       | Metrics      | Link to metrics for that span type         |

---

## Proposed Architecture (Revised)

**Principle:** Types in `@mastra/core`, instrumentation in `observability/mastra/`, storage domains in `packages/core/`.

### Types (@mastra/core)

```
packages/core/src/observability/types/
â”œâ”€â”€ index.ts
â”œâ”€â”€ tracing.ts      # Span types, attributes (existing)
â”œâ”€â”€ metrics.ts      # Counter, Gauge, Histogram types (new)
â””â”€â”€ logging.ts      # LogRecord, LogLevel types (new)
```

### Instrumentation (observability/mastra)

```
observability/mastra/src/
â”œâ”€â”€ index.ts              # Main exports
â”œâ”€â”€ config.ts             # Config (existing)
â”œâ”€â”€ registry.ts           # Registry (existing)
â”œâ”€â”€ usage.ts              # Usage tracking (existing)
â”œâ”€â”€ model-tracing.ts      # Model tracing (existing)
â”‚
â”œâ”€â”€ exporters/            # All signal exporters (existing + extended)
â”‚   â”œâ”€â”€ base.ts           # Base exporter class
â”‚   â”œâ”€â”€ default.ts        # Storage exporter (traces + metrics + logs)
â”‚   â”œâ”€â”€ cloud.ts          # Mastra Cloud exporter
â”‚   â”œâ”€â”€ console.ts        # Console exporter
â”‚   â”œâ”€â”€ json.ts           # JSON file exporter
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ spans/                # Tracing (existing)
â”‚   â”œâ”€â”€ base.ts
â”‚   â”œâ”€â”€ default.ts
â”‚   â””â”€â”€ no-op.ts
â”‚
â”œâ”€â”€ span_processors/      # Span processors (existing)
â”‚   â””â”€â”€ sensitive-data-filter.ts
â”‚
â”œâ”€â”€ metrics/              # Metrics instrumentation (new)
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ registry.ts       # MetricRegistry - manages all metrics
â”‚   â””â”€â”€ instruments/
â”‚       â”œâ”€â”€ counter.ts
â”‚       â”œâ”€â”€ gauge.ts
â”‚       â””â”€â”€ histogram.ts
â”‚
â””â”€â”€ logging/              # Logging API (new)
    â”œâ”€â”€ index.ts
    â””â”€â”€ logger.ts         # Logger class with auto-correlation

packages/core/src/storage/domains/
â”œâ”€â”€ observability/        # Trace storage (existing)
â”‚   â”œâ”€â”€ base.ts
â”‚   â”œâ”€â”€ types.ts
â”‚   â””â”€â”€ inmemory.ts
â”‚
â”œâ”€â”€ metrics/              # Metrics storage (new)
â”‚   â”œâ”€â”€ base.ts           # MetricsStorage abstract class
â”‚   â”œâ”€â”€ types.ts          # MetricPoint, aggregation types
â”‚   â””â”€â”€ inmemory.ts
â”‚
â””â”€â”€ logs/                 # Log storage (new)
    â”œâ”€â”€ base.ts           # LogsStorage abstract class
    â”œâ”€â”€ types.ts          # LogRecord storage types
    â””â”€â”€ inmemory.ts

stores/{adapter}/src/storage/domains/
â”œâ”€â”€ metrics/              # Per-backend metrics implementation
â”‚   â””â”€â”€ index.ts
â””â”€â”€ logs/                 # Per-backend logs implementation
    â””â”€â”€ index.ts
```

**Key points:**

- Types live in `@mastra/core` (`packages/core/src/observability/types/`)
- Instrumentation/API lives in `observability/mastra/` (tracing, metrics, logging)
- Storage domain base classes stay in `packages/core/src/storage/domains/`
- Backend implementations in `stores/{adapter}/` follow existing pattern
- Other observability packages will also export logging & metrics

### Other Observability Packages

Each package in `observability/` will need metrics & logging support:

```
observability/
â”œâ”€â”€ mastra/         # Core instrumentation (primary)
â”œâ”€â”€ langfuse/       # â†’ add metrics/logs export to Langfuse
â”œâ”€â”€ braintrust/     # â†’ add metrics/logs export to Braintrust
â”œâ”€â”€ datadog/        # â†’ add metrics/logs export to Datadog
â”œâ”€â”€ arize/          # â†’ add metrics/logs export to Arize
â”œâ”€â”€ laminar/        # â†’ add metrics/logs export to Laminar
â”œâ”€â”€ langsmith/      # â†’ add metrics/logs export to LangSmith
â”œâ”€â”€ posthog/        # â†’ add metrics/logs export to PostHog
â”œâ”€â”€ sentry/         # â†’ add metrics/logs export to Sentry
â”œâ”€â”€ otel-bridge/    # â†’ OTLP export for metrics/logs
â””â”€â”€ otel-exporter/  # â†’ OTLP export for metrics/logs
```

---

## Next Steps

1. âœ… Design decisions documented (this plan)
2. Write formal design docs for Notion (Metrics, Logging, Tracing)
3. Define type schemas in `@mastra/core`
4. Implement storage domain base classes + in-memory
5. Add LibSQL, PostgreSQL, ClickHouse implementations
6. Implement metrics instrumentation in `observability/mastra`
7. Implement logging API in `observability/mastra`
8. Extend existing exporters to handle metrics/logs
9. Add auto-instrumentation to existing tracing points
10. Update other observability packages
11. Documentation

---

## References

- ChatGPT summary: `mastra-observability-metrics-logging-summary.md`
- Notion docs format: `.claude/docs/notion-document-formats.md`
- Existing observability: `packages/core/src/storage/domains/observability/`
- MastraAdmin design (has ClickHouse observability): Notion
