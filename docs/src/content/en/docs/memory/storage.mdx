---
title: "Storage | Memory"
description: Configure storage for Mastra's memory system to persist conversations, workflows, and traces.
packages:
  - "@mastra/core"
  - "@mastra/libsql"
  - "@mastra/memory"
  - "@mastra/pg"
  - "@mastra/pinecone"
---

# Storage

For Mastra to remember previous interactions, you must configure a storage adapter. Mastra is designed to work with your preferred database provider - choose from the [supported providers](#supported-providers) and pass it to your Mastra instance.


```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { LibSQLStore } from "@mastra/libsql";

export const mastra = new Mastra({
  storage: new LibSQLStore({
    id: 'mastra-storage',
    url: "file:./mastra.db",
  }),
});
```
On first interaction, Mastra automatically creates the necessary tables following the [core schema](/reference/storage/overview#core-schema). This includes tables for messages, threads, resources, workflows, traces, and evaluation datasets.

## Supported providers

Each provider page includes installation instructions, configuration parameters, and usage examples:

- [libSQL Storage](/reference/storage/libsql)
- [PostgreSQL Storage](/reference/storage/postgresql)
- [MongoDB Storage](/reference/storage/mongodb)
- [Upstash Storage](/reference/storage/upstash)
- [Redis Storage](/reference/v1/storage/redis)
- [Cloudflare D1](/reference/storage/cloudflare-d1)
- [Cloudflare Durable Objects](/reference/storage/cloudflare)
- [Convex](/reference/storage/convex)
- [DynamoDB](/reference/storage/dynamodb)
- [LanceDB](/reference/storage/lance)
- [Microsoft SQL Server](/reference/storage/mssql)

:::tip
libSQL is the easiest way to get started because it doesn’t require running a separate database server
:::

## Configuration scope

You can configure storage at two different scopes:

### Instance-level storage

Add storage to your Mastra instance so all agents, workflows, observability traces and scores share the same memory provider:

```typescript
import { Mastra } from "@mastra/core";
import { PostgresStore } from "@mastra/pg";

export const mastra = new Mastra({
  storage: new PostgresStore({
    id: 'mastra-storage',
    connectionString: process.env.DATABASE_URL,
  }),
});

// All agents automatically use this storage
const agent1 = new Agent({ id: "agent-1", memory: new Memory() });
const agent2 = new Agent({ id: "agent-2", memory: new Memory() });
```

This is useful when all primitives share the same storage backend and have similar performance, scaling, and operational requirements.

#### Composite storage

Add storage to your Mastra instance using `MastraCompositeStore` and configure individual storage domains to use different storage providers.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { MastraCompositeStore } from "@mastra/core/storage";
import { MemoryLibSQL } from "@mastra/libsql";
import { WorkflowsPG } from "@mastra/pg";
import { ObservabilityStorageClickhouse } from "@mastra/clickhouse";

export const mastra = new Mastra({
  storage: new MastraCompositeStore({
    id: "composite",
    domains: {
      memory: new MemoryLibSQL({ url: "file:./memory.db" }),
      workflows: new WorkflowsPG({ connectionString: process.env.DATABASE_URL }),
      observability: new ObservabilityStorageClickhouse({
        url: process.env.CLICKHOUSE_URL,
        username: process.env.CLICKHOUSE_USERNAME,
        password: process.env.CLICKHOUSE_PASSWORD,
      }),
    },
  }),
});
```

This is useful when different types of data have different performance or operational requirements, such as low-latency storage for memory, durable storage for workflows, and high-throughput storage for observability.

:::info
See [Storage Domains](/reference/storage/composite#storage-domains) for more information.
:::

### Agent-level storage

Agent-level storage overrides storage configured at the instance-level. Add storage to a specific agent when you need data boundaries or compliance requirements:

```typescript title="src/mastra/agents/memory-agent.ts"
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { PostgresStore } from "@mastra/pg";

export const agent = new Agent({
  id: "agent",
  memory: new Memory({
    storage: new PostgresStore({
      id: 'agent-storage',
      connectionString: process.env.AGENT_DATABASE_URL,
    }),
  }),
});
```

This is useful when different agents need to store data in separate databases for security, compliance, or organizational reasons.

:::warning[Mastra Cloud Store limitation]
Agent-level storage is not supported when using [Mastra Cloud Store](/docs/mastra-cloud/deployment#using-mastra-cloud-store). If you use Mastra Cloud Store, configure storage on the Mastra instance instead. This limitation does not apply if you bring your own database.
:::

## Threads and resources

Mastra organizes memory into threads using two identifiers:

- **Thread**: A conversation session containing a sequence of messages (e.g., `convo_123`)
- **Resource**: An identifier for the entity the thread belongs to, typically a user (e.g., `user_123`)

Both identifiers are required for agents to store and recall information:

```typescript
const stream = await agent.stream("message for agent", {
  memory: {
    thread: "convo_123",
    resource: "user_123",
  },
});
```

:::note
[Studio](/docs/getting-started/studio) automatically generates a thread and resource ID for you. Remember to  to pass these explicitly when calling `stream` or `generate` yourself.
:::

### Thread and resource relationship

Each thread has an owner (its `resourceId`) that is set when the thread is created and cannot be changed. When you query a thread, you must use the correct owner's resource ID. Attempting to query a thread with a different resource ID will result in an error:

```text
Thread with id <thread_id> is for resource with id <resource_a>
but resource <resource_b> was queried
```

Note that while each thread has one owner, messages within that thread can have different `resourceId` values. This is used for message attribution and filtering (e.g., distinguishing between different agents in a multi-agent system, or filtering messages for analytics).

**Security:** Memory is a storage layer, not an authorization layer. Your application must implement access control before calling memory APIs. The `resourceId` parameter controls both validation and filtering - provide it to validate ownership and filter messages, or omit it for server-side access without validation.

To avoid accidentally reusing thread IDs across different owners, use UUIDs: `crypto.randomUUID()`

### Thread title generation

Mastra can automatically generate descriptive thread titles based on the user's first message.

Use this option when implementing a ChatGPT-style chat interface to render a title alongside each thread in the conversation list (for example, in a sidebar) derived from the thread’s initial user message.

```typescript
export const testAgent = new Agent({
  id: "test-agent",
  memory: new Memory({
    options: {
      generateTitle: true,
    },
  }),
});
```

Title generation runs asynchronously after the agent responds and does not affect response time.

To optimize cost or behavior, provide a smaller `model` and custom `instructions`:

```typescript
export const testAgent = new Agent({
  id: "test-agent",
  memory: new Memory({
    options: {
      generateTitle: {
        model: "openai/gpt-4o-mini",
        instructions: "Generate a concise title based on the user's first message",
      },
    },
  }),
});
```

## Semantic recall

Semantic recall uses vector embeddings to retrieve relevant past messages based on meaning rather than recency. This requires a vector database instance, which can be configured at the instance or agent level.

The vector database doesn't have to be the same as your storage provider. For example, you might use PostgreSQL for storage and Pinecone for vectors:

```typescript
import { Mastra } from "@mastra/core";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { PostgresStore } from "@mastra/pg";
import { PineconeVector } from "@mastra/pinecone";

// Instance-level vector configuration
export const mastra = new Mastra({
  storage: new PostgresStore({
    id: 'mastra-storage',
    connectionString: process.env.DATABASE_URL,
  }),
});

// Agent-level vector configuration
export const agent = new Agent({
  id: "agent",
  memory: new Memory({
    vector: new PineconeVector({
      id: 'agent-vector',
      apiKey: process.env.PINECONE_API_KEY,
    }),
    options: {
      semanticRecall: {
        topK: 5,
        messageRange: 2,
      },
    },
  }),
});
```

We support all popular vector providers including [Pinecone](/reference/vectors/pinecone), [Chroma](/reference/vectors/chroma), [Qdrant](/reference/vectors/qdrant), and many more.

For more information on configuring semantic recall, see the [Semantic Recall](./semantic-recall) documentation.

## Handling large attachments

Some storage providers enforce record size limits that can be exceeded when storing messages with base64-encoded attachments (such as images). When an attachment is embedded directly in the message content, the total record size may exceed the provider's limit.

### Affected providers

| Provider | Record size limit |
| -------- | ----------------- |
| [DynamoDB](/reference/storage/dynamodb) | 400 KB |
| [Convex](/reference/storage/convex) | 1 MiB |
| [Cloudflare D1](/reference/storage/cloudflare-d1) | 1 MiB |

Other providers like PostgreSQL, MongoDB, and libSQL have significantly higher limits and are generally not affected.

### Solution: Upload attachments to external storage

The recommended approach is to use an input processor that uploads large attachments to external storage and replaces them with URL references before the message is persisted. This works with any file storage service—S3, Cloudflare R2, Google Cloud Storage, [Convex file storage](https://docs.convex.dev/file-storage), or your own server.

```typescript title="src/mastra/processors/attachment-uploader.ts"
import type { Processor } from "@mastra/core/processors";
import type { MastraDBMessage } from "@mastra/core/memory";

export class AttachmentUploader implements Processor {
  id = "attachment-uploader";

  async processInput({ messages }: { messages: MastraDBMessage[] }) {
    return Promise.all(messages.map((msg) => this.processMessage(msg)));
  }

  async processMessage(msg: MastraDBMessage) {
    const attachments = msg.content.experimental_attachments;
    if (!attachments?.length) return msg;

    const uploaded = await Promise.all(
      attachments.map(async (att) => {
        // Skip if already a URL
        if (!att.url?.startsWith("data:")) return att;

        // Upload base64 data and replace with URL
        const url = await this.upload(att.url, att.contentType);
        return { ...att, url };
      })
    );

    return { ...msg, content: { ...msg.content, experimental_attachments: uploaded } };
  }

  async upload(dataUri: string, contentType?: string): Promise<string> {
    const base64 = dataUri.split(",")[1];
    const buffer = Buffer.from(base64, "base64");

    // Replace with your storage provider (S3, R2, GCS, Convex, etc.)
    // return await s3.upload(buffer, contentType);
    throw new Error("Implement upload() with your storage provider");
  }
}
```

Use the processor with your agent:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { AttachmentUploader } from "./processors/attachment-uploader";

const agent = new Agent({
  id: "my-agent",
  memory: new Memory({ storage: yourStorage }),
  inputProcessors: [new AttachmentUploader()],
});
```
