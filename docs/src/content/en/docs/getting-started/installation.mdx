---
title: "Installing Mastra | Getting Started | Mastra Docs"
description: Guide on installing Mastra and setting up the necessary prerequisites for running it with various LLM providers.
---

import { Callout, Steps } from "nextra/components";
import { Tabs, Tab } from "@/components/tabs";

# Automatic Install

You can create a new Mastra project using our CLI in one of two modes: **interactive** or **non-interactive**. We recommend starting with the interactive setup.

<Steps>

## Create a New Project

<Tabs items={["Interactive", "Non Interactive"]}>

  <Tab>

    Run the following command to start the interactive setup:

    {/*
    LLM CONTEXT: This Tabs component shows different package manager commands for creating a new Mastra project.
    Each tab displays the equivalent command for that specific package manager (npx, npm, yarn, pnpm, bun).
    This helps users choose their preferred package manager while following the same installation process.
    All commands achieve the same result - creating a new Mastra project with the interactive setup.
    */}

    <Tabs items={["npx", "npm", "yarn", "pnpm", "bun"]}>
      <Tab>
        ```bash copy
        npx create-mastra@latest
        ```
      </Tab>
      <Tab>
        ```bash copy
        npm create mastra@latest
        ```
      </Tab>
      <Tab>
        ```bash copy
        yarn create mastra@latest
        ```
      </Tab>
      <Tab>
        ```bash copy
        pnpm create mastra@latest
        ```
      </Tab>
      <Tab>
        ```bash copy
        bun create mastra@latest
        ```
      </Tab>
    </Tabs>

  </Tab>

  <Tab>

    You can run the Mastra CLI in fully non-interactive mode by passing all required flags, for example:

    ```bash copy
    npx create-mastra@latest --project-name hello-mastra --example --components tools,agents,workflows --llm openai
    ```

    > See the [create-mastra](/reference/cli/create-mastra) documentation for a full list of available CLI options.

  </Tab>
</Tabs>

Once your project is created, it will include:

1. A new Mastra project set up with TypeScript
2. Installed dependencies
3. Your selected components and LLM provider configured
4. The MCP server set up in your IDE (if selected) for instant access to docs, examples, and in-editor help

> If you're using a different IDE, you can install the MCP server manually by following the instructions in the [MCP server docs](/docs/getting-started/mcp-docs-server). **Also** note that there are additional steps for [Cursor and Windsurf](/docs/getting-started/mcp-docs-server#after-configuration) to activate the MCP server.

## Set Up your API Key

Add your API key to the `.env` file:

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

> This example uses OpenAI. Each LLM provider uses a unique name. See [Model Capabilities](docs/getting-started/model-capability) for more information.

## Start the Mastra Server

<Tabs items={["npm", "Mastra CLI"]}>
  <Tab>
    ```bash copy
    npm run dev
    ```
  </Tab>
  <Tab>
    ```bash copy
    mastra dev
    ```
  </Tab>
</Tabs>

This starts the local Mastra server and creates REST API endpoints for your agents, which you can test using the Playground.

- Playground: [http://localhost:4111/](http://localhost:4111/)

> The Mastra dev server also creates the following links:
> - Mastra API: [http://localhost:4111/api](http://localhost:4111/api)
> - OpenAPI Spec: [http://localhost:4111/openapi.json](http://localhost:4111/openapi.json)
> - Swagger UI – API explorer: [http://localhost:4111/swagger-ui](http://localhost:4111/swagger-ui)

## Test the Endpoint

You can test your agent's endpoint using either `curl` or `fetch`:

<Tabs items={['curl', 'fetch', 'command line']}>
  <Tab>
    ```bash copy
    curl -s -X POST http://localhost:4111/api/agents/weatherAgent/generate \
      -H "Content-Type: application/json" \
      -d '{"messages": ["What is the weather in London?"]}' \
      | jq -r '.text'
    ```
  </Tab>
  <Tab>
    ```javascript copy
    async function main() {
      const response = await fetch('http://localhost:4111/api/agents/weatherAgent/generate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: ['What is the weather in London?'],
        }),
      });

      const result = await response.json();
      console.log('Agent response:', result.text);
    }

    main();
    ```
    > This example assumes your application is already set up to load environment variables (e.g. via `dotenv` or built-in support).
  </Tab>
  <Tab>

    Install `dotenv` to load environment variables (e.g. your API keys):

    ```bash copy
    npm install dotenv --save-dev
    ```

    Create a test file that calls the agent:

    ```bash copy
    touch src/test-agent.ts
    ```

    Add the following code:

    ```ts filename="src/test-agent.ts" showLineNumbers copy
    import "dotenv/config";

    import { mastra } from "./mastra";

    async function main() {
      const agent = await mastra.getAgent("weatherAgent");

      const result = await agent.generate("What is the weather in London?");

      console.log("Agent response:", result.text);
    }

    main();
    ```

    Run the script to test the agent:

    ```bash copy
    npx tsx src/test-agent.ts
    ```

  </Tab>
</Tabs>

You should see output similar to the following:

```plaintext
Agent response: The current weather in London is as follows:

- **Temperature:** 12.9°C (Feels like 9.7°C)
- **Humidity:** 63%
- **Wind Speed:** 14.7 km/h
- **Wind Gusts:** 32.4 km/h
- **Conditions:** Overcast

Let me know if you need more information!
```

</Steps>

## Next Steps

- [Mastra Client SDK](/docs/client-js/overview)
- [Deploy to Mastra Cloud](/docs/deployment/overview)
