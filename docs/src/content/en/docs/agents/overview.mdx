---
title: "Agent Overview | Agents | Mastra Docs"
description: Overview of agents in Mastra, detailing their capabilities and how they interact with tools, workflows, and external systems.
---

import { Steps, Tabs } from "nextra/components";

# Using Agents

Agents let you build intelligent assistants powered by language models that can make decisions and perform actions. Each agent has required instructions and an LLM, with optional tools and memory, and they can respond in one step or run in a loop until they achieve a goal.

An agent coordinates conversations, calls tools when needed, maintains context through memory, and produces responses tailored to the interaction. Agents can operate on their own or work as part of larger workflows.

![Agents overview](/image/agents/agents-overview.jpg)

> **ðŸ“¹ Watch**:  â†’ An introduction to agents, and how they compare to workflows [YouTube (7 minutes)](https://youtu.be/0jg2g3sNvgw)

## Getting started

<Tabs items={["Mastra model routing", "Vercel AI SDK"]}>
  <Tabs.Tab>
    <Steps>
### Install dependencies

Add the Mastra core package to your project:

```bash
npm install @mastra/core
```

### Configure your API key

Mastra's model router automatically detects environment variables that match the provider you choose. For OpenAI models, set `OPENAI_API_KEY`:

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

> Browse [Model Providers](../getting-started/model-providers.mdx) to see all available `provider/model` strings.

### Create an agent

Import the `Agent` class and point the `model` field to the provider/model combination you want to use:

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { Agent } from "@mastra/core/agent";

export const testAgent = new Agent({
  name: "test-agent",
  instructions: "You are a helpful assistant.",
  model: "openai/gpt-4o-mini"
});
```
    </Steps>
  </Tabs.Tab>
  <Tabs.Tab>
    <Steps>
### Install dependencies

Include the Mastra core package alongside the Vercel AI SDK provider you want to use:

```bash
npm install @mastra/core @ai-sdk/openai
```

### Configure your API key

Set the corresponding environment variable for your provider. For OpenAI via the AI SDK:

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

> See the [AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers) in the Vercel AI SDK docs for additional configuration options.

### Create an agent

Import the AI SDK client and provide it to your agent's `model` field:

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";

export const testAgent = new Agent({
  name: "test-agent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o-mini")
});
```
    </Steps>
  </Tabs.Tab>
</Tabs>

### Creating an agent

To create an agent in Mastra, use the `Agent` class. Every agent must include `instructions` to define its behavior, and a `model` parameter to specify the LLM provider and model:

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { Agent } from "@mastra/core/agent";

export const testAgent = new Agent({
  name: "test-agent",
  instructions: "You are a helpful assistant.",
  model: "openai/gpt-4o-mini"
});
```

#### Instruction formats

Instructions define the agent's behavior, personality, and capabilities.
They are system-level prompts that establish the agent's core identity and expertise.

Instructions can be provided in multiple formats for greater flexibility. Choose the approach that best matches your agentâ€™s configuration:

<Tabs
  items={[
    "String",
    "System message",
    "Array of strings",
    "Array of system messages",
    "With provider options"
  ]}
>
  <Tabs.Tab>
Use a simple string for quick prototypes or straightforward behaviors.

```typescript copy
// String (most common)
instructions: "You are a helpful assistant."
```
  </Tabs.Tab>
  <Tabs.Tab>
Wrap the prompt in a system message object when you need to pass structured metadata.

```typescript copy
// System message object
instructions: {
  role: "system",
  content: "You are an expert programmer."
}
```
  </Tabs.Tab>
  <Tabs.Tab>
Provide multiple guidance statements while keeping the format lightweight with an array of strings.

```typescript copy
// Array of strings
instructions: [
  "You are a helpful assistant.",
  "Always be polite.",
  "Provide detailed answers."
]
```
  </Tabs.Tab>
  <Tabs.Tab>
Use fully structured messages when you want fine-grained control over roles and sequencing.

```typescript copy
// Array of system messages
instructions: [
  { role: "system", content: "You are a helpful assistant." },
  { role: "system", content: "You have expertise in TypeScript." }
]
```
  </Tabs.Tab>
  <Tabs.Tab>
Attach provider-specific configuration to unlock capabilities like caching or reasoning modes.

```typescript copy
// With provider-specific options (e.g., caching, reasoning)
instructions: {
  role: "system",
  content:
    "You are an expert code reviewer. Analyze code for bugs, performance issues, and best practices.",
  providerOptions: {
    openai: { reasoning_effort: "high" },        // OpenAI's reasoning models
    anthropic: { cache_control: { type: "ephemeral" } }  // Anthropic's prompt caching
  }
}
```
  </Tabs.Tab>
</Tabs>

### Provider-specific options

Provider-specific options allow you to leverage unique features of different LLM providers:
- **Anthropic caching**: Reduce costs by caching frequently-used instructions
- **OpenAI reasoning**: Enable deeper analysis for complex tasks
- **Custom parameters**: Pass any provider-specific configuration

> See [Agent](../../reference/agents/agent.mdx) for more information.

### Registering an agent

Register your agent in the Mastra instance to make it available throughout your application. Once registered, it can be called from workflows, tools, or other agents, and has access to shared resources such as memory, logging, and observability features:

```typescript showLineNumbers filename="src/mastra/index.ts" copy
import { Mastra } from "@mastra/core/mastra";
import { testAgent } from './agents/test-agent';

export const mastra = new Mastra({
  // ...
  agents: { testAgent },
});
```

## Referencing an agent

You can call agents from workflow steps, tools, the Mastra Client, or the command line. Get a reference by calling `.getAgent()` on your `mastra` or `mastraClient` instance, depending on your setup:

```typescript showLineNumbers copy
const testAgent = mastra.getAgent("testAgent");
```

Note that `mastra.getAgent()` is preferred over a direct import, since it will preserve the Mastra instance configuration (tools registered, telemetry, vector stores configuration for agent memory, etc.)

> See [Calling agents](../../examples/agents/calling-agents.mdx) for more information.

## Generating responses

Agents can return results in two ways: generating the full output before returning it or streaming tokens in real time. Choose the approach that fits your use case: generate for short, internal responses or debugging, and stream to deliver pixels to end users as quickly as possible.

<Tabs items={["Generate", "Stream"]}>
  <Tabs.Tab>
Pass a single string for simple prompts, an array of strings when providing multiple pieces of context, or an array of message objects with `role` and `content` for precise control over roles and conversational flows.

Call `.generate()` with an array of message objects containing `role` and `content`. The `role` defines the speaker for each message. Typical roles are `user` for human input, `assistant` for agent responses, and `system` for instructions. This structure helps the LLM maintain conversation flow and generate contextually appropriate responses.

```typescript showLineNumbers copy
const response = await testAgent.generate([
  { role: "user", content: "Help me organize my day" },
  { role: "user", content: "My day starts at 9am and finishes at 5.30pm" },
  { role: "user", content: "I take lunch between 12:30 and 13:30" },
  { role: "user", content: "I have meetings Monday to Friday between 10:30 and 11:30" }
]);

console.log(response.text);
```
  </Tabs.Tab>
  <Tabs.Tab>
Pass a single string for simple prompts, an array of strings when providing multiple pieces of context, or an array of message objects with `role` and `content` for precise control over roles and conversational flows.

Use `.stream()` with an array of message objects that include `role` and `content`:

```typescript showLineNumbers copy
const stream = await testAgent.stream([
  { role: "user", content: "Help me organize my day" },
  { role: "user", content: "My day starts at 9am and finishes at 5.30pm" },
  { role: "user", content: "I take lunch between 12:30 and 13:30" },
  { role: "user", content: "I have meetings Monday to Friday between 10:30 and 11:30" }
]);

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### Completion using `onFinish()`

When streaming responses, the `onFinish()` callback runs after the LLM finishes generating its response and all tool executions are complete.
It provides the final `text`, execution `steps`, `finishReason`, token `usage` statistics, and other metadata useful for monitoring or logging.

```typescript showLineNumbers copy
const stream = await testAgent.stream("Help me organize my day", {
  onFinish: ({ steps, text, finishReason, usage }) => {
    console.log({ steps, text, finishReason, usage });
  }
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```
  </Tabs.Tab>
</Tabs>

> See [.generate()](../../reference/agents/generate.mdx) or [.stream()](../../reference/agents/stream.mdx) for more information.

## Structured output

Agents can return structured, type-safe data by defining the expected output using either [Zod](https://zod.dev/) or [JSON Schema](https://json-schema.org/). We recommend Zod for better TypeScript support and developer experience. The parsed result is available on `response.object`, allowing you to work directly with validated and typed data.

### Using Zod

Define the `output` shape using [Zod](https://zod.dev/):

```typescript showLineNumbers copy
import { z } from "zod";

const response = await testAgent.generate(
  [
    {
      role: "system",
      content: "Provide a summary and keywords for the following text:"
    },
    {
      role: "user",
      content: "Monkey, Ice Cream, Boat"
    }
  ],
  {
    output: z.object({
      summary: z.string(),
      keywords: z.array(z.string())
    })
  }
);

console.log(response.object);
```

#### Agents with tools

To generate structured output with agents that use tools, use the `output` property:

```typescript {6} showLineNumbers copy
import { z } from "zod";

const response = await testAgent.generate(
  // ...
  {
    output: z.object({
      summary: z.string(),
      keywords: z.array(z.string())
    })
  }
);

console.log(response.object);
```

## Working with images

Agents can analyze and describe images by processing both the visual content and any text within them. To enable image analysis, pass an object with `type: 'image'` and the image URL in the `content` array. You can combine image content with text prompts to guide the agent's analysis.

```typescript showLineNumbers copy
const response = await testAgent.generate([
  {
    role: "user",
    content: [
      {
        type: "image",
        image: "https://placebear.com/cache/395-205.jpg",
        mimeType: "image/jpeg"
      },
      {
        type: "text",
        text: "Describe the image in detail, and extract all the text in the image."
      }
    ]
  }
]);

console.log(response.text);
```

## Multi-step tool use

Agents can be enhanced with tools, functions that extend their capabilities beyond text generation. Tools allow agents to perform calculations, access external systems, and process data. Agents not only decide whether to call tools they're given, they determine the parameters that should be given to that tool.

For a detailed guide to creating and configuring tools, see the [Tools Overview](../tools-mcp/overview.mdx) page.

### Using `maxSteps`

The `maxSteps` parameter controls the maximum number of sequential LLM calls an agent can make. Each step includes generating a response, executing any tool calls, and processing the result. Limiting steps helps prevent infinite loops, reduce latency, and control token usage for agents that use tools. The default is 1, but can be increased:

```typescript showLineNumbers copy
const response = await testAgent.generate("Help me organize my day", {
  maxSteps: 5
});

console.log(response.text);
```

### Using `onStepFinish`

You can monitor the progress of multi-step operations using the `onStepFinish` callback. This is useful for debugging or providing progress updates to users.

`onStepFinish` is only available when streaming or generating text without structured output.

```typescript showLineNumbers copy
const response = await testAgent.generate("Help me organize my day", {
  onStepFinish: ({ text, toolCalls, toolResults, finishReason, usage }) => {
    console.log({ text, toolCalls, toolResults, finishReason, usage });
  }
});
```

## Testing agents locally
There are two ways to run and test agents.

<Steps>

### Mastra Playground

With the Mastra Dev Server running you can test an agent from the Mastra Playground by visiting [http://localhost:4111/agents](http://localhost:4111/agents) in your browser.

> For more information, see the [Local Dev Playground](/docs/server-db/local-dev-playground) documentation.

### Command line

Create an agent response using `.generate()` or `.stream()`.

```typescript {7} filename="src/test-agent.ts" showLineNumbers copy
import "dotenv/config";

import { mastra } from "./mastra";

const agent = mastra.getAgent("testAgent");

const response = await agent.generate("Help me organize my day");

console.log(response.text);
```

> See [.generate()](../../reference/agents/generate.mdx) or [.stream()](../../reference/agents/stream.mdx) for more information.

To test this agent, run the following:

```bash copy
npx tsx src/test-agent.ts
```

</Steps>

## Related

- [Agent Memory](./agent-memory.mdx)
- [Dynamic Agents](./dynamic-agents.mdx)
- [Agent Tools and MCP](./using-tools-and-mcp.mdx)
- [Calling Agents](../../examples/agents/calling-agents.mdx)
