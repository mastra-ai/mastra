---
title: "Together AI | Models | Mastra"
description: "Use Together AI models with Mastra. 6 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}

import ProviderModelsTable from "@site/src/components/ProviderModelsTable";
import PropertiesTable from "@site/src/components/PropertiesTable";

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

# <img src="https://models.dev/logos/togetherai.svg" alt="Together AI logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Together AI

Access 6 Together AI models through Mastra's model router. Authentication is handled automatically using the `TOGETHER_API_KEY` environment variable.

Learn more in the [Together AI documentation](https://docs.together.ai/docs/serverless-models).

```bash
TOGETHER_API_KEY=your-api-key
```

```typescript
import { Agent } from "@mastra/core/agent";

const agent = new Agent({
  id: "my-agent",
  name: "My Agent",
  instructions: "You are a helpful assistant",
  model: "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Together AI documentation](https://docs.together.ai/docs/serverless-models) for details.

:::

## Models

<ProviderModelsTable
  models={[
  {
    "model": "togetherai/deepseek-ai/DeepSeek-R1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": true,
    "contextWindow": 163839,
    "maxOutput": 12288,
    "inputCost": 3,
    "outputCost": 7
  },
  {
    "model": "togetherai/deepseek-ai/DeepSeek-V3",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 12288,
    "inputCost": 1.25,
    "outputCost": 1.25
  },
  {
    "model": "togetherai/meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 66536,
    "inputCost": 0.88,
    "outputCost": 0.88
  },
  {
    "model": "togetherai/moonshotai/Kimi-K2-Instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 32768,
    "inputCost": 1,
    "outputCost": 3
  },
  {
    "model": "togetherai/openai/gpt-oss-120b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 131072,
    "inputCost": 0.15,
    "outputCost": 0.6
  },
  {
    "model": "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 262144,
    "maxOutput": 66536,
    "inputCost": 2,
    "outputCost": 2
  }
]}
/>

## Advanced Configuration

### Custom Headers

```typescript
const agent = new Agent({
  id: "custom-agent",
  name: "custom-agent",
  model: {
    url: "https://api.together.xyz/v1",
    id: "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    apiKey: process.env.TOGETHER_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### Dynamic Model Selection

```typescript
const agent = new Agent({
  id: "dynamic-agent",
  name: "Dynamic Agent",
  model: ({ requestContext }) => {
    const useAdvanced = requestContext.task === "complex";
    return useAdvanced
      ? "togetherai/openai/gpt-oss-120b"
      : "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8";
  }
});
```



## Direct Provider Installation

This provider can also be installed directly as a standalone package, which can be used instead of the Mastra model router string. View the [package documentation](https://www.npmjs.com/package/@ai-sdk/togetherai) for more details.

```bash npm2yarn copy
npm install @ai-sdk/togetherai
```

For detailed provider-specific documentation, see the [AI SDK Together AI provider docs](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai).
