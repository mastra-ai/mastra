---
title: "STACKIT | Models"
description: "Use STACKIT models with Mastra. 8 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}

# <img src="https://models.dev/logos/stackit.svg" alt="STACKIT logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />STACKIT

Access 8 STACKIT models through Mastra's model router. Authentication is handled automatically using the `STACKIT_API_KEY` environment variable.

Learn more in the [STACKIT documentation](https://docs.stackit.cloud/products/data-and-ai/ai-model-serving/basics/available-shared-models).

```bash title=".env"
STACKIT_API_KEY=your-api-key
```

```typescript title="src/mastra/agents/my-agent.ts" {7}
import { Agent } from "@mastra/core/agent";

const agent = new Agent({
  id: "my-agent",
  name: "My Agent",
  instructions: "You are a helpful assistant",
  model: "stackit/e5-mistral-7b"
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [STACKIT documentation](https://docs.stackit.cloud/products/data-and-ai/ai-model-serving/basics/available-shared-models) for details.

:::

## Models

<ProviderModelsTable
  models={[
  {
    "model": "stackit/e5-mistral-7b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 4096,
    "maxOutput": 4096,
    "inputCost": 0.02,
    "outputCost": 0.02
  },
  {
    "model": "stackit/gemma-3-27b",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 37000,
    "maxOutput": 8192,
    "inputCost": 0.53,
    "outputCost": 0.77
  },
  {
    "model": "stackit/gpt-oss-120b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 0.53,
    "outputCost": 0.77
  },
  {
    "model": "stackit/llama-3.1-8b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 0.18,
    "outputCost": 0.3
  },
  {
    "model": "stackit/llama-3.3-70b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 0.53,
    "outputCost": 0.77
  },
  {
    "model": "stackit/mistral-nemo",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 0.53,
    "outputCost": 0.77
  },
  {
    "model": "stackit/qwen3-vl-235b",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 218000,
    "maxOutput": 8192,
    "inputCost": 1.77,
    "outputCost": 2.07
  },
  {
    "model": "stackit/qwen3-vl-embedding-8b",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 32000,
    "maxOutput": 4096,
    "inputCost": 0.09,
    "outputCost": 0.09
  }
]}
/>

## Advanced Configuration

### Custom Headers

```typescript title="src/mastra/agents/my-agent.ts"
const agent = new Agent({
  id: "custom-agent",
  name: "custom-agent",
  model: {
    url: "https://api.openai-compat.model-serving.eu01.onstackit.cloud/v1",
    id: "stackit/e5-mistral-7b",
    apiKey: process.env.STACKIT_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### Dynamic Model Selection

```typescript title="src/mastra/agents/my-agent.ts"
const agent = new Agent({
  id: "dynamic-agent",
  name: "Dynamic Agent",
  model: ({ requestContext }) => {
    const useAdvanced = requestContext.task === "complex";
    return useAdvanced
      ? "stackit/qwen3-vl-embedding-8b"
      : "stackit/e5-mistral-7b";
  }
});
```


