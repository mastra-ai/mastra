---
title: "NanoGPT | Models | Mastra"
description: "Use NanoGPT models with Mastra. 21 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}

# <img src="https://models.dev/logos/nano-gpt.svg" alt="NanoGPT logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />NanoGPT

Access 21 NanoGPT models through Mastra's model router. Authentication is handled automatically using the `NANO_GPT_API_KEY` environment variable.

Learn more in the [NanoGPT documentation](https://docs.nano-gpt.com).

```bash
NANO_GPT_API_KEY=your-api-key
```

```typescript
import { Agent } from "@mastra/core/agent";

const agent = new Agent({
  id: "my-agent",
  name: "My Agent",
  instructions: "You are a helpful assistant",
  model: "nano-gpt/deepseek/deepseek-r1"
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [NanoGPT documentation](https://docs.nano-gpt.com) for details.

:::

## Models

<ProviderModelsTable
  models={[
  {
    "model": "nano-gpt/deepseek/deepseek-r1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/deepseek/deepseek-v3.2:thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/meta-llama/llama-3.3-70b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/meta-llama/llama-4-maverick",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/minimax/minimax-m2.1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/mistralai/devstral-2-123b-instruct-2512",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/mistralai/ministral-14b-instruct-2512",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/mistralai/mistral-large-3-675b-instruct-2512",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/moonshotai/kimi-k2-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/moonshotai/kimi-k2-thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 32768,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/nousresearch/hermes-4-405b:thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/nvidia/llama-3_3-nemotron-super-49b-v1_5",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/openai/gpt-oss-120b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/qwen/qwen3-235b-a22b-thinking-2507",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 262144,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/qwen/qwen3-coder",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 106000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/z-ai/glm-4.6",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 200000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/z-ai/glm-4.6:thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/zai-org/glm-4.5-air",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/zai-org/glm-4.5-air:thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/zai-org/glm-4.7",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 204800,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  },
  {
    "model": "nano-gpt/zai-org/glm-4.7:thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": 1,
    "outputCost": 2
  }
]}
/>

## Advanced Configuration

### Custom Headers

```typescript
const agent = new Agent({
  id: "custom-agent",
  name: "custom-agent",
  model: {
    url: "https://nano-gpt.com/api/v1",
    id: "nano-gpt/deepseek/deepseek-r1",
    apiKey: process.env.NANO_GPT_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### Dynamic Model Selection

```typescript
const agent = new Agent({
  id: "dynamic-agent",
  name: "Dynamic Agent",
  model: ({ requestContext }) => {
    const useAdvanced = requestContext.task === "complex";
    return useAdvanced
      ? "nano-gpt/zai-org/glm-4.7:thinking"
      : "nano-gpt/deepseek/deepseek-r1";
  }
});
```


