---
title: "Nvidia | Models | Mastra"
description: "Use Nvidia models with Mastra. 20 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}





# <img src="https://models.dev/logos/nvidia.svg" alt="Nvidia logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Nvidia

Access 20 Nvidia models through Mastra's model router. Authentication is handled automatically using the `NVIDIA_API_KEY` environment variable.

Learn more in the [Nvidia documentation](https://docs.api.nvidia.com/nim/).

```bash
NVIDIA_API_KEY=your-api-key
```

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "nvidia/black-forest-labs/flux.1-dev"
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Nvidia documentation](https://docs.api.nvidia.com/nim/) for details.

:::

## Models

<ProviderModelsTable
  models={[
  {
    "model": "nvidia/black-forest-labs/flux.1-dev",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 4096,
    "maxOutput": null,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/deepseek-ai/deepseek-v3.1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/deepseek-ai/deepseek-v3.1-terminus",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/google/gemma-3-27b-it",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/microsoft/phi-4-mini-instruct",
    "imageInput": true,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/minimaxai/minimax-m2",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 16384,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/moonshotai/kimi-k2-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/moonshotai/kimi-k2-instruct-0905",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 262144,
    "maxOutput": 262144,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/cosmos-nemotron-34b",
    "imageInput": true,
    "audioInput": false,
    "videoInput": true,
    "toolUsage": false,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/llama-3.1-nemotron-ultra-253b-v1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/llama-embed-nemotron-8b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 32768,
    "maxOutput": 2048,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/nemoretriever-ocr-v1",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/nvidia-nemotron-nano-9b-v2",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 131072,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/parakeet-tdt-0.6b-v2",
    "imageInput": false,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/openai/gpt-oss-120b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/openai/whisper-large-v3",
    "imageInput": false,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-235b-a22b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-coder-480b-a35b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 262144,
    "maxOutput": 66536,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-next-80b-a3b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 262144,
    "maxOutput": 16384,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-next-80b-a3b-thinking",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 262144,
    "maxOutput": 16384,
    "inputCost": null,
    "outputCost": null
  }
]}
/>

## Advanced Configuration

### Custom Headers

```typescript
const agent = new Agent({
  name: "custom-agent",
  model: {
    url: "https://integrate.api.nvidia.com/v1",
    id: "nvidia/black-forest-labs/flux.1-dev",
    apiKey: process.env.NVIDIA_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### Dynamic Model Selection

```typescript
const agent = new Agent({
  name: "dynamic-agent",
  model: ({ runtimeContext }) => {
    const useAdvanced = runtimeContext.task === "complex";
    return useAdvanced
      ? "nvidia/qwen/qwen3-next-80b-a3b-thinking"
      : "nvidia/black-forest-labs/flux.1-dev";
  }
});
```


