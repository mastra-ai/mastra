---
title: "Providers: Vultr | Models | Mastra"
description: "Use Vultr models with Mastra. 5 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}

import ProviderModelsTable from "@site/src/components/ProviderModelsTable";
import PropertiesTable from "@site/src/components/PropertiesTable";

# <img src="https://models.dev/logos/vultr.svg" alt="Vultr logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Vultr

Access 5 Vultr models through Mastra's model router. Authentication is handled automatically using the `VULTR_API_KEY` environment variable.

Learn more in the [Vultr documentation](https://api.vultrinference.com/).

```bash
VULTR_API_KEY=your-api-key
```

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "vultr/deepseek-r1-distill-llama-70b",
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Vultr documentation](https://api.vultrinference.com/) for details.

:::

## Models

<ProviderModelsTable
  models={[
    {
      model: "vultr/deepseek-r1-distill-llama-70b",
      imageInput: false,
      audioInput: false,
      videoInput: false,
      toolUsage: true,
      reasoning: true,
      contextWindow: 121808,
      maxOutput: 8192,
      inputCost: 0.2,
      outputCost: 0.2,
    },
    {
      model: "vultr/deepseek-r1-distill-qwen-32b",
      imageInput: false,
      audioInput: false,
      videoInput: false,
      toolUsage: true,
      reasoning: true,
      contextWindow: 121808,
      maxOutput: 8192,
      inputCost: 0.2,
      outputCost: 0.2,
    },
    {
      model: "vultr/gpt-oss-120b",
      imageInput: false,
      audioInput: false,
      videoInput: false,
      toolUsage: true,
      reasoning: false,
      contextWindow: 121808,
      maxOutput: 8192,
      inputCost: 0.2,
      outputCost: 0.2,
    },
    {
      model: "vultr/kimi-k2-instruct",
      imageInput: false,
      audioInput: false,
      videoInput: false,
      toolUsage: true,
      reasoning: false,
      contextWindow: 58904,
      maxOutput: 4096,
      inputCost: 0.2,
      outputCost: 0.2,
    },
    {
      model: "vultr/qwen2.5-coder-32b-instruct",
      imageInput: false,
      audioInput: false,
      videoInput: false,
      toolUsage: true,
      reasoning: false,
      contextWindow: 12952,
      maxOutput: 2048,
      inputCost: 0.2,
      outputCost: 0.2,
    },
  ]}
/>

## Advanced Configuration

### Custom Headers

```typescript
const agent = new Agent({
  name: "custom-agent",
  model: {
    url: "https://api.vultrinference.com/v1",
    id: "vultr/deepseek-r1-distill-llama-70b",
    apiKey: process.env.VULTR_API_KEY,
    headers: {
      "X-Custom-Header": "value",
    },
  },
});
```

### Dynamic Model Selection

```typescript
const agent = new Agent({
  name: "dynamic-agent",
  model: ({ runtimeContext }) => {
    const useAdvanced = runtimeContext.task === "complex";
    return useAdvanced
      ? "vultr/qwen2.5-coder-32b-instruct"
      : "vultr/deepseek-r1-distill-llama-70b";
  },
});
```
