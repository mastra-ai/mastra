---
title: "Models"
description: "Access 44+ AI providers and 618+ models through Mastra's model router."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}

import { Tabs, Tab } from "@/components/tabs";
import { CardGrid, CardGridItem } from "@/components/cards/card-grid";
import { Callout } from "nextra/components";

# Model Providers


Integrating AI models into applications typically means dealing with different SDKs, authentication methods, and API formats for each provider. Every new model requires learning a new integration.

Mastra's Model Router standardizes how you work with AI models across providers. This means you can focus on building your application instead of managing provider-specific implementations. Access 600+ models from 40+ providers through a single interface — no package installs, no provider-specific imports. Just specify the model as a string and Mastra handles the rest.

Whether you're using providers directly like OpenAI, Anthropic, or Google, or working through gateways like OpenRouter, the Model Router manages all the routing, authentication, and API compatibility for you. When you need a specific model, you write it as `provider/model-name` and Mastra reads the appropriate environment variable (like `ANTHROPIC_API_KEY`) automatically.

<Tabs items={["OpenAI", "Anthropic", "OpenRouter"]}>
  <Tab>
    ```typescript copy
    import { Agent } from "@mastra/core";

    const agent = new Agent({
      name: "my-agent",
      instructions: "You are a helpful assistant",
      model: "openai/gpt-4o"  // Works with any provider/model
    });
    ```
  </Tab>
  <Tab>
    ```typescript copy
    import { Agent } from "@mastra/core";

    const agent = new Agent({
      name: "assistant", 
      instructions: "You are a helpful assistant",
      model: "anthropic/claude-3-5-sonnet"
    });
    ```
  </Tab>
  <Tab>
    ```typescript copy
    import { Agent } from "@mastra/core";

    const agent = new Agent({
      name: "assistant",
      instructions: "You are a helpful assistant", 
      model: "openrouter/meta-llama/llama-3.1-8b-instruct"
    });
    ```
  </Tab>
</Tabs>

## Features

- One API for any model - Access hundreds of models without learning different SDKs or managing multiple integrations. The same Agent interface works with every provider.
- Access the newest AI - New models appear in your IDE autocomplete as soon as they're released. No package updates needed — the model registry updates automatically.
- Single integration - Instead of integrating with each provider separately, you get a model-agnostic interface that works with OpenAI, Anthropic, Google, and dozens more through one consistent API.
- Mix and match models - Use different models for different tasks within your application. Run GPT-4o-mini for processing large documents with its 128K context window, then switch to Claude Opus 4.1 for complex reasoning tasks. Optimize cost and performance by selecting the right model for each job.
- Model discovery - Full TypeScript autocomplete for all 600+ models in your IDE. Start typing and see what's available — no need to check documentation. The playground UI also provides browsable model selection.
- Guaranteed uptime - If a provider experiences an outage or high latency period, automatically reroute to other providers so your customers never experience any issues. Unlike other solutions that force you through their gateway, Mastra handles this at the application level and routes directly to providers for the lowest latency. Learn more about guaranteed uptime →

## Model directory
Mastra supports models from all major AI providers and gateways. Browse the complete list using the navigation on the left, or explore all available models below.

<CardGrid>
    <CardGridItem
      title="Gateways"
      href="./models/gateways"
    >
      <div className="space-y-3">
        <div className="flex flex-col gap-2">
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/openrouter.svg" alt="OpenRouter" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>OpenRouter</span>
          </div>
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/fireworks-ai.svg" alt="Fireworks AI" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>Fireworks AI</span>
          </div>
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/togetherai.svg" alt="Together AI" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>Together AI</span>
          </div>
        </div>
        <div className="text-sm text-gray-600 dark:text-gray-400 mt-3">+ 4 more</div>
      </div>
    </CardGridItem>
    <CardGridItem
      title="Providers"
      href="./models/providers"
    >
      <div className="space-y-3">
        <div className="flex flex-col gap-2">
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/openai.svg" alt="OpenAI" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>OpenAI</span>
          </div>
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/anthropic.svg" alt="Anthropic" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>Anthropic</span>
          </div>
          <div className="flex items-center gap-2 text-sm">
            <img src="https://models.dev/logos/google.svg" alt="Google" className="w-4 h-4 object-contain dark:invert dark:brightness-0 dark:contrast-200" />
            <span>Google</span>
          </div>
        </div>
        <div className="text-sm text-gray-600 dark:text-gray-400 mt-3">+ 34 more</div>
      </div>
    </CardGridItem>
</CardGrid>

Direct providers include OpenAI, Anthropic, Google, Cohere, and more. Gateways like OpenRouter give you access to even more models through a unified billing interface. Each provider's models are available with the same simple string format: provider/model-name.

## Model Discovery

Mastra automatically pulls in the latest models from providers like OpenAI, Anthropic, Google, and gateways like OpenRouter. When providers release new models, they appear in your IDE autocomplete without any package updates.

The model registry fetches from sources including models.dev, OpenRouter's model list, and provider APIs. This means you're always working with the most current selection of available models — no manual updates, no waiting for package releases.

<Callout type="info">
**Auto-Refresh**: The model registry automatically refreshes every hour during development. To disable, set `MASTRA_AUTO_REFRESH_PROVIDERS=false`. Auto-refresh is disabled by default in production.
</Callout>



## Mix and Match Models

Use different models for different parts of your application to optimize both cost and performance. Each agent can use the model best suited for its specific task:

```typescript
import { Agent } from "@mastra/core";

// Use a cost-effective model for document processing
const documentProcessor = new Agent({
  name: "document-processor",
  instructions: "Extract and summarize key information from documents",
  model: "openai/gpt-4o-mini"  // 128K context window, low cost
});

// Use a powerful reasoning model for complex analysis
const reasoningAgent = new Agent({
  name: "reasoning-agent", 
  instructions: "Analyze data and provide strategic recommendations",
  model: "anthropic/claude-opus-4-1"  // Advanced reasoning capabilities
});

// Use a fast model for real-time interactions
const chatAgent = new Agent({
  name: "chat-agent",
  instructions: "Provide quick responses in conversations",
  model: "google/gemini-1.5-flash"  // Optimized for speed
});
```

This approach lets you build sophisticated AI systems where each component uses the optimal model — avoiding overpaying for simple tasks while ensuring complex operations have the power they need.

## Model Fallbacks

Configure backup models that activate automatically when your primary provider fails:

```typescript
import { Agent } from '@mastra/core';

const agent = new Agent({
  name: 'resilient-assistant',
  instructions: 'You are a helpful assistant.',
  model: [
    {
      model: "openai/gpt-4o-mini",
      maxRetries: 3,
    },
    {
      model: "anthropic/claude-3-5-sonnet",
      maxRetries: 2,
    },
    {
      model: "google/gemini-pro",
      maxRetries: 2,
    },
  ],
});
```
The system tries your primary model first. If it encounters a 500 error, rate limit, or timeout, it automatically switches to your first fallback. If that fails too, it moves to the next. Each model gets its own retry count before moving on.

Your users never experience the disruption — the response comes back with the same format, just from a different model. The error context is preserved as the system moves through your fallback chain, ensuring clean error propagation while maintaining streaming compatibility.


## Dynamic Model Selection at Runtime

Since models are just strings, you can select them dynamically based on runtime context:


```typescript
const agent = new Agent({
  name: "dynamic-assistant",
  model: ({ runtimeContext }) => {
    const provider = runtimeContext.get("provider-id");
    const model = runtimeContext.get("model-id");
    return `${provider}/${model}`;
  },
});
```

This enables powerful patterns:

- Split testing - Compare model performance in production
- User-selectable models - Let users choose their preferred model in your app
- Multi-tenant applications - Each customer can bring their own API keys and model preferences

## Provider-specific options

Each model provider also enables a few different options, including prompt caching and configuring reasoning. We provide a providerOptions flag to manage these. You can set providerOptions on the instruction level to set different caching strategy per system instruction/prompt.

```typescript
// With provider-specific options (e.g., caching, reasoning)
instructions: {
  role: "system",
  content:
    "You are an expert code reviewer. Analyze code for bugs, performance issues, and best practices.",
  providerOptions: {
    openai: { reasoning_effort: "high" },        // OpenAI's reasoning models
    anthropic: { cache_control: { type: "ephemeral" } }  // Anthropic's prompt caching
  }
}
```

## Custom headers

```typescript
const agent = new Agent({
  name: "custom-agent",
  model: {
    url: "https://llm.chutes.ai/v1",
    modelId: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    apiKey: process.env.CHUTES_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

## Alternative Model Providers (AI SDK)

While Mastra provides built-in support for 600+ models, you can also use Vercel AI SDK model providers for additional flexibility:

```typescript
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "AISDKAgent",
  model: openai("gpt-4-turbo")  // AI SDK model provider
});
```

