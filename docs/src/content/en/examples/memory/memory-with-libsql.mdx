---
title: "Example: Memory with LibSQL | Memory | Mastra Docs"
description: Example for how to use Mastra's memory system with LibSQL storage and vector database backend.
---

# Memory with LibSQL

This example demonstrates how to use Mastra's memory system with LibSQL, which is an option for storage and vector database backend.

## Prerequisites

This example uses the `openai` model. Make sure to add `OPENAI_API_KEY` to your `.env` file.

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

## Adding memory to an agent

To add LibSQL memory to an agent use the `Memory` class and create a new `storage` key using `LibSQLStore`. The `url` can either by a remote location, or a local file system resource.

```typescript filename="src/mastra/agents/example-libsql-agent.ts" showLineNumbers copy
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { LibSQLStore } from "@mastra/libsql";
import { openai } from "@ai-sdk/openai";

export const libsqlAgent = new Agent({
  name: "libsql-agent",
  instructions: "You are an AI agent with the ability to automatically recall memories from previous interactions.",
  model: openai("gpt-4o"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db"
    }),
    options: {
      threads: {
        generateTitle: true
      }
    }
  })
});
```

## Local embeddings with FastEmbed

Embeddings are numeric vectors that represent text so the agent can semantically recall related messages. This example uses `@mastra/fastembed` to generate embeddings locally—no external API calls—keeping data on-device, reducing cost, and giving predictable latency.

Install `fastembed` to get started:

```bash copy
npm install @mastra/fastembed
```

Add the following to your agent:

```typescript {15-18, 20-24} filename="src/mastra/agents/example-libsql-agent.ts" showLineNumbers copy
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";
import { openai } from "@ai-sdk/openai";
import { fastembed } from "@mastra/fastembed";

export const libsqlAgent = new Agent({
  name: "libsql-agent",
  instructions: "You are an AI agent with the ability to automatically recall memories from previous interactions.",
  model: openai("gpt-4o"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db"
    }),
    vector: new LibSQLVector({
      connectionUrl: "file:local.db"
    }),
    embedder: fastembed,
    options: {
      lastMessages: 10,
      semanticRecall: {
        topK: 3,
        messageRange: 2
      },
      threads: {
        generateTitle: true
      }
    }
  })
});
```

## Usage Example

Use `memoryOptions` to scope recall for this request. Set `lastMessages: false` to disable recency-based recall, and use `semanticRecall` to fetch the `topK: 3` most relevant messages, including `messageRange: 2` neighboring messages for context around each match.

```typescript filename="src/test-libsql-agent.ts" showLineNumbers copy
import "dotenv/config";

import { mastra } from "./mastra";

const agent = mastra.getAgent("libsqlAgent");

const stream = await agent.stream("What did we discuss earlier?", {
  memoryOptions: {
    lastMessages: false,
    semanticRecall: {
      topK: 3,
      messageRange: 2
    }
  }
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```


## Related

- [Calling Agents](../agents/calling-agents.mdx)
