---
title: "Example: Streaming Working Memory | Memory | Mastra Docs"
description: Example for how to use working memory with an agent to maintain conversational context.
---

# Streaming Working Memory

This example demonstrates how to create an agent that maintains a working memory for relevant conversational details like the users name, location, or preferences.

## Prerequisites

This example uses the `openai` model. Make sure to add `OPENAI_API_KEY` to your `.env` file.

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

And install the following package:

```bash copy
npm install @mastra/libsql
```

## Adding memory to an agent

To add LibSQL memory to an agent, use the `Memory` class and create a `storage` key with `LibSQLStore`. The `url` can point to either a remote location or a local file system resource.

### Enable working memory

Enable `workingMemory` in the options to allow the agent to recall information during ongoing interactions while also persisting data across application restarts.

```typescript filename="src/mastra/agents/example-working-memory-agent.ts" showLineNumbers copy
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { LibSQLStore } from "@mastra/libsql";

export const workingMemoryAgent = new Agent({
  name: "working-memory-agent",
  instructions: "You are an AI agent with the ability to automatically recall memories from previous interactions.",
  model: openai("gpt-4o"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:working-memory.db"
    }),
    options: {
      workingMemory: {
        enabled: true,
      },
      threads: {
        generateTitle: true
      }
    }
  })
});
```

## Usage example

This example shows how to interact with an agent that has working memory enabled. The agent will remember information shared across multiple interactions within the same thread.

### Closing streams for memory writes

To persist responses in memory, each `textStream` must be closed. Call `.pipeTo(new WritableStream())` after every message to properly finalize the response and allow it to be stored.

```typescript filename="src/test-working-memory-agent.ts" showLineNumbers copy
import "dotenv/config";

import { mastra } from "./mastra";

const threadId = "123";
const resourceId = "user-456";

const agent = mastra.getAgent("workingMemoryAgent");

const message = await agent.stream("My name is Mastra", {
  memory: {
    thread: threadId,
    resource: resourceId
  }
});

await message.textStream.pipeTo(new WritableStream());

const stream = await agent.stream("What do you know about me?", {
  memory: {
    thread: threadId,
    resource: resourceId
  }
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

## Example output

The output demonstrates the agent has used it's memory to recall information.

```text
So far, I know your first name is Mastra.
```

## Related

- [Agent Memory](../../docs/agents/agent-memory.mdx)
- [Streaming Working Memory (advanced)](./streaming-working-memory-advanced.mdx)
- [Streaming Structured Working Memory](./streaming-working-memory-structured.mdx)
