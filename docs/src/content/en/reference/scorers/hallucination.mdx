---
title: "Reference: Hallucination | Scorers | Mastra Docs"
description: Documentation for the Hallucination Scorer in Mastra, which evaluates the factual correctness of LLM outputs by identifying contradictions with provided context.
---

# Hallucination Scorer

The `createHallucinationScorer()` function evaluates whether an LLM generates factually correct information by comparing its output against the provided context. This scorer measures hallucination by identifying direct contradictions between the context and the output.

## Parameters

The `createHallucinationScorer()` function accepts a single options object with the following properties:

<PropertiesTable
  content={[
    {
      name: "model",
      type: "LanguageModel",
      required: true,
      description: "Configuration for the model used to evaluate hallucination.",
    },
    {
      name: "scale",
      type: "number",
      required: false,
      defaultValue: "1",
      description: "Maximum score value.",
    },
  ]}
/>

## .run() Input

<PropertiesTable
  content={[
    {
      name: "runId",
      type: "string",
      required: false,
      description: "The id of the run (optional).",
    },
    {
      name: "input",
      type: "Record<string, any>[]",
      required: false,
      description: "An array of records. If the scorer is added to an agent, this will contain user messages.",
    },
    {
      name: "output",
      type: "Record<string, any>",
      required: false,
      description: "A record. If the scorer is added to an agent, this will contain the assistant message.",
    },
    {
      name: "additionalContext",
      type: "Record<string, any>",
      required: false,
      description: "Additional context for the run (optional).",
    },
    {
      name: "runtimeContext",
      type: "Record<string, any>",
      required: false,
      description: "Runtime context for the run (optional).",
    },
  ]}
/>

## .run() Returns

<PropertiesTable
  content={[
    {
      name: "runId",
      type: "string",
      description: "The id of the run (optional).",
    },
    {
      name: "extractStepResult",
      type: "object",
      description: "Object with extracted claims: { claims: string[] }",
    },
    {
      name: "extractPrompt",
      type: "string",
      description: "The prompt sent to the LLM for the extract step (optional).",
    },
    {
      name: "analyzeStepResult",
      type: "object",
      description: "Object with verdicts: { verdicts: Array<{ statement: string, verdict: 'yes' | 'no', reason: string }> }",
    },
    {
      name: "analyzePrompt",
      type: "string",
      description: "The prompt sent to the LLM for the analyze step (optional).",
    },
    {
      name: "score",
      type: "number",
      description: "Hallucination score (0 to scale, default 0-1).",
    },
    {
      name: "reason",
      type: "string",
      description: "Detailed explanation of the score and identified contradictions.",
    },
    {
      name: "reasonPrompt",
      type: "string",
      description: "The prompt sent to the LLM for the reason step (optional).",
    },
  ]}
/>

## Scoring Details

The scorer evaluates hallucination through contradiction detection and unsupported claim analysis.

### Scoring Process

1. Analyzes factual content:
   - Extracts statements from context
   - Identifies numerical values and dates
   - Maps statement relationships
2. Analyzes output for hallucinations:
   - Compares against context statements
   - Marks direct conflicts as hallucinations
   - Identifies unsupported claims as hallucinations
   - Evaluates numerical accuracy
   - Considers approximation context
3. Calculates hallucination score:
   - Counts hallucinated statements (contradictions and unsupported claims)
   - Divides by total statements
   - Scales to configured range

Final score: `(hallucinated_statements / total_statements) * scale`

### Important Considerations

- Claims not present in context are treated as hallucinations
- Subjective claims are hallucinations unless explicitly supported
- Speculative language ("might", "possibly") about facts IN context is allowed
- Speculative language about facts NOT in context is treated as hallucination
- Empty outputs result in zero hallucinations
- Numerical evaluation considers:
  - Scale-appropriate precision
  - Contextual approximations
  - Explicit precision indicators

### Score interpretation

(0 to scale, default 0-1)

- 1.0: Complete hallucination - contradicts all context statements
- 0.75: High hallucination - contradicts 75% of context statements
- 0.5: Moderate hallucination - contradicts half of context statements
- 0.25: Low hallucination - contradicts 25% of context statements
- 0.0: No hallucination - output aligns with all context statements

**Note:** The score represents the degree of hallucination - lower scores indicate better factual alignment with the provided context

## Related

- [Faithfulness Scorer](./faithfulness)
- [Answer Relevancy Scorer](./answer-relevancy)
- [Context Precision Scorer](./context-precision)
- [Context Relevancy Scorer](./context-relevancy)
