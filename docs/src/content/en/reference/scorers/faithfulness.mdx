---
title: "Reference: Faithfulness | Scorers | Mastra Docs"
description: Documentation for the Faithfulness Scorer in Mastra, which evaluates the factual accuracy of LLM outputs compared to the provided context.
---

# Faithfulness Scorer

The `createFaithfulnessScorer()` function evaluates how factually accurate an LLM's output is compared to the provided context. It extracts claims from the output and verifies them against the context, making it essential to measure RAG pipeline responses' reliability.

## Parameters

The `createFaithfulnessScorer()` function accepts a single options object with the following properties:

<PropertiesTable
  content={[
    {
      name: "model",
      type: "LanguageModel",
      required: true,
      description: "Configuration for the model used to evaluate faithfulness.",
    },
    {
      name: "context",
      type: "string[]",
      required: true,
      description: "Array of context chunks against which the output's claims will be verified.",
    },
    {
      name: "scale",
      type: "number",
      required: false,
      defaultValue: "1",
      description: "The maximum score value. The final score will be normalized to this scale.",
    },
  ]}
/>

## .run() Input

<PropertiesTable
  content={[
    {
      name: "runId",
      type: "string",
      required: false,
      description: "The id of the run (optional).",
    },
    {
      name: "input",
      type: "Record<string, any>[]",
      required: false,
      description: "An array of records. If the scorer is added to an agent, this will contain user messages.",
    },
    {
      name: "output",
      type: "Record<string, any>",
      required: false,
      description: "A record. If the scorer is added to an agent, this will contain the assistant message.",
    },
    {
      name: "additionalContext",
      type: "Record<string, any>",
      required: false,
      description: "Additional context for the run (optional).",
    },
    {
      name: "runtimeContext",
      type: "Record<string, any>",
      required: false,
      description: "Runtime context for the run (optional).",
    },
  ]}
/>

## .run() Returns

<PropertiesTable
  content={[
    {
      name: "runId",
      type: "string",
      description: "The id of the run (optional).",
    },
    {
      name: "extractStepResult",
      type: "string[]",
      description: "Array of extracted claims from the output.",
    },
    {
      name: "extractPrompt",
      type: "string",
      description: "The prompt sent to the LLM for the extract step (optional).",
    },
    {
      name: "analyzeStepResult",
      type: "object",
      description: "Object with verdicts: { verdicts: Array<{ verdict: 'yes' | 'no' | 'unsure', reason: string }> }",
    },
    {
      name: "analyzePrompt",
      type: "string",
      description: "The prompt sent to the LLM for the analyze step (optional).",
    },
    {
      name: "score",
      type: "number",
      description: "A score between 0 and the configured scale, representing the proportion of claims that are supported by the context.",
    },
    {
      name: "reason",
      type: "string",
      description: "A detailed explanation of the score, including which claims were supported, contradicted, or marked as unsure.",
    },
    {
      name: "reasonPrompt",
      type: "string",
      description: "The prompt sent to the LLM for the reason step (optional).",
    },
  ]}
/>

## Scoring Details

The scorer evaluates faithfulness through claim verification against provided context.

### Scoring Process

1. Analyzes claims and context:
   - Extracts all claims (factual and speculative)
   - Verifies each claim against context
   - Assigns one of three verdicts:
     - "yes" - claim supported by context
     - "no" - claim contradicts context
     - "unsure" - claim unverifiable
2. Calculates faithfulness score:
   - Counts supported claims
   - Divides by total claims
   - Scales to configured range

Final score: `(supported_claims / total_claims) * scale`

### Score interpretation

(0 to scale, default 0-1)

- 1.0: All claims supported by context
- 0.7-0.9: Most claims supported, few unverifiable
- 0.4-0.6: Mixed support with some contradictions
- 0.1-0.3: Limited support, many contradictions
- 0.0: No supported claims

## Related

- [Answer Relevancy Scorer](./answer-relevancy)
- [Hallucination Scorer](./hallucination)
- [Context Relevancy Scorer](./context-relevancy)
