---
title: "Reference: createLLMScorer | Scorers | Mastra Docs"
description: Documentation for creating LLM-based scorers in Mastra, allowing users to define evaluation logic using language models.
---

# createLLMScorer

The `createLLMScorer()` function lets you define custom scorers that use a language model (LLM) as a judge for evaluation. LLM scorers are ideal for tasks where you want to use prompt-based evaluation, such as answer relevancy, faithfulness, or custom prompt-based metrics. LLM scorers integrate seamlessly with the Mastra scoring framework and can be used anywhere built-in scorers are used.

For a usage example, see the [Custom LLM Judge Examples](/examples/scorers/custom-llm-judge-eval).

## createLLMScorer Options

<PropertiesTable
  content={[
    {
      name: "name",
      type: "string",
      required: true,
      description: "Name of the scorer.",
    },
    {
      name: "description",
      type: "string",
      required: true,
      description: "Description of what the scorer does.",
    },
    {
      name: "judge",
      type: "object",
      required: true,
      description: "Judge configuration object. Must include a model and instructions (system prompt). See Judge Object section below.",
    },
    {
      name: "extract",
      type: "object",
      required: false,
      description: "(Optional) Extraction step configuration object. See Extract Object section below.",
    },
    {
      name: "analyze",
      type: "object",
      required: true,
      description: "Analysis step configuration object. See Analyze Object section below.",
    },
    {
      name: "reason",
      type: "object",
      required: false,
      description: "(Optional) Reason step configuration object. See Reason Object section below.",
    },
    {
      name: "calculateScore",
      type: "function",
      required: true,
      description: "Function: ({ run }) => number. Computes the final score from the analyze step result.",
    },
  ]}
/>

This function returns an instance of the MastraScorer class. See the [MastraScorer reference](./mastra-scorer) for details on the `.run()` method and its input/output.

## Judge Object
<PropertiesTable
  content={[
    {
      name: "model",
      type: "LanguageModel",
      required: true,
      description: "The LLM model instance to use for evaluation.",
    },
    {
      name: "instructions",
      type: "string",
      required: true,
      description: "System prompt/instructions for the LLM.",
    },
  ]}
/>

## Extract Object
<PropertiesTable
  content={[
    {
      name: "description",
      type: "string",
      required: true,
      description: "Description of the extract step.",
    },
    {
      name: "judge",
      type: "object",
      required: false,
      description: "(Optional) LLM judge for this step (can override main judge/model). See Judge Object section.",
    },
    {
      name: "outputSchema",
      type: "ZodSchema",
      required: true,
      description: "Zod schema for the expected output of the extract step.",
    },
    {
      name: "createPrompt",
      type: "function",
      required: true,
      description: "Function: ({ run: ScoringInput }) => string. Returns the prompt for the LLM.",
    },
  ]}
/>

## Analyze Object
<PropertiesTable
  content={[
    {
      name: "description",
      type: "string",
      required: true,
      description: "Description of the analyze step.",
    },
    {
      name: "judge",
      type: "object",
      required: false,
      description: "(Optional) LLM judge for this step (can override main judge/model). See Judge Object section.",
    },
    {
      name: "outputSchema",
      type: "ZodSchema",
      required: true,
      description: "Zod schema for the expected output of the analyze step.",
    },
    {
      name: "createPrompt",
      type: "function",
      required: true,
      description: "Function: ({ run: ScoringInput & { extractStepResult } }) => string. Returns the LLM prompt.",
    },
  ]}
/>

## Calculate Score Function

The `calculateScore` function converts the LLM's structured analysis into a numerical score. This function receives the results from previous steps but not the score itself (since that's what it calculates).

<PropertiesTable
  content={[
    {
      name: "input",
      type: "Record<string, any>[]",
      required: true,
      description:
        "Input records provided to the scorer. If the scorer is added to an agent, this will be an array of user messages, e.g. `[{ role: 'user', content: 'hello world' }]`. If the scorer is used in a workflow, this will be the input of the workflow.",
    },
    {
      name: "output",
      type: "Record<string, any>",
      required: true,
      description:
        "Output record provided to the scorer. For agents, this is usually the agent's response. For workflows, this is the workflow's output.",
    },
    {
      name: "runtimeContext",
      type: "object",
      required: false,
      description: "Runtime context from the agent or workflow step being evaluated (optional).",
    },
    {
      name: "extractStepResult",
      type: "object",
      required: false,
      description: "Result of the extract step, if defined (optional).",
    },
    {
      name: "analyzeStepResult",
      type: "object",
      required: true,
      description: "Structured result from the analyze step, conforming to the outputSchema defined in the analyze step.",
    },
  ]}
/>

Returns: `number`  
The function must return a numerical score, typically in the 0-1 range where 1 represents the best possible score.

## Reason Object
<PropertiesTable
  content={[
    {
      name: "description",
      type: "string",
      required: true,
      description: "Description of the reason step.",
    },
    {
      name: "judge",
      type: "object",
      required: false,
      description: "(Optional) LLM judge for this step (can override main judge/model). See Judge Object section.",
    },
    {
      name: "createPrompt",
      type: "function",
      required: true,
      description: "Function: ({ run }) => string. `run` includes input, output, extractStepResult, analyzeStepResult, and score. Returns the prompt for the LLM.",
    },
  ]}
/>

LLM scorers may also include step-specific prompt fields in the return value, such as `extractPrompt`, `analyzePrompt`, and `reasonPrompt`.

