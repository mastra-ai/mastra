---
title: "Reference: Prompt Alignment Scorer | Scorers | Mastra Docs"
description: Documentation for the Prompt Alignment Scorer in Mastra. Evaluates how well agent responses align with user prompt intent, requirements, completeness, and appropriateness using multi-dimensional analysis.
---

import { PropertiesTable } from "@/components/properties-table";

# Prompt Alignment Scorer

The `createPromptAlignmentScorerLLM()` function creates a scorer that evaluates how well agent responses align with user prompts across multiple dimensions: intent understanding, requirement fulfillment, response completeness, and format appropriateness.

## Parameters

<PropertiesTable
  content={[
    {
      name: "model",
      type: "MastraLanguageModel",
      description: "The language model to use for evaluating prompt-response alignment",
      required: true,
    },
    {
      name: "options",
      type: "PromptAlignmentOptions",
      description: "Configuration options for the scorer",
      required: false,
      children: [
        {
          name: "scale",
          type: "number",
          description: "Scale factor to multiply the final score (default: 1)",
          required: false,
        },
      ],
    },
  ]}
/>

## .run() Returns

<PropertiesTable
  content={[
    {
      name: "score",
      type: "number",
      description: "Multi-dimensional alignment score between 0 and scale (default 0-1)",
    },
    {
      name: "reason",
      type: "string",
      description: "Human-readable explanation of the prompt alignment evaluation with detailed breakdown",
    },
  ]}
/>

## Scoring Details

### Multi-Dimensional Analysis

Prompt Alignment evaluates responses across four key dimensions with weighted scoring:

1. **Intent Alignment** (40% weight)
   - Identifies the primary intent of the user's prompt
   - Evaluates whether the response addresses this core purpose
   - Scored 0.0 (completely misses intent) to 1.0 (perfectly addresses intent)

2. **Requirements Fulfillment** (30% weight)
   - Extracts explicit and implicit requirements from the prompt
   - Checks if each requirement is satisfied in the response
   - Overall score based on fulfilled vs. total requirements

3. **Completeness** (20% weight)
   - Assesses whether the response is comprehensive and thorough
   - Identifies missing elements that should have been included
   - Scored 0.0 (severely incomplete) to 1.0 (fully complete)

4. **Response Appropriateness** (10% weight)
   - Evaluates format alignment (e.g., list vs. paragraph, code vs. text)
   - Checks tone appropriateness (formal, casual, technical)
   - Scored 0.0 (completely inappropriate) to 1.0 (perfectly appropriate)

### Scoring Formula

```
Weighted Score = (intent_score × 0.4) + (requirements_score × 0.3) + 
                 (completeness_score × 0.2) + (appropriateness_score × 0.1)

Final Score = Weighted Score × scale
```

**Weight Distribution Rationale**:
- **Intent Alignment (40%)**: Most critical - the response must address what was asked
- **Requirements Fulfillment (30%)**: Essential for meeting specific constraints and tasks  
- **Completeness (20%)**: Important for thorough responses but secondary to correctness
- **Response Appropriateness (10%)**: Format/tone matching is helpful but not critical

### Score Interpretation

- **0.9-1.0** = Excellent alignment across all dimensions
- **0.8-0.9** = Very good alignment with minor gaps
- **0.7-0.8** = Good alignment but missing some requirements or completeness
- **0.6-0.7** = Moderate alignment with noticeable gaps
- **0.4-0.6** = Poor alignment with significant issues
- **0.0-0.4** = Very poor alignment, response doesn't address the prompt effectively

### Comparison with Other Scorers

| Aspect | Prompt Alignment | Answer Relevancy | Faithfulness |
|--------|------------------|------------------|--------------|
| **Focus** | Multi-dimensional prompt adherence | Query-response relevance | Context groundedness |
| **Evaluation** | Intent, requirements, completeness, format | Semantic similarity to query | Factual consistency with context |
| **Use Case** | General prompt following | Information retrieval | RAG/context-based systems |
| **Dimensions** | 4 weighted dimensions | Single relevance dimension | Single faithfulness dimension |

## Usage Examples

### Basic Configuration

```typescript
import { openai } from '@ai-sdk/openai';
import { createPromptAlignmentScorerLLM } from '@mastra/evals';

const scorer = createPromptAlignmentScorerLLM({
  model: openai('gpt-4o'),
});

// Evaluate a code generation task
const result = await scorer.run({
  input: [{
    role: 'user',
    content: 'Write a Python function to calculate factorial with error handling'
  }],
  output: {
    role: 'assistant', 
    text: `def factorial(n):
    if n < 0:
        raise ValueError("Factorial not defined for negative numbers")
    if n == 0:
        return 1
    return n * factorial(n-1)`
  }
});
// Result: { score: 0.95, reason: "Excellent alignment - function addresses intent, includes error handling..." }
```

### Custom Scale Configuration

```typescript
const scorer = createPromptAlignmentScorerLLM({
  model: openai('gpt-4o'),
  options: {
    scale: 10, // Score from 0-10 instead of 0-1
  },
});

const result = await scorer.run(testRun);
// Result: { score: 8.5, reason: "Score: 8.5 out of 10 - Good alignment with minor format issues..." }
```

### Format-Specific Evaluation

```typescript
// Evaluate bullet point formatting
const result = await scorer.run({
  input: [{
    role: 'user',
    content: 'List the benefits of TypeScript in bullet points'
  }],
  output: {
    role: 'assistant',
    text: 'TypeScript provides static typing, better IDE support, and enhanced code reliability.'
  }
});
// Result: Lower appropriateness score due to format mismatch (paragraph vs bullet points)
```

## Usage Patterns

### Code Generation Evaluation
Ideal for evaluating:
- Programming task completion
- Code quality and completeness  
- Adherence to coding requirements
- Format specifications (functions, classes, etc.)

```typescript
// Example: API endpoint creation
const codePrompt = "Create a REST API endpoint with authentication and rate limiting";
// Scorer evaluates: intent (API creation), requirements (auth + rate limiting), 
// completeness (full implementation), format (code structure)
```

### Instruction Following Assessment
Perfect for:
- Task completion verification
- Multi-step instruction adherence
- Requirement compliance checking
- Educational content evaluation

```typescript
// Example: Multi-requirement task
const taskPrompt = "Write a Python class with initialization, validation, error handling, and documentation";
// Scorer tracks each requirement individually and provides detailed breakdown
```

### Content Format Validation
Useful for:
- Format specification compliance
- Style guide adherence
- Output structure verification
- Response appropriateness checking

```typescript
// Example: Structured output
const formatPrompt = "Explain the differences between let and const in JavaScript using bullet points";
// Scorer evaluates content accuracy AND format compliance
```

## Common Use Cases

### 1. Agent Response Quality
Measure how well your AI agents follow user instructions:

```typescript
const agent = new Agent({
  name: 'CodingAssistant',
  instructions: 'You are a helpful coding assistant',
  model: openai('gpt-4o'),
});

const scorer = createPromptAlignmentScorerLLM({
  model: openai('gpt-4o-mini'), // Can use a different model for evaluation
});

// Evaluate agent performance
const result = await scorer.run(agentRun);
```

### 2. Prompt Engineering Optimization
Test different prompts to improve alignment:

```typescript
const prompts = [
  'Write a function to calculate factorial',
  'Create a Python function that calculates factorial with error handling for negative inputs',
  'Implement a factorial calculator in Python with: input validation, error handling, and docstring'
];

// Compare alignment scores to find the best prompt
for (const prompt of prompts) {
  const result = await scorer.run(createTestRun(prompt, response));
  console.log(`Prompt alignment: ${result.score}`);
}
```

### 3. Multi-Agent System Evaluation
Compare different agents or models:

```typescript
const agents = [agent1, agent2, agent3];
const testPrompts = [...]; // Array of test prompts

for (const agent of agents) {
  let totalScore = 0;
  for (const prompt of testPrompts) {
    const response = await agent.run(prompt);
    const evaluation = await scorer.run({ input: prompt, output: response });
    totalScore += evaluation.score;
  }
  console.log(`${agent.name} average alignment: ${totalScore / testPrompts.length}`);
}
```

## Error Handling

The scorer handles various edge cases gracefully:

```typescript
// Missing user prompt
try {
  await scorer.run({ input: [], output: response });
} catch (error) {
  // Error: "Both user prompt and agent response are required for prompt alignment scoring"
}

// Empty response
const result = await scorer.run({ 
  input: [userMessage], 
  output: { role: 'assistant', text: '' } 
});
// Returns low scores with detailed reasoning about incompleteness
```

## Related

- [Answer Relevancy Scorer](/reference/scorers/answer-relevancy) - Evaluates query-response relevance
- [Faithfulness Scorer](/reference/scorers/faithfulness) - Measures context groundedness
- [Tool Call Accuracy Scorer](/reference/scorers/tool-call-accuracy) - Evaluates tool selection
- [Custom Scorers](/docs/scorers/custom-scorers) - Creating your own evaluation metrics