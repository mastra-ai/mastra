---
title: "Reference: Agent.getLLM() | Agents | Mastra Docs"
description: "Documentation for the `Agent.getLLM()` method in Mastra agents, which retrieves the language model instance."
---

# Agent.getLLM()

The `.getLLM()` method retrieves the language model instance configured for an agent, resolving it if it's a function. This method provides access to the underlying LLM that powers the agent's capabilities.

## Usage example

```typescript copy
await agent.getLLM();
```

## Parameters

<PropertiesTable
  content={[
    {
      name: "options",
      type: "{ requestContext?: RequestContext; model?: MastraLanguageModel | DynamicArgument<MastraLanguageModel> }",
      isOptional: true,
      defaultValue: "{}",
      description:
        "Optional configuration object containing request context and optional model override.",
    },
  ]}
/>

## Returns

<PropertiesTable
  content={[
    {
      name: "llm",
      type: "MastraLLMV1 | Promise<MastraLLMV1>",
      description:
        "The language model instance configured for the agent, either as a direct instance or a promise that resolves to the LLM.",
    },
  ]}
/>

## Extended usage example

```typescript copy
await agent.getLLM({
  requestContext: new RequestContext(),
  model: openai("gpt-4"),
});
```

### Options parameters

<PropertiesTable
  content={[
    {
      name: "requestContext",
      type: "RequestContext",
      isOptional: true,
      defaultValue: "new RequestContext()",
      description:
        "Request Context for dependency injection and contextual information.",
    },
    {
      name: "model",
      type: "MastraLanguageModel | DynamicArgument<MastraLanguageModel>",
      isOptional: true,
      description:
        "Optional model override. If provided, this model will be used used instead of the agent's configured model.",
    },
  ]}
/>

## Related

- [Agents overview](/docs/v1/agents/overview)
- [Request Context](/docs/v1/server-db/request-context)
