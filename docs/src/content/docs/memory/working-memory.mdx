# Continuously Relevant Information

While [conversation history](./last-messages.mdx) and [semantic recall](./semantic-recall.mdx) help agents remember conversations, working memory allows them to maintain persistent information about users across all interactions. Think of it as the agent's active thoughts or scratchpad – the key information they keep available about the user or task, like how a person would naturally remember someone's name, preferences, or important details during a conversation. This feature is useful for maintaining preferences, user details, and ongoing state that should always be available to the agent.

## Quick Start

Here's a minimal example of setting up an agent with working memory:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";

// Create agent with working memory enabled
const agent = new Agent({
  name: "PersonalAssistant",
  instructions: "You are a helpful personal assistant.",
  model: openai("gpt-4o"),
  memory: new Memory({
    options: {
      workingMemory: {
        enabled: true,
        use: "tool-call", // Recommended setting
      },
    },
  }),
});
```

## When to Use Working Memory

Working memory is ideal for:

- Storing user preferences that should persist across conversations
- Maintaining state for ongoing tasks or processes
- Keeping important user details readily available
- Maintaining non-linear information that should always be "top of mind"

## How it Works

Working memory uses an unstructured text string that the agent is able to update over time, similar to a state store:

1. The agent receives a template defining what information to track
2. During conversations, the agent updates this information automatically
3. The working memory is injected into every conversation's context
4. Updates are handled invisibly to users through markdown blocks or tool calls

```text
        ┌────────────────────┐
        │  User Interaction  │
        └─────────┬──────────┘
                  ▼
  ┌────────────────────────────┐
  │      Context Window        │
  │    ───────────────         │
  │    System Instructions     │
  │    Working Memory          │
  │    Last Messages           │
  │    Current User Message    │
  └─────────────┬──────────────┘
                │ sent to
                ▼
        ┌────────────────┐
        │  LLM Provider  │
        └───────┬────────┘
                ▼
      ┌───────────────────────┐
      │    Agent Response     │
      │  with Memory Updates  │
      └─────────┬─────────────┘
                ▼
   ┌──────────────────────────┐
   │  Extract & Store Memory  │
   │         Updates          │
   └──────────┬───────────────┘
              ▼
  ┌────────────────────────────┐
  │   Persistent Storage Layer │
  │  (Stored in Memory Thread) │
  └─────────────┬──────────────┘
                ▼
      ┌───────────────────────┐
      │   Next Interaction    │
      │  (Includes Updated    │
      │   Working Memory)     │
      └───────────────────────┘
```

## Memory Templates

Templates guide the agent on what information to track and update in working memory. While a default template is used if none is provided, you'll typically want to define a custom template tailored to your agent's specific use case to ensure it remembers the most relevant information.

Here's an example of a custom template:

```typescript
const memory = new Memory({
  options: {
    workingMemory: {
      enabled: true,
      template: `# User Profile

## Preferences
- Theme: 
- Language: 

## Personal Info
- Name: 
- Timezone: 
`,
    },
  },
});
```

You may also need to include specific instructions in your agent's system prompt to ensure it properly maintains the information defined in your template.

### Designing Effective Templates

While a default template exists, crafting a custom template tailored to your agent's purpose significantly improves its ability to manage working memory effectively. Good templates are typically:

1.  **Structured**: Use Markdown headings (`#`, `##`), lists (`-`), and key-value pairs (`Key: Value`) to organize related information logically. This helps the agent parse and update specific pieces of data.
2.  **Comprehensive**: Include placeholders for all the key pieces of information you expect the agent to track (e.g., user name, preferences, task status, important entities).
3.  **Clear**: Use descriptive headings and field names so the agent (and you, when debugging) understands the purpose of each part.
4.  **Flexible**: Allow for storing multiple related items if necessary (e.g., a list of user goals, multiple contact persons).

**Example Template:**

```markdown
# User Profile

## Personal Info

- Name:
- Location:
- Timezone:

## Preferences

- Communication Style: [e.g., Formal, Casual]
- Project Goal:
- Key Deadlines:
  - [Deadline 1]: [Date]
  - [Deadline 2]: [Date]

## Session State

- Last Task Discussed:
- Open Questions:
  - [Question 1]
  - [Question 2]
```

Remember to instruct your agent on _how_ and _when_ to use this template in its system prompt.

## Update Modes

Working memory supports two update modes:

1.  **Text Stream Mode** (`text-stream`):

    - **How it works**: The agent includes working memory updates directly in its response stream using special markdown tags (e.g., `<working_memory>...</working_memory>`). Mastra extracts this content and updates the memory.
    - **Pros**: Simpler concept, might work well for basic updates.
    - **Cons**: Less reliable with some models, requires masking tags in the UI, not compatible with `toDataStream()`.
    - **Configuration**:
      ```typescript
      const memory = new Memory({
        options: {
          workingMemory: {
            enabled: true,
            use: "text-stream", // Current default, but will be deprecated
          },
        },
      });
      ```

2.  **Tool Call Mode** (`tool-call`):
    - **How it works**: The agent uses a dedicated internal tool (`updateWorkingMemory`) to explicitly update the working memory content.
    - **Pros**: More structured, compatible with `toDataStream()`, suitable for agents skilled with tools, recommended.
    - **Cons**: Slightly more complex interaction flow (involves tool calls).
    - **Configuration**:
      ```typescript
      const memory = new Memory({
        options: {
          workingMemory: {
            enabled: true,
            use: "tool-call", // Recommended as it will become the default in future
          },
        },
      });
      ```

**Recommendation**: Use `tool-call` mode for better reliability and compatibility, especially with streaming UIs. `text-stream` mode will eventually be deprecated.

### Handling Updates in Streams

When using `text-stream` mode, the agent's response stream will contain `<working_memory>` tags. To prevent these tags from being visible to users in your UI, you can use the `maskStreamTags` utility:

```typescript
import { maskStreamTags } from "@mastra/core/utils";

// Example of masking tags in text-stream mode
for await (const chunk of maskStreamTags(
  response.textStream,
  "working_memory", // The tag name to mask
)) {
  process.stdout.write(chunk); // Only user-visible text is processed
}
```

**Note**: Masking is **not** required when using `tool-call` mode, as updates happen via tool calls behind the scenes.

## Related Features

Working memory integrates with other memory features to enhance agent capabilities:

- **[Conversation History](./last-messages.mdx)**: For recent conversation context
- **[Recalling Relevant History](./semantic-recall.mdx)**: For finding relevant past information
- **[Memory Threads](./memory-threads.mdx)**: For managing conversation organization
- **[Token Management](./token-management.mdx)**: For optimizing memory token usage
