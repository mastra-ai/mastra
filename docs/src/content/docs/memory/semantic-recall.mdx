# Recalling Relevant History

Semantic recall enables agents to find relevant information from past messages using vector search instead of message recency. This helps agents maintain context across longer interactions when messages are no longer within the [conversation history](./getting-started.mdx#conversation-history-last-messages).

## How Semantic Recall Works

Semantic recall uses the newest user message to search for relevant past messages:

1. Every new message is converted into a vector representation (embedding).
2. These embeddings are stored in a vector database.
3. A vector query is made using the embeddings.
4. The most relevant messages and their surrounding context are added to the agent's context window in chronological message order.

## Minimal Quick Start Example

Semantic recall is enabled by default:

```typescript {9}
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";

const agent = new Agent({
  name: "SupportAgent",
  instructions: "You are a helpful support agent.",
  model: openai("gpt-4o"),
  memory: new Memory(),
});
```

## Configuration

The two main parameters that control semantic recall behavior are:

1. **topK**: How many semantically similar messages to retrieve
2. **messageRange**: How much surrounding context to include with each match

```typescript {5-6}
const agent = new Agent({
  memory: new Memory({
    options: {
      semanticRecall: {
        topK: 3, // Retrieve 3 most similar messages
        messageRange: 2, // Include 2 messages before and after each match
      },
    },
  }),
});
```

### Configuration Examples

Semantic recall relies on a [storage and vector db](/docs/reference/memory/Memory#parameters) to store messages and their embeddings, and an [embedder](/docs/reference/memory/Memory#embedder) to convert messages into embeddings.

```ts {3-5}
const agent = new Agent({
  memory: new Memory({
    storage,
    vector,
    embedder,
  }),
});
```

**Storage/vector code Examples**:

- [LibSQL](/examples/memory/memory-with-libsql)
- [Postgres](/examples/memory/memory-with-pg)
- [Upstash](/examples/memory/memory-with-upstash)

### Disabling Semantic Recall

There is a performance impact to using semantic recall. New messages are converted into embeddings and used to query a vector database before new messages are sent to the LLM.

Semantic recall is enabled by default but can be disabled when not needed:

```typescript {4}
const agent = new Agent({
  memory: new Memory({
    options: {
      semanticRecall: false,
    },
  }),
});
```

You might want to disable semantic recall in scenarios like:

- When [conversation history](./getting-started.mdx#conversation-history-last-messages) provide sufficient context for the current conversation.
- In performance-sensitive applications, like realtime two-way audio, where the added latency of creating embeddings and running vector queries is noticeable.

## Next Steps

Semantic recall works alongside other memory features:

- **[Working Memory](./working-memory.mdx)**: Stores persistent, structured information.
- **[Memory Processors](./memory-processors.mdx)**: Essential for managing token limits (`TokenLimiter`) and filtering content.
- **[Conversation History](./getting-started.mdx#conversation-history-last-messages)**: Provides the most recent messages (covered in Getting Started).

