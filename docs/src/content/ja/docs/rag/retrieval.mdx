---
title: "リトリーバル、セマンティック検索、リランキング | RAG | Mastra ドキュメント"
description: Mastra の RAG システムにおけるリトリーバル（セマンティック検索、フィルタリング、リランキング）に関するガイド。
---

import { Tabs } from "nextra/components";


## RAGシステムにおける検索

埋め込みを保存した後は、ユーザーの問い合わせに回答するために、関連するチャンクを取得する必要があります。

Mastraはセマンティック検索、フィルタリング、リランキングに対応しており、柔軟な検索オプションを提供します。

## 取得の仕組み

1. ユーザーのクエリは、ドキュメント埋め込みに使用したのと同じモデルで埋め込みに変換されます
2. この埋め込みを、ベクトル類似度を用いて保存済みの埋め込みと比較します
3. 最も類似したチャンクを取得し、必要に応じて次の処理を行えます:

- メタデータによるフィルタリング
- 関連性向上のための再ランク付け
- ナレッジグラフを用いた処理

## 基本的な取得

最もシンプルなアプローチは、セマンティック検索をそのまま用いる方法です。この方法では、ベクトル類似度に基づいて、クエリと意味的に近いチャンクを見つけます。

```ts showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { embed } from "ai";
import { PgVector } from "@mastra/pg";

// クエリを埋め込みベクトルに変換する
const { embedding } = await embed({
  value: "この記事の主なポイントは何ですか？",
  model: openai.embedding("text-embedding-3-small"),
});

// ベクターストアにクエリを実行する
const pgVector = new PgVector({
  connectionString: process.env.POSTGRES_CONNECTION_STRING,
});
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
});

// 結果を表示する
console.log(results);
```

結果にはテキスト内容と類似度スコアの両方が含まれます：

```ts showLineNumbers copy
[
  {
    text: "気候変動は重大な課題をもたらしています...",
    score: 0.89,
    metadata: { source: "article1.txt" },
  },
  {
    text: "気温の上昇は作物の収量に影響を及ぼしています...",
    score: 0.82,
    metadata: { source: "article1.txt" },
  },
  // ... さらに多くの結果
];
```

基本的なリトリーバル方法の使い方については、[Retrieve Results](../../examples/rag/query/retrieve-results.mdx) を参照してください。


## 高度な検索オプション

### メタデータのフィルタリング

メタデータフィールドに基づいて結果を絞り込み、検索対象を狭めます。これは、出典や時期が異なるドキュメントや、特定の属性を持つドキュメントを扱う場合に有用です。Mastra は、サポートされているすべてのベクトルストアで利用できる、統一的な MongoDB 風のクエリ構文を提供します。

利用可能な演算子や構文の詳細は、[Metadata Filters Reference](/reference/rag/metadata-filters) を参照してください。

基本的なフィルタリングの例:

```ts showLineNumbers copy
// シンプルな等価フィルタ
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    source: "article1.txt",
  },
});

// 数値比較
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    price: { $gt: 100 },
  },
});

// 複数条件
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    category: "electronics",
    price: { $lt: 1000 },
    inStock: true,
  },
});

// 配列操作
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    tags: { $in: ["sale", "new"] },
  },
});

// 論理演算子
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    $or: [{ category: "electronics" }, { category: "accessories" }],
    $and: [{ price: { $gt: 50 } }, { price: { $lt: 200 } }],
  },
});
```

メタデータ フィルタリングの一般的なユースケース:

* ドキュメントのソースまたは種類でフィルター
* 日付範囲でフィルター
* 特定のカテゴリやタグでフィルター
* 数値範囲（例：価格、評価）でフィルター
* 複数の条件を組み合わせて高精度にクエリ
* ドキュメントの属性（例：言語、著者）でフィルター

メタデータ フィルタリングの使い方の例については、[Hybrid Vector Search](../../examples/rag/query/hybrid-vector-search.mdx) を参照してください。


### ベクタークエリツール

エージェントにベクターデータベースへ直接クエリさせたい場合があります。ベクタークエリツールを使うと、エージェントが取得方針の判断を担い、ユーザーのニーズに対する理解に基づいて、セマンティック検索に加えて任意のフィルタリングやリランキングを組み合わせられます。

```ts showLineNumbers copy
const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
});
```

ツールを作成する際は、ツールの名称と説明に特に注意してください。これらは、エージェントがいつどのように検索・取得機能を使うべきかを理解する助けになります。たとえば、名称を &quot;SearchKnowledgeBase&quot;、説明を &quot;ドキュメント全体を検索して、Xというトピックに関する関連情報を見つけます。&quot; とすることができます。

これは次のような場合に特に有用です:

* エージェントが取得すべき情報を動的に判断する必要があるとき
* 取得プロセスに複雑な意思決定が伴うとき
* 文脈に応じて複数の取得戦略を組み合わせたいとき


#### データベース固有の設定

Vector Query Tool は、各種ベクトルストアの独自機能や最適化を活用できるデータベース固有の設定をサポートしています。

```ts showLineNumbers copy
// 名前空間を使用した Pinecone
const pineconeQueryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    pinecone: {
      namespace: "production"  // 環境ごとにデータを分離
    }
  }
});

// パフォーマンス調整を施した pgVector
const pgVectorQueryTool = createVectorQueryTool({
  vectorStoreName: "postgres",
  indexName: "embeddings", 
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    pgvector: {
      minScore: 0.7,    // 低品質な結果を除外
      ef: 200,          // HNSW の検索パラメータ
      probes: 10        // IVFFlat のプローブ数パラメータ
    }
  }
});

// 高度なフィルタリングを備えた Chroma
const chromaQueryTool = createVectorQueryTool({
  vectorStoreName: "chroma",
  indexName: "documents",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    chroma: {
      where: { "category": "technical" },
      whereDocument: { "$contains": "API" }
    }
  }
});

// テーブルを明示した LanceDB
const lanceQueryTool = createVectorQueryTool({
  vectorStoreName: "lance",
  indexName: "documents",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    lance: {
      tableName: "myVectors",     // 参照するテーブルを指定
      includeAllColumns: true     // すべてのメタデータ列を結果に含める
    }
  }
});
```

**主なメリット:**

* **Pinecone のネームスペース**: テナント、環境、データ種別ごとにベクトルを整理
* **pgVector の最適化**: ef/probes パラメータで検索精度と速度を調整
* **品質フィルタリング**: 最小類似度のしきい値を設定して結果の関連性を向上
* **LanceDB のテーブル**: データをテーブルに分けて整理性とパフォーマンスを向上
* **実行時の柔軟性**: コンテキストに応じて設定を動的に上書き

**一般的なユースケース:**

* Pinecone のネームスペースを用いたマルチテナントアプリケーション
* 高負荷環境でのパフォーマンス最適化
* 環境別の設定（dev/staging/prod）
* 品質基準を満たした検索結果
* エッジ展開向けの LanceDB を用いた埋め込み型・ファイルベースのベクトルストレージ

これらの設定は、実行時コンテキストを使用してランタイムに上書きすることもできます:

```ts showLineNumbers copy
import { RuntimeContext } from '@mastra/core/runtime-context';

const runtimeContext = new RuntimeContext();
runtimeContext.set('databaseConfig', {
  pinecone: {
    namespace: 'runtime-namespace'
  }
});

await pineconeQueryTool.execute({
  context: { queryText: 'search query' },
  mastra,
  runtimeContext
});
```

詳細な設定オプションや高度な使い方については、[Vector Query Tool Reference](/reference/tools/vector-query-tool)をご覧ください。


### ベクターストア向けプロンプト

ベクターストア向けプロンプトは、各ベクターデータベース実装におけるクエリパターンとフィルタリング機能を定義します。
フィルタリングを実装する際は、各ベクターストア実装で有効な演算子や構文を明示するため、エージェントの指示にこれらのプロンプトを含める必要があります。

{/* 
LLM CONTEXT: この Tabs コンポーネントは、各種データベースプロバイダー向けのベクターストア設定例を表示します。
各タブでは、該当するベクターストアに適したプロンプトを用いて RAG エージェントを設定する方法を示します。
タブでは、ストア固有のプロンプトをインポートし、エージェントの指示に追加するという一貫したパターンを示しています。
これにより、ユーザーは異なるベクターデータベースのバックエンドに対して、RAG エージェントを適切に設定する方法を理解できます。
プロバイダーには Pg Vector、Pinecone、Qdrant、Chroma、Astra、LibSQL、Upstash、Cloudflare、MongoDB、OpenSearch、S3 Vectors が含まれます。
*/}

<Tabs items={['Pg Vector', 'Pinecone', 'Qdrant', 'Chroma', 'Astra', 'LibSQL', 'Upstash', 'Cloudflare', 'MongoDB', 'OpenSearch', 'S3 Vectors']}>
  <Tabs.Tab>
    ```ts showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { PGVECTOR_PROMPT } from "@mastra/pg";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理し、回答は簡潔かつ関連性の高い内容にまとめてください。
      ${PGVECTOR_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { PINECONE_PROMPT } from "@mastra/pinecone";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理し、回答は簡潔かつ関連性の高い内容に構成してください。
      ${PINECONE_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { QDRANT_PROMPT } from "@mastra/qdrant";

    export const ragAgent = new Agent({
      name: 'RAGエージェント',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理してください。回答は簡潔で要点を押さえたものにしてください。
      ${QDRANT_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { CHROMA_PROMPT } from "@mastra/chroma";

    export const ragAgent = new Agent({
      name: 'RAG エージェント',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理してください。回答は簡潔で要点を押さえたものにしてください。
      ${CHROMA_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { ASTRA_PROMPT } from "@mastra/astra";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理してください。回答は簡潔で要点を押さえたものにしてください。
      ${ASTRA_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { LIBSQL_PROMPT } from "@mastra/libsql";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストに基づいてクエリを処理してください。回答は簡潔かつ適切な内容になるように構成してください。
      ${LIBSQL_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { UPSTASH_PROMPT } from "@mastra/upstash";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理してください。回答は簡潔かつ関連性の高い内容に構成してください。
      ${UPSTASH_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { VECTORIZE_PROMPT } from "@mastra/vectorize";

    export const ragAgent = new Agent({
      name: 'RAG エージェント',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理すること。回答は簡潔かつ関連性の高いものにすること。
      ${VECTORIZE_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { MONGODB_PROMPT } from "@mastra/mongodb";

    export const ragAgent = new Agent({
      name: 'RAG エージェント',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストを用いてクエリを処理してください。回答は簡潔かつ関連性の高い内容にまとめてください。
      ${MONGODB_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { OPENSEARCH_PROMPT } from "@mastra/opensearch";

    export const ragAgent = new Agent({
      name: 'RAG エージェント',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供されたコンテキストに基づいてクエリを処理してください。回答は簡潔で要点を押さえた内容にしてください。
      ${OPENSEARCH_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    ```ts filename="vector-store.ts" showLineNumbers copy
    import { openai } from '@ai-sdk/openai';
    import { S3VECTORS_PROMPT } from "@mastra/s3vectors";

    export const ragAgent = new Agent({
      name: 'RAG Agent',
      model: openai('gpt-4o-mini'),
      instructions: `
      提供された文脈を用いてクエリを処理してください。回答は簡潔かつ要点を押さえたものにしてください。
      ${S3VECTORS_PROMPT}
      `,
      tools: { vectorQueryTool },
    });
    ```
  </Tabs.Tab>
</Tabs>

### 再ランキング

初期のベクトル類似検索では、微妙な関連性を見落とすことがあります。再ランキングは計算コストは高いものの、次の点で結果を改善する、より高精度なアルゴリズムです。

* 語順や厳密一致を考慮する
* より洗練された関連性スコアリングを適用する
* クエリとドキュメント間のクロスアテンションと呼ばれる手法を用いる

再ランキングの使い方は次のとおりです。

```ts showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { 
  rerankWithScorer as rerank, 
  MastraAgentRelevanceScorer 
} from "@mastra/rag";

// ベクター検索で初期結果を取得
const initialResults = await pgVector.query({
  indexName: "embeddings",
  queryVector: queryEmbedding,
  topK: 10,
});

// 関連度スコアラーを作成
const relevanceProvider = new MastraAgentRelevanceScorer('relevance-scorer', openai("gpt-4o-mini"));

// 結果を再ランク付けする
const rerankedResults = await rerank({
  results: initialResults,
  query,
  provider: relevanceProvider,
  options: {
    topK: 10,
  },
);
```

> **注:** 再ランキングでセマンティック・スコアリングを正しく機能させるには、各結果の `metadata.text` フィールドにテキスト内容を含める必要があります。

Cohere や ZeroEntropy などの関連度スコア提供元も利用できます。

```ts showLineNumbers copy
const relevanceProvider = new CohereRelevanceScorer('rerank-v3.5');
```

```ts showLineNumbers copy
const relevanceProvider = new ZeroEntropyRelevanceScorer('zerank-1');
```

再ランク付けされた結果は、ベクトル類似度と意味理解を組み合わせて、検索の品質を高めます。

再ランク付けの詳細は、[rerank()](/reference/rag/rerankWithScorer) メソッドを参照してください。

再ランク付けメソッドの使用例は、[Re-ranking Results](../../examples/rag/rerank/rerank.mdx) を参照してください。


### グラフベースのリトリーバル

複雑な関係をもつドキュメントでは、グラフベースのリトリーバルによりチャンク間のつながりをたどることができます。これは次のような場合に有効です:

* 情報が複数のドキュメントにまたがっている
* ドキュメント同士が互いに参照している
* 完全な回答を得るために関係を辿る必要がある

セットアップ例:

```ts showLineNumbers copy
const graphQueryTool = createGraphQueryTool({
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
  graphOptions: {
    threshold: 0.7,
  },
});
```

グラフベースの検索の詳細は、[GraphRAG](/reference/rag/graph-rag) クラスと [createGraphQueryTool()](/reference/tools/graph-rag-tool) 関数を参照してください。

グラフベースの検索手法の使い方の例は、[Graph-based Retrieval](../../examples/rag/usage/graph-rag.mdx) の例をご覧ください。
