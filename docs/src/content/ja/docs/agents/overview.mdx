---
title: "エージェント概要 | Agents | Mastra ドキュメント"
description: Mastra におけるエージェントの概要。エージェントの機能や、ツール、ワークフロー、外部システムとの連携方法について説明します。
---

import { Steps, Callout, Tabs } from "nextra/components";


# エージェントの使用

エージェントは LLM とツールを活用して、オープンエンドなタスクを解決します。目標を踏まえて推論し、使うツールを選び、会話の記憶を保持し、モデルが最終的な回答を出すか任意の停止条件を満たすまで内部で反復します。エージェントは UI で表示したりプログラムから処理したりできる構造化された応答を生成します。エージェントを単体で使うことも、ワークフローやエージェントネットワークに組み込むこともできます。

![エージェントの概要](/image/agents/agents-overview.jpg)

> **📹 視聴**:  → エージェントの紹介とワークフローとの比較 [YouTube（7分）](https://youtu.be/0jg2g3sNvgw)

## エージェントのセットアップ

<Tabs items={["Mastra model router", "Vercel AI SDK"]}>
  <Tabs.Tab>
    <Steps>
### 依存関係をインストールする [#install-dependencies-mastra-router]

Mastra のコアパッケージをプロジェクトに追加します：

```bash
npm install @mastra/core
```

### API キーを設定する [#set-api-key-mastra-router]

Mastra のモデルルーターは、選択したプロバイダー向けの環境変数を自動検出します。OpenAI の場合は `OPENAI_API_KEY` を設定します：

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

> Mastra は 600 以上のモデルに対応しています。全リストは[こちら](/models)からご確認ください。

### エージェントを作成する [#creating-an-agent-mastra-router]

システムの `instructions` と `model` を指定して `Agent` クラスをインスタンス化し、エージェントを作成します：

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { Agent } from "@mastra/core/agent";

export const testAgent = new Agent({
  name: "test-agent",
  instructions: "You are a helpful assistant.",
  model: "openai/gpt-4o-mini"
});
```
    </Steps>
  </Tabs.Tab>
  <Tabs.Tab>
    <Steps>

### 依存関係をインストールする [#install-dependencies-ai-sdk]

使用する Vercel AI SDK のプロバイダーに合わせて、Mastra のコアパッケージを追加します：

```bash
npm install @mastra/core @ai-sdk/openai
```

### API キーを設定する [#set-api-key-ai-sdk]

利用するプロバイダーに対応する環境変数を設定します。AI SDK 経由で OpenAI を使う場合：

```bash filename=".env" copy
OPENAI_API_KEY=<your-api-key>
```

> 追加の設定項目は、Vercel AI SDK ドキュメントの [AI SDK Providers](https://ai-sdk.dev/providers/ai-sdk-providers) を参照してください。

### エージェントを作成する [#creating-an-agent-ai-sdk]

Mastra でエージェントを作成するには `Agent` クラスを使用します。各エージェントには、動作を定義する `instructions` と、LLM プロバイダーとモデルを指定する `model` パラメータが必要です。Vercel AI SDK を使う場合は、エージェントの `model` フィールドにクライアントを渡します：

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";

export const testAgent = new Agent({
  name: "test-agent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o-mini")
});
```
    </Steps>
  </Tabs.Tab>
</Tabs>

#### 命令の形式

命令は、エージェントの振る舞い・人格・能力を定義します。
これは、エージェントの中核となるアイデンティティと専門性を確立するシステムレベルのプロンプトです。

柔軟性を高めるため、命令は複数の形式で提供できます。以下の例は、サポートされている形式を示します。

```typescript copy
// 文字列（最も一般的）
instructions: "あなたは親切なアシスタントです。"

// 文字列の配列
instructions: [
  "あなたは親切なアシスタントです。",
  "常に丁寧に対応してください。",
  "詳細な回答を提供してください。"
]

// システムメッセージの配列
instructions: [
  { role: "system", content: "あなたは親切なアシスタントです。" },
  { role: "system", content: "あなたはTypeScriptの専門知識を持っています。" }
]
```


#### プロバイダー固有のオプション

各モデルプロバイダーでは、プロンプトのキャッシュや推論設定など、いくつか異なるオプションも利用できます。これらを管理するために `providerOptions` フラグを用意しています。`providerOptions` はインストラクション単位で設定でき、各システムインストラクション／プロンプトごとに異なるキャッシュ戦略を指定できます。

```typescript copy
// プロバイダー固有のオプション(例:キャッシング、推論)
instructions: {
  role: "system",
  content:
    "あなたは熟練したコードレビュアーです。バグ、パフォーマンスの問題、ベストプラクティスについてコードを分析してください。",
  providerOptions: {
    openai: { reasoningEffort: "high" },        // OpenAIの推論モデル
    anthropic: { cacheControl: { type: "ephemeral" } }  // Anthropicのプロンプトキャッシング
  }
}
```

> 詳細は [Agent リファレンス ドキュメント](../../reference/agents/agent.mdx) を参照してください。


### エージェントの登録

アプリケーション全体で利用できるように、Mastra インスタンスにエージェントを登録します。登録すると、ワークフローやツール、他のエージェントから呼び出せるようになり、メモリ、ロギング、オブザーバビリティ機能などの共有リソースにもアクセスできます。

```typescript {6} showLineNumbers filename="src/mastra/index.ts" copy
import { Mastra } from "@mastra/core/mastra";
import { testAgent } from './agents/test-agent';

export const mastra = new Mastra({
  // ...
  agents: { testAgent },
});
```


## エージェントの参照

ワークフローのステップ、ツール、Mastra Client、またはコマンドラインからエージェントを呼び出せます。セットアップに応じて、`mastra` または `mastraClient` インスタンスで `.getAgent()` を呼び出し、参照を取得します。

```typescript showLineNumbers copy
const testAgent = mastra.getAgent("testAgent");
```

<Callout type="info">
  <p>
    `mastra.getAgent()` の使用を、直接のインポートよりも推奨します。Mastra インスタンスの設定（logger、telemetry、storage、登録済みエージェント、ベクトルストア）へアクセスできるためです。
  </p>
</Callout>

> 詳細は [Calling agents](../../examples/agents/calling-agents.mdx) を参照してください。


## レスポンスの生成

エージェントは結果を返す方法として、返却前に出力をすべて生成してから返すか、トークンをリアルタイムにストリーミングするかの2通りがあります。ユースケースに合う方法を選んでください。短い内部向けレスポンスやデバッグには生成を、エンドユーザーへできるだけ早く画面を届けるにはストリーミングを使います。

<Tabs items={["Generate", "Stream"]}>
  <Tabs.Tab>
シンプルなプロンプトには単一の文字列を、複数のコンテキストを渡す場合は文字列の配列を、または `role` と `content` を持つメッセージオブジェクトの配列を渡します。

（`role` は各メッセージの話者を示します。一般的なロールは、人間の入力を表す `user`、エージェントの応答を表す `assistant`、指示を表す `system` です。）

```typescript showLineNumbers copy
const response = await testAgent.generate([
  { role: "user", content: "Help me organize my day" },
  { role: "user", content: "My day starts at 9am and finishes at 5.30pm" },
  { role: "user", content: "I take lunch between 12:30 and 13:30" },
  { role: "user", content: "I have meetings Monday to Friday between 10:30 and 11:30" }
]);

console.log(response.text);
```
  </Tabs.Tab>
  <Tabs.Tab>
シンプルなプロンプトには単一の文字列を、複数のコンテキストを渡す場合は文字列の配列を、または `role` と `content` を持つメッセージオブジェクトの配列を渡します。

（`role` は各メッセージの話者を示します。一般的なロールは、人間の入力を表す `user`、エージェントの応答を表す `assistant`、指示を表す `system` です。）

```typescript showLineNumbers copy
const stream = await testAgent.stream([
  { role: "user", content: "Help me organize my day" },
  { role: "user", content: "My day starts at 9am and finishes at 5.30pm" },
  { role: "user", content: "I take lunch between 12:30 and 13:30" },
  { role: "user", content: "I have meetings Monday to Friday between 10:30 and 11:30" }
]);

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### `onFinish()` を使った完了処理

レスポンスをストリーミングする場合、`onFinish()` コールバックは LLM がレスポンスの生成を終え、すべてのツール実行が完了した後に実行されます。
これにより、最終的な `text`、実行の `steps`、`finishReason`、トークンの `usage` 統計、そして監視やログ記録に役立つその他のメタデータが提供されます。

```typescript showLineNumbers copy
const stream = await testAgent.stream("Help me organize my day", {
  onFinish: ({ steps, text, finishReason, usage }) => {
    console.log({ steps, text, finishReason, usage });
  }
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```
  </Tabs.Tab>
</Tabs>

> 詳細は [.generate()](../../reference/agents/generate.mdx) または [.stream()](../../reference/agents/stream.mdx) を参照してください。

## 構造化出力

エージェントは、期待する出力を [Zod](https://zod.dev/) または [JSON Schema](https://json-schema.org/) で定義することで、構造化された型安全なデータを返せます。TypeScript のサポートと開発体験の観点からは Zod を推奨します。パース済みの結果は `response.object` で参照でき、検証済みかつ型付けされたデータをそのまま扱えます。

### Zod を使う

[Zod](https://zod.dev/) を使って `output` のスキーマを定義します：

```typescript showLineNumbers copy
import { z } from "zod";

const response = await testAgent.generate(
  [
    {
      role: "system",
      content: "以下のテキストの要約とキーワードを提供してください:"
    },
    {
      role: "user",
      content: "サル、アイスクリーム、ボート"
    }
  ],
  {
    structuredOutput: {
      schema: z.object({
        summary: z.string(),
        keywords: z.array(z.string())
      })
    },
  }
);

console.log(response.object);
```


### ツール呼び出しを利用する

`model` プロパティを設定して、エージェントがツール呼び出しを伴う複数段階の LLM 呼び出しを実行できるようにします。

```typescript showLineNumbers copy
import { z } from "zod";

const response = await testAgentWithTools.generate(
  [
    {
      role: "system",
      content: "次のテキストの要約とキーワードを提供してください:"
    },
    {
      role: "user",
      content: "テストツールを使用して結果を教えてください"
    }
  ],
  {
    structuredOutput: {
      schema: z.object({
        summary: z.string(),
        keywords: z.array(z.string())
      }),
      model: "openai/gpt-4o"
    },
  }
);

console.log(response.object);
console.log(response.toolResults)
```


### レスポンス形式

デフォルトでは、`structuredOutput` はスキーマをモデルプロバイダーに渡すために `response_format` を使用します。モデルプロバイダーが `response_format` をネイティブにサポートしていない場合、エラーになったり、期待した結果が得られない可能性があります。同じモデルを使い続けるには、`jsonPromptInjection` を使用してレスポンス形式をバイパスし、システムプロンプトメッセージを注入して、モデルに構造化出力を返すよう促してください。

```typescript showLineNumbers copy
import { z } from "zod";

const response = await testAgentThatDoesntSupportStructuredOutput.generate(
  [
    {
      role: "system",
      content: "次のテキストの要約とキーワードを提供してください:"
    },
    {
      role: "user",
      content: "サル、アイスクリーム、ボート"
    }
  ],
  {
    structuredOutput: {
      schema: z.object({
        summary: z.string(),
        keywords: z.array(z.string())
      }),
      jsonPromptInjection: true
    },
  }
);

console.log(response.object);
```


## 画像の扱い方

エージェントは、画像の視覚的な内容と内部のテキストの両方を処理し、画像を分析して説明できます。画像分析を有効にするには、`content` 配列に `type: 'image'` と画像のURLを含むオブジェクトを渡してください。画像コンテンツにテキストのプロンプトを組み合わせることで、エージェントの分析を誘導できます。

```typescript showLineNumbers copy
const response = await testAgent.generate([
  {
    role: "user",
    content: [
      {
        type: "image",
        image: "https://placebear.com/cache/395-205.jpg",
        mimeType: "image/jpeg"
      },
      {
        type: "text",
        text: "画像を詳しく説明し、画像内のすべてのテキストを抽出してください。"
      }
    ]
  }
]);

console.log(response.text);
```

ツールの作成と設定に関する詳しいガイドは、[Tools Overview](../tools-mcp/overview.mdx) ページをご覧ください。


### `maxSteps` の使用

`maxSteps` パラメータは、エージェントが行える連続的な LLM 呼び出しの最大回数を制御します。各ステップには、応答の生成、ツール呼び出しの実行、結果の処理が含まれます。ステップ数を制限することで、無限ループの防止、レイテンシの低減、ツールを使用するエージェントのトークン使用量の管理に役立ちます。デフォルトは 1 ですが、増やすこともできます:

```typescript showLineNumbers copy
const response = await testAgent.generate("私の一日を整理するのを手伝って", {
  maxSteps: 5
});

console.log(response.text);
```


### `onStepFinish` の使用

`onStepFinish` コールバックを使うと、複数ステップの処理の進行状況を監視できます。デバッグやユーザーへの進捗通知に便利です。

`onStepFinish` は、ストリーミング中、または構造化されていない出力でテキストを生成している場合にのみ利用できます。

```typescript showLineNumbers copy
const response = await testAgent.generate("今日の予定を整理するのを手伝って", {
  onStepFinish: ({ text, toolCalls, toolResults, finishReason, usage }) => {
    console.log({ text, toolCalls, toolResults, finishReason, usage });
  }
});
```


## ツールの使用

エージェントはツールを使うことで単なる言語生成を超え、外部の API やサービスと構造化されたやり取りが可能になります。ツールによって、エージェントはデータにアクセスし、明確に定義された操作を、信頼性が高く再現性のある方法で実行できます。

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers
export const testAgent = new Agent({
  // ...
  tools: { testTool }
});
```

> 詳細については、[Using Tools](./using-tools.mdx) をご覧ください。


## `RuntimeContext` の使用

`RuntimeContext` を使うと、リクエストごとの値にアクセスできます。これにより、リクエストのコンテキストに応じて挙動を条件付きで調整できます。

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers
export type UserTier = {
  "user-tier": "enterprise" | "pro";
};

export const testAgent = new Agent({
  // ...
  model: ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier") as UserTier["user-tier"];

    return userTier === "enterprise"
      ? openai("gpt-4o-mini")
      : openai("gpt-4.1-nano");
  }
});
```

> 詳しくは [Runtime Context](../server-db/runtime-context.mdx) をご覧ください。


## Mastra Playground でのテスト

Mastra の[Playground](../server-db/local-dev-playground.mdx)を使って、さまざまなメッセージでエージェントをテストし、ツール呼び出しやレスポンスを確認し、エージェントの動作をデバッグします。

## 関連項目

- [ツールの使い方](./using-tools.mdx)
- [エージェントメモリ](./agent-memory.mdx)
- [ランタイムコンテキスト](../../examples/agents/runtime-context.mdx)
- [エージェントの呼び出し](../../examples/agents/calling-agents.mdx)