---
title: Mastra の音声認識（Speech-to-Text, STT） | Mastra ドキュメント
description: Mastra の音声認識（Speech-to-Text）機能の概要。設定、使用方法、音声プロバイダーとの連携について解説します。
---

# 音声認識（STT）

Mastra の音声認識（STT）は、複数のサービスプロバイダーに対応し、音声入力をテキストに変換するための標準化インターフェースを提供します。
STT は、人間の音声に反応する音声対応アプリケーションの構築を支援し、ハンズフリー操作、障害のあるユーザーのアクセシビリティ向上、より自然な人間とコンピューターのインターフェースを実現します。

## 設定

Mastra で STT を利用するには、音声プロバイダーを初期化する際に `listeningModel` を指定します。これには次のようなパラメータが含まれます:

* **`name`**: 使用する STT モデル名。
* **`apiKey`**: 認証用 API キー。
* **プロバイダー固有のオプション**: 利用する音声プロバイダーで必要/サポートされる追加オプション。

**注意**: これらのパラメータはすべて任意です。使用するプロバイダーに応じて、音声プロバイダーが提供するデフォルト設定をそのまま利用できます。

```typescript
const voice = new OpenAIVoice({
  listeningModel: {
    name: "whisper-1",
    apiKey: process.env.OPENAI_API_KEY,
  },
});

// 既定の設定を使用する場合、設定は次のように簡略化できます:
const voice = new OpenAIVoice();
```


## 利用可能なプロバイダー

Mastra は複数の Speech-to-Text プロバイダーをサポートしており、それぞれに固有の機能と強みがあります。

* [**OpenAI**](/reference/voice/openai/) - Whisper モデルによる高精度な文字起こし
* [**Azure**](/reference/voice/azure/) - 企業向けの高い信頼性を備えた Microsoft の音声認識
* [**ElevenLabs**](/reference/voice/elevenlabs/) - 多言語対応の高度な音声認識
* [**Google**](/reference/voice/google/) - 幅広い言語をサポートする Google の音声認識
* [**Cloudflare**](/reference/voice/cloudflare/) - 低レイテンシ用途向けのエッジ最適化音声認識
* [**Deepgram**](/reference/voice/deepgram/) - 多様なアクセントに高精度で対応する AI 搭載の音声認識
* [**Sarvam**](/reference/voice/sarvam/) - インド系言語とアクセントに特化

各プロバイダーは、必要に応じてインストールできる個別パッケージとして提供されています。

```bash
pnpm add @mastra/voice-openai  # OpenAI の例
```


## Listen メソッドの使用

STT の主要なメソッドは `listen()` で、音声をテキストに変換します。使い方は次のとおりです。

```typescript
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { OpenAIVoice } from "@mastra/voice-openai";
import { getMicrophoneStream } from "@mastra/node-audio";

const voice = new OpenAIVoice();

const agent = new Agent({
  name: "Voice Agent",
  instructions:
    "あなたは、ユーザーの入力に基づいて推薦を行う音声アシスタントです。",
  model: openai("gpt-4o"),
  voice,
});

const audioStream = getMicrophoneStream(); // この関数が音声入力を取得すると仮定

const transcript = await agent.voice.listen(audioStream, {
  filetype: "m4a", // オプション: 音声ファイルの種類を指定
});

console.log(`ユーザーの発言: ${transcript}`);

const { text } = await agent.generate(
  `ユーザーの発言に基づき、推奨を提示してください: ${transcript}`,
);

console.log(`推奨: ${text}`);
```

エージェントでの STT の使い方は、[Adding Voice to Agents](../agents/adding-voice.mdx) のドキュメントをご参照ください。
