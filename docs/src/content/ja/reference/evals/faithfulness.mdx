---
title: "リファレンス: Faithfulness | 指標 | 評価 | Mastra ドキュメント"
description: Mastra における Faithfulness 指標のドキュメント。提供されたコンテキストに照らして、LLM の出力の事実的正確性を評価します。
---

import { ScorerCallout } from '@/components/scorer-callout'


# FaithfulnessMetric リファレンス

<ScorerCallout />

Mastra の `FaithfulnessMetric` は、提供されたコンテキストに対して LLM の出力がどれだけ事実に忠実かを評価します。出力から主張を抽出し、それらをコンテキストと照合して検証するため、RAG パイプラインの応答の信頼性を測定するうえで不可欠です。

## 基本的な使い方

```typescript
import { openai } from "@ai-sdk/openai";
import { FaithfulnessMetric } from "@mastra/evals/llm";

// 評価用にモデルを設定する
const model = openai("gpt-4o-mini");

const metric = new FaithfulnessMetric(model, {
  context: [
    "その会社は1995年に設立されました。",
    "現在は約450〜550人を雇用しています。",
  ],
});

const result = await metric.measure(
  "その会社について教えてください。",
  "その会社は1995年に設立され、従業員数は500人です。",
);

console.log(result.score); // 1.0
console.log(result.info.reason); // "すべての記述はコンテキストによって裏付けられています。"
```


## コンストラクターのパラメーター

<PropertiesTable
  content={[
    {
      name: "model",
      type: "LanguageModel",
      description: "忠実性評価に使用するモデルの設定。",
      isOptional: false,
    },
    {
      name: "options",
      type: "FaithfulnessMetricOptions",
      description: "このメトリクスの構成用の追加オプション。",
      isOptional: false,
    },
  ]}
/>

### FaithfulnessMetricOptions

<PropertiesTable
  content={[
    {
      name: "scale",
      type: "number",
      description:
        "スコアの最大値。最終的なスコアはこの尺度に正規化されます。",
      isOptional: false,
      defaultValue: "1",
    },
    {
      name: "context",
      type: "string[]",
      description:
        "出力の主張を検証するために照合されるコンテキストチャンクの配列。",
      isOptional: false,
    },
  ]}
/>

## measure() のパラメータ

<PropertiesTable
  content={[
    {
      name: "input",
      type: "string",
      description: "LLM に与えられた元のクエリまたはプロンプト。",
      isOptional: false,
    },
    {
      name: "output",
      type: "string",
      description: "忠実性を評価する対象となる LLM の応答。",
      isOptional: false,
    },
  ]}
/>

## 戻り値

<PropertiesTable
  content={[
    {
      name: "score",
      type: "number",
      description:
        "0 から設定済みスケールまでの数値で、コンテキストによって裏付けられた主張の割合を表します。",
    },
    {
      name: "info",
      type: "object",
      description: "スコアの根拠を含むオブジェクト",
      properties: [
        {
          type: "string",
          parameters: [
            {
              name: "reason",
              type: "string",
              description:
                "どの主張が支持・矛盾・不確かと判断されたかを含む、スコアの詳細な説明。",
            },
          ],
        },
      ],
    },
  ]}
/>

## スコアリングの詳細

この指標は、与えられたコンテキストに照らして主張を検証し、その結果に基づいて忠実性を評価します。

### スコアリングプロセス

1. 主張とコンテキストを分析:

   - すべての主張（事実・推測を含む）を抽出
   - 各主張をコンテキストに照らして検証
   - 次の3つの判定のいずれかを付与:
     - "yes" - コンテキストにより主張が裏付けられる
     - "no" - コンテキストと主張が矛盾する
     - "unsure" - 主張は検証不能

2. 忠実性スコアを算出:
   - 裏付けられた主張の数を数える
   - 総主張数で割る
   - 設定された範囲にスケーリングする

最終スコア: `(supported_claims / total_claims) * scale`

### スコアの解釈

（スケールは0から。デフォルトは0〜1）

- 1.0: すべての主張が文脈で裏付けられている
- 0.7〜0.9: ほとんどの主張が裏付けられており、検証不能なものは少数
- 0.4〜0.6: 一部に矛盾が見られるなど、裏付けはまちまち
- 0.1〜0.3: 裏付けは限定的で、矛盾が多い
- 0.0: 裏付けられた主張はない

## 応用例

```typescript
import { openai } from "@ai-sdk/openai";
import { FaithfulnessMetric } from "@mastra/evals/llm";

// 評価用にモデルを設定
const model = openai("gpt-4o-mini");

const metric = new FaithfulnessMetric(model, {
  context: [
    "その会社の従業員数は2020年に100人だった。",
    "現在の従業員数は約500人である。",
  ],
});

// 異なる種類の主張を含む例
const result = await metric.measure(
  "その会社の成長はどのような状況ですか？",
  "その会社は2020年の100人から現在は500人へと増加しており、来年までに1000人へ拡大する可能性がある。",
);

// 出力例:
// {
//   score: 0.67,
//   info: {
//     reason: "スコアが0.67であるのは、2つの主張（2020年の従業員数100人と現在の従業員数500人）がコンテキストで裏付けられる一方で、
//           将来の拡大に関する主張はコンテキストで検証できないため不確実と判断されたためである。"
//           while the future expansion claim is marked as unsure as it cannot
//           be verified against the context."
//   }
// }
```


### 関連項目

- [回答関連性メトリック](./answer-relevancy)
- [幻覚（ハルシネーション）メトリック](./hallucination)
- [コンテキスト関連性メトリック](./context-relevancy)