---
title: "リファレンス: Google Gemini Live Voice | 音声プロバイダー | Mastra ドキュメント"
description: "GeminiLiveVoice クラスのドキュメント。Google の Gemini Live API を利用し、Gemini API と Vertex AI の両方に対応したリアルタイムのマルチモーダル音声対話を提供します。"
---

# Google Gemini Live Voice

GeminiLiveVoice クラスは、Google の Gemini Live API を用いてリアルタイムの音声対話を実現します。双方向の音声ストリーミング、ツールの呼び出し、セッション管理に対応し、標準的な Google API と Vertex AI のいずれの認証方式も利用できます。

## 使い方の例

```typescript
import { GeminiLiveVoice } from "@mastra/voice-google-gemini-live";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";

// Gemini API で初期化（API キーを使用）
const voice = new GeminiLiveVoice({
  apiKey: process.env.GOOGLE_API_KEY, // Gemini API に必須
  model: "gemini-2.0-flash-exp",
  speaker: "Puck", // デフォルトのボイス
  debug: true,
});

// または Vertex AI で初期化（OAuth を使用）
const voiceWithVertexAI = new GeminiLiveVoice({
  vertexAI: true,
  project: "your-gcp-project",
  location: "us-central1",
  serviceAccountKeyFile: "/path/to/service-account.json",
  model: "gemini-2.0-flash-exp",
  speaker: "Puck",
});

// もしくは VoiceConfig パターンを使用（他プロバイダーとの一貫性のため推奨）
const voiceWithConfig = new GeminiLiveVoice({
  speechModel: {
    name: "gemini-2.0-flash-exp",
    apiKey: process.env.GOOGLE_API_KEY,
  },
  speaker: "Puck",
  realtimeConfig: {
    model: "gemini-2.0-flash-exp",
    apiKey: process.env.GOOGLE_API_KEY,
    options: {
      debug: true,
      sessionConfig: {
        interrupts: { enabled: true },
      },
    },
  },
});

// 接続を確立（他のメソッドを使用する前に必須）
await voice.connect();

// イベントリスナーを設定
voice.on("speaker", (audioStream) => {
  // オーディオストリームを処理（NodeJS.ReadableStream）
  playAudio(audioStream);
});

voice.on("writing", ({ text, role }) => {
  // 書き起こしテキストを処理
  console.log(`${role}: ${text}`);
});

voice.on("turnComplete", ({ timestamp }) => {
  // ターン完了を処理
  console.log("ターン完了時刻:", timestamp);
});

// テキスト読み上げ
await voice.speak("こんにちは。本日どのようにお手伝いできますか？", {
  speaker: "Charon", // 既定のボイスを上書き
  responseModalities: ["AUDIO", "TEXT"],
});

// 音声入力を処理
const microphoneStream = getMicrophoneStream();
await voice.send(microphoneStream);

// セッション設定を更新
await voice.updateSessionConfig({
  speaker: "Kore",
  instructions: "回答はより簡潔にしてください",
});

// 終了時は切断
await voice.disconnect();
// または同期ラッパーを使用
voice.close();
```


## 設定

### コンストラクターオプション

<PropertiesTable
  content={[
    {
      name: "apiKey",
      type: "string",
      description:
        "Gemini API 認証に使用する Google の API キー。Vertex AI を使用しない場合は必須。",
      isOptional: true,
    },
    {
      name: "model",
      type: "GeminiVoiceModel",
      description: "リアルタイム音声対話に使用するモデル ID。",
      isOptional: true,
      defaultValue: "'gemini-2.0-flash-exp'",
    },
    {
      name: "speaker",
      type: "GeminiVoiceName",
      description: "音声合成のデフォルト音声 ID。",
      isOptional: true,
      defaultValue: "'Puck'",
    },
    {
      name: "vertexAI",
      type: "boolean",
      description: "認証に Gemini API の代わりに Vertex AI を使用します。",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "project",
      type: "string",
      description: "Google Cloud のプロジェクト ID（Vertex AI で必須）。",
      isOptional: true,
    },
    {
      name: "location",
      type: "string",
      description: "Vertex AI 用の Google Cloud リージョン。",
      isOptional: true,
      defaultValue: "'us-central1'",
    },
    {
      name: "serviceAccountKeyFile",
      type: "string",
      description:
        "Vertex AI 認証用のサービス アカウント JSON キー ファイルへのパス。",
      isOptional: true,
    },
    {
      name: "serviceAccountEmail",
      type: "string",
      description:
        "なりすまし用のサービス アカウントのメールアドレス（キー ファイルの代替）。",
      isOptional: true,
    },
    {
      name: "instructions",
      type: "string",
      description: "モデルへのシステム指示。",
      isOptional: true,
    },
    {
      name: "sessionConfig",
      type: "GeminiSessionConfig",
      description: "割り込みやコンテキスト設定を含むセッション設定。",
      isOptional: true,
    },
    {
      name: "debug",
      type: "boolean",
      description: "トラブルシューティング用にデバッグ ログ出力を有効化します。",
      isOptional: true,
      defaultValue: "false",
    },
  ]}
/>

### セッション設定

<PropertiesTable
  content={[
    {
      name: "interrupts",
      type: "object",
      description: "割り込み処理の構成。",
      isOptional: true,
    },
    {
      name: "interrupts.enabled",
      type: "boolean",
      description: "割り込み処理を有効にするかどうか。",
      isOptional: true,
      defaultValue: "true",
    },
    {
      name: "interrupts.allowUserInterruption",
      type: "boolean",
      description: "ユーザーがモデルの応答を中断できるようにするかどうか。",
      isOptional: true,
      defaultValue: "true",
    },
    {
      name: "contextCompression",
      type: "boolean",
      description: "自動コンテキスト圧縮を有効にするかどうか。",
      isOptional: true,
      defaultValue: "false",
    },
  ]}
/>

## メソッド

### connect()

Gemini Live API への接続を確立します。speak、listen、または send メソッドを使用する前に呼び出す必要があります。

<PropertiesTable
  content={[
    {
      name: "runtimeContext",
      type: "object",
      description: "接続時の任意の実行時コンテキスト。",
      isOptional: true,
    },
    {
      name: "returns",
      type: "Promise<void>",
      description: "接続が確立されると解決される Promise。",
    },
  ]}
/>

### speak()

テキストを音声に変換してモデルに送信します。入力は文字列または読み取り可能なストリームを受け付けます。

<PropertiesTable
  content={[
    {
      name: "input",
      type: "string | NodeJS.ReadableStream",
      description: "音声に変換するテキストまたはテキストのストリーム。",
      isOptional: false,
    },
    {
      name: "options",
      type: "GeminiLiveVoiceOptions",
      description: "任意の音声設定。",
      isOptional: true,
    },
    {
      name: "options.speaker",
      type: "GeminiVoiceName",
      description: "この音声リクエストに使用する音声 ID。",
      isOptional: true,
      defaultValue: "コンストラクタで指定された speaker の値",
    },
    {
      name: "options.languageCode",
      type: "string",
      description: "レスポンスの言語コード。",
      isOptional: true,
    },
    {
      name: "options.responseModalities",
      type: "('AUDIO' | 'TEXT')[]",
      description: "モデルから受け取るレスポンスのモダリティ。",
      isOptional: true,
      defaultValue: "['AUDIO', 'TEXT']",
    },
  ]}
/>

戻り値: `Promise<void>`（レスポンスは `speaker` および `writing` イベントで発行されます）

### listen()

音声認識のための音声入力を処理します。読み取り可能な音声データのストリームを受け取り、文字起こしされたテキストを返します。

<PropertiesTable
  content={[
    {
      name: "audioStream",
      type: "NodeJS.ReadableStream",
      description: "文字起こし対象の音声ストリーム。",
      isOptional: false,
    },
    {
      name: "options",
      type: "GeminiLiveVoiceOptions",
      description: "オプションのリスニング設定。",
      isOptional: true,
    },
  ]}
/>

戻り値: `Promise<string>` - 文字起こしされたテキスト

### send()

ライブのマイク入力など、連続的な音声ストリーミングのシナリオで、音声データをリアルタイムに Gemini サービスへストリーミングします。

<PropertiesTable
  content={[
    {
      name: "audioData",
      type: "NodeJS.ReadableStream | Int16Array",
      description: "サービスに送信する音声ストリームまたはバッファ。",
      isOptional: false,
    },
  ]}
/>

Returns: `Promise<void>`

### updateSessionConfig()

セッション設定を動的に更新します。音声設定やスピーカー選択、その他のランタイム設定の変更に使用できます。

<PropertiesTable
  content={[
    {
      name: "config",
      type: "Partial<GeminiLiveVoiceConfig>",
      description: "適用する設定の更新内容。",
      isOptional: false,
    },
  ]}
/>

戻り値: `Promise<void>`

### addTools()

音声インスタンスにツールのセットを追加します。ツールを使うと、モデルは会話中に追加のアクションを実行できます。GeminiLiveVoice を Agent に追加すると、Agent に設定されたツールは自動的に音声インターフェースでも利用可能になります。

<PropertiesTable
  content={[
    {
      name: "tools",
      type: "ToolsInput",
      description: "適用するツールの設定。",
      isOptional: false,
    },
  ]}
/>

Returns: `void`

### addInstructions()

モデルに対するシステム指示を追加または更新します。

<PropertiesTable
  content={[
    {
      name: "instructions",
      type: "string",
      description: "設定するシステム指示。",
      isOptional: true,
    },
  ]}
/>

戻り値: `void`

### answer()

モデルからの応答を起動します。このメソッドは、エージェントと統合された場合に主に内部で使用されます。

<PropertiesTable
  content={[
    {
      name: "options",
      type: "Record<string, unknown>",
      description: "answer リクエスト用のオプションパラメータ。",
      isOptional: true,
    },
  ]}
/>

戻り値: `Promise<void>`

### getSpeakers()

Gemini Live API で利用可能な音声ボイスの一覧を返します。

Returns: `Promise<Array<{ voiceId: string; description?: string }>>`

### disconnect()

Gemini Live セッションから切断し、リソースを解放します。クリーンアップを適切に行う非同期メソッドです。

戻り値: `Promise<void>`

### close()

disconnect() の同期ラッパー。内部で await せずに disconnect() を呼び出します。

戻り値: `void`

### on()

音声イベントのリスナーを登録します。

<PropertiesTable
  content={[
    {
      name: "event",
      type: "string",
      description: "リッスンするイベント名。",
      isOptional: false,
    },
    {
      name: "callback",
      type: "Function",
      description: "イベント発生時に呼び出される関数。",
      isOptional: false,
    },
  ]}
/>

戻り値: `void`

### off()

以前に登録したイベントリスナーを削除します。

<PropertiesTable
  content={[
    {
      name: "event",
      type: "string",
      description: "リッスンを停止するイベント名。",
      isOptional: false,
    },
    {
      name: "callback",
      type: "Function",
      description: "削除するコールバック関数。",
      isOptional: false,
    },
  ]}
/>

戻り値: `void`

## Events

GeminiLiveVoice クラスは次のイベントを送出します:

<PropertiesTable
  content={[
    {
      name: "speaker",
      type: "event",
      description:
        "モデルから音声データを受信したときに送出されます。コールバックは NodeJS.ReadableStream を受け取ります。",
    },
    {
      name: "speaking",
      type: "event",
      description:
        "音声メタデータとともに送出されます。コールバックは { audioData?: Int16Array, sampleRate?: number } を受け取ります。",
    },
    {
      name: "writing",
      type: "event",
      description:
        "文字起こしテキストが利用可能になったときに送出されます。コールバックは { text: string, role: 'assistant' | 'user' } を受け取ります。",
    },
    {
      name: "session",
      type: "event",
      description:
        "セッション状態が変化したときに送出されます。コールバックは { state: 'connecting' | 'connected' | 'disconnected' | 'disconnecting' | 'updated', config?: object } を受け取ります。",
    },
    {
      name: "turnComplete",
      type: "event",
      description:
        "会話のターンが完了したときに送出されます。コールバックは { timestamp: number } を受け取ります。",
    },
    {
      name: "toolCall",
      type: "event",
      description:
        "モデルがツール呼び出しを要求したときに送出されます。コールバックは { name: string, args: object, id: string } を受け取ります。",
    },
    {
      name: "usage",
      type: "event",
      description:
        "トークン使用情報とともに送出されます。コールバックは { inputTokens: number, outputTokens: number, totalTokens: number, modality: string } を受け取ります。",
    },
    {
      name: "error",
      type: "event",
      description:
        "エラー発生時に送出されます。コールバックは { message: string, code?: string, details?: unknown } を受け取ります。",
    },

    {
      name: "interrupt",
      type: "event",
      description:
        "割り込みイベントです。コールバックは { type: 'user' | 'model', timestamp: number } を受け取ります。",
    },
  ]}
/>

## 利用可能なモデル

利用可能な Gemini Live モデルは次のとおりです:

- `gemini-2.0-flash-exp`（デフォルト）
- `gemini-2.0-flash-exp-image-generation`
- `gemini-2.0-flash-live-001`
- `gemini-live-2.5-flash-preview-native-audio`
- `gemini-2.5-flash-exp-native-audio-thinking-dialog`
- `gemini-live-2.5-flash-preview`
- `gemini-2.6.flash-preview-tts`

## 利用可能な音声

利用できる音声オプションは次のとおりです:

- `Puck`（デフォルト）: 会話調で親しみやすい
- `Charon`: 低く、威厳がある
- `Kore`: 中立的でプロフェッショナル
- `Fenrir`: 温かみがあり、親しみやすい

## 認証方式

### Gemini API（開発）

[Google AI Studio](https://makersuite.google.com/app/apikey) の API キーを使う最も簡単な方法：

```typescript
const voice = new GeminiLiveVoice({
  apiKey: "あなたのAPIキー", // Gemini API に必要
  model: "gemini-2.0-flash-exp",
});
```


### Vertex AI（本番環境）

OAuth 認証と Google Cloud Platform を使用する本番環境向け:

```typescript
// サービス アカウント キー ファイルを使用
const voice = new GeminiLiveVoice({
  vertexAI: true,
  project: "your-gcp-project",
  location: "us-central1",
  serviceAccountKeyFile: "/path/to/service-account.json",
});

// アプリケーション デフォルト認証情報（ADC）を使用
const voice = new GeminiLiveVoice({
  vertexAI: true,
  project: "your-gcp-project",
  location: "us-central1",
});

// サービス アカウントの偽装（インパーソネーション）を使用
const voice = new GeminiLiveVoice({
  vertexAI: true,
  project: "your-gcp-project",
  location: "us-central1",
  serviceAccountEmail: "service-account@project.iam.gserviceaccount.com",
});
```


## 高度な機能

### セッション管理

Gemini Live API は、ネットワーク障害時のセッション再開に対応しています:

```typescript
voice.on("sessionHandle", ({ handle, expiresAt }) => {
  // セッション再開用にハンドルを保存する
  saveSessionHandle(handle, expiresAt);
});

// 以前のセッションを再開する
const voice = new GeminiLiveVoice({
  sessionConfig: {
    enableResumption: true,
    maxDuration: "2h",
  },
});
```


### ツール呼び出し

会話中にモデルが関数を呼び出せるようにする:

```typescript
import { z } from 'zod';

voice.addTools({
  weather: {
    description: "天気情報を取得",
    parameters: z.object({
      location: z.string(),
    }),
    execute: async ({ location }) => {
      const weather = await getWeather(location);
      return weather;
    },
  },
});

voice.on("toolCall", ({ name, args, id }) => {
  console.log(`ツール呼び出し: ${name}、引数:`, args);
});
```


## 注意事項

- Gemini Live API はリアルタイム通信に WebSocket を使用します
- 音声は入力が 16 kHz の PCM16、出力が 24 kHz の PCM16 として処理されます
- 他のメソッドを使用する前に、音声インスタンスは `connect()` で接続しておく必要があります
- 処理が完了したら、リソースを正しく解放するために必ず `close()` を呼び出してください
- Vertex AI の認証には、適切な IAM 権限（`aiplatform.user` ロール）が必要です
- セッション再開機能により、ネットワーク中断から復旧できます
- この API はテキストおよび音声のリアルタイム対話をサポートします