---
title: "リファレンス: createVectorQueryTool() | RAG | Mastra Tools ドキュメント"
description: フィルタリングとリランキング機能を備え、ベクターストア上でのセマンティック検索を実現する Mastra の Vector Query Tool のドキュメント。
---

import { Callout } from "nextra/components";
import { Tabs } from "nextra/components";


# createVectorQueryTool()

`createVectorQueryTool()` 関数は、ベクターストアに対するセマンティック検索用のツールを作成します。フィルタ、リランキング、データベース固有の設定に対応し、さまざまなベクターストアのバックエンドと統合できます。

## 基本的な使い方

```typescript
import { openai } from "@ai-sdk/openai";
import { createVectorQueryTool } from "@mastra/rag";

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```


## パラメータ

<Callout>
  **パラメータ要件:** ほとんどのフィールドは作成時にデフォルトとして設定できます。
  一部のフィールドは実行時コンテキストまたは入力によって実行時に上書きできます。
  作成時と実行時の両方で必須フィールドが欠けている場合はエラーがスローされます。`model`、`id`、`description` は作成時にのみ設定可能である点に注意してください。
</Callout>

<PropertiesTable
  content={[
    {
      name: "id",
      type: "string",
      description:
        "ツールのカスタム ID。デフォルト: 'VectorQuery {vectorStoreName} {indexName} Tool'。（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "description",
      type: "string",
      description:
        "ツールのカスタム説明。デフォルト: 'Access the knowledge base to find information needed to answer user questions'（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "model",
      type: "EmbeddingModel",
      description:
        "ベクター検索に使用する埋め込みモデル。（作成時のみ設定可能）",
      isOptional: false,
    },
    {
      name: "vectorStoreName",
      type: "string",
      description:
        "クエリ対象のベクターストア名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "indexName",
      type: "string",
      description:
        "ベクターストア内のインデックス名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "enableFilter",
      type: "boolean",
      description:
        "メタデータに基づく結果のフィルタリングを有効化します。（作成時のみ設定可能。ただし実行時コンテキストでフィルターが指定された場合は自動的に有効化されます）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeVectors",
      type: "boolean",
      description:
        "結果に埋め込みベクターを含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeSources",
      type: "boolean",
      description:
        "結果に取得オブジェクト全体を含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "true",
    },
    {
      name: "reranker",
      type: "RerankConfig",
      description:
        "結果のリランキングに関するオプション。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "databaseConfig",
      type: "DatabaseConfig",
      description:
        "クエリ最適化のためのデータベース固有の設定オプション。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "providerOptions",
      type: "Record<string, Record<string, any>>",
      description:
        "埋め込みモデル向けのプロバイダー固有オプション（例: outputDimensionality）。**重要**: AI SDK の EmbeddingModelV2 モデルでのみ有効です。V1 モデルではモデル作成時にオプションを設定してください。",
      isOptional: true,
    },
  ]}
/>

### DatabaseConfig

`DatabaseConfig` 型では、クエリ処理に自動的に適用されるデータベース固有の設定を指定できます。これにより、各種ベクターストアが提供する固有の機能や最適化を活用できます。

<PropertiesTable
  content={[
    {
      name: "pinecone",
      type: "PineconeConfig",
      description: "Pinecone ベクターストア固有の設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "namespace",
              description: "ベクターを整理するための Pinecone の namespace",
              isOptional: true,
              type: "string",
            },
            {
              name: "sparseVector",
              description: "ハイブリッド検索用のスパースベクター",
              isOptional: true,
              type: "{ indices: number[]; values: number[]; }",
            },
          ],
        },
      ],
    },
    {
      name: "pgvector",
      type: "PgVectorConfig",
      description: "pgvector 拡張機能を用いた PostgreSQL 向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "minScore",
              description: "結果に対する最小類似度スコアのしきい値",
              isOptional: true,
              type: "number",
            },
            {
              name: "ef",
              description: "HNSW の検索パラメータ — 精度と速度のトレードオフを制御",
              isOptional: true,
              type: "number",
            },
            {
              name: "probes",
              description: "IVFFlat の probe パラメータ — 検索時に訪問するセル数",
              isOptional: true,
              type: "number",
            },
          ],
        },
      ],
    },
    {
      name: "chroma",
      type: "ChromaConfig",
      description: "Chroma ベクターストア固有の設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "where",
              description: "メタデータのフィルタ条件",
              isOptional: true,
              type: "Record<string, any>",
            },
            {
              name: "whereDocument",
              description: "ドキュメント本文のフィルタ条件",
              isOptional: true,
              type: "Record<string, any>",
            },
          ],
        },
      ],
    },
  ]}
/>

### RerankConfig

<PropertiesTable
  content={[
    {
      name: "model",
      type: "MastraLanguageModel",
      description: "リランキングに使用する言語モデル",
      isOptional: false,
    },
    {
      name: "options",
      type: "RerankerOptions",
      description: "リランキング処理のオプション",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "weights",
              description:
                "スコアリング要素の重み（semantic: 0.4、vector: 0.4、position: 0.2）",
              isOptional: true,
              type: "WeightConfig",
            },
            {
              name: "topK",
              description: "返却する上位結果数",
              isOptional: true,
              type: "number",
              defaultValue: "3",
            },
          ],
        },
      ],
    },
  ]}
/>

## 返り値

このツールは、次のプロパティを持つオブジェクトを返します:

<PropertiesTable
  content={[
    {
      name: "relevantContext",
      type: "string",
      description: "最も関連性の高いドキュメントのチャンクから結合したテキスト",
    },
    {
      name: "sources",
      type: "QueryResult[]",
      description:
        "取得結果（リトリーバル）オブジェクトの完全版の配列。各オブジェクトには、元のドキュメント、チャンク、類似度スコアを参照するために必要な情報がすべて含まれます。",
    },
  ]}
/>

### QueryResult オブジェクトの構成

```typescript
{
  id: string;         // 一意のチャンク／ドキュメント識別子
  metadata: any;      // すべてのメタデータフィールド（ドキュメントID など）
  vector: number[];   // 埋め込みベクトル（利用可能な場合）
  score: number;      // この取得における類似度スコア
  document: string;   // チャンク／ドキュメントの全文（利用可能な場合）
}
```


## 既定のツールの説明

既定の説明は次の点に重点を置いています：

- 蓄積された知識から関連情報を見つけること
- ユーザーの質問に回答すること
- 事実ベースの内容を取得すること

## 結果の処理

このツールはユーザーのクエリに応じて返す結果数を決定し、既定では10件を返します。必要に応じてクエリの要件に合わせて調整できます。

## フィルター付きの例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  enableFilter: true,
});
```

フィルタリングを有効にすると、ツールはクエリを処理してメタデータフィルターを構築し、セマンティック検索と組み合わせます。処理の流れは次のとおりです。

1. ユーザーが「&#39;version&#39; フィールドが 2.0 より大きいコンテンツを見つけて」のように、特定のフィルター要件を含むクエリを行います
2. エージェントがクエリを解析し、適切なフィルターを構築します:
   ```typescript
   {
      "version": { "$gt": 2.0 }
   }
   ```

このエージェント主導のアプローチでは、次のことを行います。

* 自然言語のクエリをフィルター仕様へ変換
* ベクトルストア固有のフィルター構文を実装
* クエリの語句をフィルター演算子へマッピング

詳細なフィルター構文やストア固有の機能については、[Metadata Filters](../rag/metadata-filters) のドキュメントをご覧ください。

エージェント主導のフィルタリングの例については、[Agent-Driven Metadata Filtering](../../../examples/rag/usage/filter-rag.mdx) をご覧ください。


## リランクの例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "milvus",
  indexName: "documentation",
  model: openai.embedding("text-embedding-3-small"),
  reranker: {
    model: openai("gpt-4o-mini"),
    options: {
      weights: {
        semantic: 0.5, // セマンティック関連性の重み
        vector: 0.3, // ベクトル類似度の重み
        position: 0.2, // 元の位置の重み
      },
      topK: 5,
    },
  },
});
```

リランキングは次の要素を組み合わせて結果の品質を高めます:

* セマンティック関連性: LLM によるテキスト類似度のスコアリング
* ベクトル類似度: 元のベクトル距離スコア
* ポジションバイアス: 元の結果の並び順を考慮
* クエリ分析: クエリ特性に基づく調整

リランカーは初回のベクトル検索結果を処理し、関連性を最適化した並べ替え済みのリストを返します。


## カスタム説明の例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  description:
    "会社の方針や手順に関する質問に答えるため、文書アーカイブを検索して関連情報を見つける",
});
```

この例では、情報検索という本来の目的を保ちながら、特定のユースケースに合わせてツールの説明をカスタマイズする方法を示します。


## データベース別の設定例

`databaseConfig` パラメータを使うと、各ベクターデータベース固有の機能や最適化を活用できます。これらの設定はクエリ実行時に自動で適用されます。

<Tabs items={['Pinecone', 'pgVector', 'Chroma', 'Multiple Configs']}>
  <Tabs.Tab>
    ### Pinecone の設定

    ```typescript
    const pineconeQueryTool = createVectorQueryTool({
      vectorStoreName: "pinecone",
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "production",  // 環境ごとにベクトルを分離
          sparseVector: {           // ハイブリッド検索を有効化
            indices: [0, 1, 2, 3],
            values: [0.1, 0.2, 0.15, 0.05]
          }
        }
      }
    });
    ```

    **Pinecone の特徴:**
    - **Namespace**: 同一インデックス内でデータセットを分離
    - **Sparse Vector**: 密・疎の埋め込みを組み合わせて検索品質を向上
    - **ユースケース**: マルチテナント、ハイブリッド意味検索
  </Tabs.Tab>

  <Tabs.Tab>
    ### pgVector の設定

    ```typescript
    const pgVectorQueryTool = createVectorQueryTool({
      vectorStoreName: "postgres",
      indexName: "embeddings",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pgvector: {
          minScore: 0.7,    // 類似度 70% 以上の結果のみ返す
          ef: 200,          // 値が高いほど精度向上、検索は遅くなる
          probes: 10        // IVFFlat: probe 数を増やすと再現率が向上
        }
      }
    });
    ```

    **pgVector の特徴:**
    - **minScore**: 低品質な一致を除外
    - **ef (HNSW)**: HNSW インデックスの精度と速度のトレードオフを調整
    - **probes (IVFFlat)**: IVFFlat インデックスの再現率と速度のトレードオフを調整
    - **ユースケース**: パフォーマンス調整、品質フィルタリング
  </Tabs.Tab>

  <Tabs.Tab>
    ### Chroma の設定

    ```typescript
    const chromaQueryTool = createVectorQueryTool({
      vectorStoreName: "chroma",
      indexName: "documents",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        chroma: {
          where: {                    // メタデータでフィルタ
            "category": "technical",
            "status": "published"
          },
          whereDocument: {            // ドキュメント内容でフィルタ
            "$contains": "API"
          }
        }
      }
    });
    ```

    **Chroma の特徴:**
    - **where**: メタデータ項目でフィルタ
    - **whereDocument**: ドキュメント内容でフィルタ
    - **ユースケース**: 高度なフィルタリング、内容ベース検索
  </Tabs.Tab>

  <Tabs.Tab>
    ### 複数データベースの設定

    ```typescript
    // 複数のデータベースに対応（動的ストアに有用）
    const multiDbQueryTool = createVectorQueryTool({
      vectorStoreName: "dynamic-store", // 実行時に設定
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "default"
        },
        pgvector: {
          minScore: 0.8,
          ef: 150
        },
        chroma: {
          where: { "type": "documentation" }
        }
      }
    });
    ```

    **マルチ設定の利点:**
    - 1 つのツールで複数のベクターストアをサポート
    - データベース固有の最適化が自動適用される
    - 柔軟なデプロイシナリオに対応
  </Tabs.Tab>
</Tabs>

### 実行時の設定上書き

さまざまな状況に対応するため、実行時にデータベースの設定を上書きできます。

```typescript
import { RuntimeContext } from '@mastra/core/runtime-context';

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    pinecone: {
      namespace: "development"
    }
  }
});

// 実行時に上書き
const runtimeContext = new RuntimeContext();
runtimeContext.set('databaseConfig', {
  pinecone: {
    namespace: 'production'  // 本番用の名前空間に切り替え
  }
});

const response = await agent.generate(
  "デプロイに関する情報を見つけてください",
  { runtimeContext }
);
```

このアプローチにより、次のことが可能になります：

* 環境（dev/staging/prod）の切り替え
* 負荷に応じたパフォーマンスパラメーターの調整
* リクエスト単位での異なるフィルタリング戦略の適用


## 例：ランタイムコンテキストの使用

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```

ランタイムコンテキストを使用する場合、必要なパラメータは実行時にランタイムコンテキスト経由で指定します。

```typescript
const runtimeContext = new RuntimeContext<{
  vectorStoreName: string;
  indexName: string;
  topK: number;
  filter: VectorFilter;
  databaseConfig: DatabaseConfig;
}>();
runtimeContext.set("vectorStoreName", "my-store");
runtimeContext.set("indexName", "my-index");
runtimeContext.set("topK", 5);
runtimeContext.set("filter", { category: "docs" });
runtimeContext.set("databaseConfig", {
  pinecone: { namespace: "runtime-namespace" }
});
runtimeContext.set("model", openai.embedding("text-embedding-3-small"));

const response = await agent.generate(
  "ナレッジベースからドキュメントを検索してください。",
  {
    runtimeContext,
  },
);
```

実行時コンテキストの詳細については、以下をご覧ください。

* [Agent Runtime Context](../../docs/server-db/runtime-context.mdx)
* [Tool Runtime Context](../../docs/tools-mcp/overview.mdx#using-runtimecontext)


## Mastra Server なしでの使用

このツールは、クエリに一致するドキュメントを取得するために単独で使用できます。

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from "@ai-sdk/openai";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { createVectorQueryTool } from "@mastra/rag";
import { PgVector } from "@mastra/pg";

const pgVector = new PgVector({
  connectionString: process.env.POSTGRES_CONNECTION_STRING!,
});

const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector", // ストアを直接渡しているため省略可能
  vectorStore: pgVector,
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
});

const runtimeContext = new RuntimeContext();
const queryResult = await vectorQueryTool.execute({
  context: { queryText: "foo", topK: 1 },
  runtimeContext,
});

console.log(queryResult.sources);
```


## ツールの詳細

このツールは次のように作成されます：

- **ID**: `VectorQuery {vectorStoreName} {indexName} Tool`
- **入力スキーマ**: queryText と filter のオブジェクトが必要
- **出力スキーマ**: relevantContext の文字列を返す

## 関連項目

- [rerank()](../rag/rerank)
- [createGraphRAGTool](./graph-rag-tool)