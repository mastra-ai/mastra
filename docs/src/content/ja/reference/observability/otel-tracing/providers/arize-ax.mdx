---
title: "リファレンス: Arize AX 連携 | Mastra Observability ドキュメント"
description: Arize AX を Mastra に統合するためのドキュメント。Mastra は、LLM アプリケーションの監視と評価のための包括的な AI 可観測性プラットフォームです。
---

# Arize AX

Arize AX は、本番環境で稼働する LLM アプリケーションの監視・評価・改善に特化して設計された、包括的な AI 可観測性プラットフォームです。

## 設定

Mastra で Arize AX を使うには、環境変数を利用するか、Mastra の設定で直接構成できます。

### 環境変数の使用

次の環境変数を設定します:

```env
ARIZE_SPACE_ID="your-space-id"
ARIZE_API_KEY="your-api-key"
```


### 資格情報の取得

1. [app.arize.com](https://app.arize.com) で Arize AX アカウントに登録する
2. スペースの設定に進み、Space ID と API Key を確認する

## インストール

まず、Mastra 向けの OpenInference のインストルメンテーションパッケージをインストールします。

```bash
npm install @arizeai/openinference-mastra
```


## 実装

OpenTelemetry と併用して Arize AX を使うように Mastra を設定する方法は次のとおりです：

```typescript
import { Mastra } from "@mastra/core";
import {
  isOpenInferenceSpan,
  OpenInferenceOTLPTraceExporter,
} from "@arizeai/openinference-mastra";

export const mastra = new Mastra({
  // ... その他の設定
  telemetry: {
    serviceName: "your-mastra-app",
    enabled: true,
    export: {
      type: "custom",
      exporter: new OpenInferenceOTLPTraceExporter({
        url: "https://otlp.arize.com/v1/traces",
        headers: {
          "space_id": process.env.ARIZE_SPACE_ID!,
          "api_key": process.env.ARIZE_API_KEY!,
        },
        spanFilter: isOpenInferenceSpan,
      }),
    },
  },
});
```


## 自動的にトレースされる内容

Mastra の包括的なトレースでは、以下が記録されます:

- **エージェントの動作**: エージェントの生成、ストリーミング、インタラクション呼び出しのすべて
- **LLM とのやり取り**: 入出力メッセージやメタデータを含むモデル呼び出しの全内容
- **ツールの実行**: パラメータと結果を伴う、エージェントによる関数呼び出し
- **ワークフローの実行**: タイミングや依存関係を含む、ステップごとのワークフロー実行
- **メモリ操作**: エージェントメモリへのクエリ、更新、取得

すべてのトレースは OpenTelemetry の標準に準拠しており、モデルパラメータ、トークン使用量、実行時間、エラーの詳細などの関連メタデータを含みます。

## ダッシュボード

設定が完了すると、[app.arize.com](https://app.arize.com) の Arize AX ダッシュボードでトレースとアナリティクスを確認できます