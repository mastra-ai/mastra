---
title: "参考文档：voice.connect() | 语音"
description: "实时语音提供者提供的 connect() 方法文档，用于建立语音到语音通信的连接。"
packages:
  - "@mastra/core"
  - "@mastra/node-speaker"
  - "@mastra/voice-openai-realtime"
---

# voice.connect()

`connect()` 方法建立 WebSocket 或 WebRTC 连接以进行实时语音到语音通信。此方法必须在使用其他实时功能（如 `send()` 或 `answer()`）之前调用。

## 使用示例

```typescript
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import Speaker from "@mastra/node-speaker";

const speaker = new Speaker({
  sampleRate: 24100, // 音频采样率（Hz）- MacBook Pro 高品质音频的标准
  channels: 1, // 单声道音频输出（立体声为 2）
  bitDepth: 16, // 音频位深度 - CD 质量标准（16位分辨率）
});

// 初始化实时语音提供者
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-5.1-realtime",
    apiKey: process.env.OPENAI_API_KEY,
    options: {
      sessionConfig: {
        turn_detection: {
          type: "server_vad",
          threshold: 0.6,
          silence_duration_ms: 1200,
        },
      },
    },
  },
  speaker: "alloy", // 默认语音
});
// 连接到实时服务
await voice.connect();
// 现在您可以使用实时功能
voice.on("speaker", (stream) => {
  stream.pipe(speaker);
});
// 使用连接选项
await voice.connect({
  timeout: 10000, // 10 秒超时
  reconnect: true,
});
```

## 参数

<PropertiesTable
  content={[
    {
      name: "options",
      type: "Record<string, unknown>",
      description: "提供者特定的连接选项",
      isOptional: true,
    },
  ]}
/>

## 返回值

返回 `Promise<void>`，在连接成功建立时解析。

## 提供者特定选项

每个实时语音提供者可能支持 `connect()` 方法的不同选项：

### OpenAI Realtime

<PropertiesTable
  content={[
    {
      name: "options.timeout",
      type: "number",
      description: "连接超时时间（毫秒）",
      isOptional: true,
      defaultValue: "30000",
    },
    {
      name: "options.reconnect",
      type: "boolean",
      description: "是否在连接丢失时自动重连",
      isOptional: true,
      defaultValue: "false",
    },
  ]}
/>

## 与 CompositeVoice 一起使用

使用 `CompositeVoice` 时，`connect()` 方法委托给配置的实时提供者：

```typescript
import { CompositeVoice } from "@mastra/core/voice";
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
const realtimeVoice = new OpenAIRealtimeVoice();
const voice = new CompositeVoice({
  realtime: realtimeVoice,
});
// 这将使用 OpenAIRealtimeVoice 提供者
await voice.connect();
```

## 注意事项

- 此方法仅由支持语音到语音功能的实时语音提供者实现
- 如果在不支持此功能的语音提供者上调用，它会记录警告并立即解析
- 必须在使用其他实时方法（如 `send()` 或 `answer()`）之前建立连接
- 完成语音实例后，调用 `close()` 以正确清理资源
- 某些提供者可能会在连接丢失时自动重连，具体取决于其实现
- 连接错误通常会作为异常抛出，应予以捕获和处理

## 相关方法

- [voice.send()](./voice.send) - 向语音提供者发送音频数据
- [voice.answer()](./voice.answer) - 触发语音提供者响应
- [voice.close()](./voice.close) - 断开与实时服务的连接
- [voice.on()](./voice.on) - 注册语音事件的事件监听器
