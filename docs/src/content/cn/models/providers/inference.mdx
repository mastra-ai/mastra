---
title: "Inference | 模型 | Mastra"
description: "在 Mastra 中使用 Inference 模型。共 9 个模型。"
---

{/* 此文件由 generate-model-docs.ts 自动生成 - 请勿手动编辑 */}

# <img src="https://models.dev/logos/inference.svg" alt="Inference logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Inference

通过 Mastra 的模型路由器访问 9 个 Inference 模型。身份验证使用 `INFERENCE_API_KEY` 环境变量自动处理。

在 [Inference 文档](https://inference.net/models) 中了解更多信息。

```bash title=".env"
INFERENCE_API_KEY=your-api-key
```

```typescript title="src/mastra/agents/my-agent.ts" {7}
import { Agent } from "@mastra/core/agent";

const agent = new Agent({
  id: "my-agent",
  name: "My Agent",
  instructions: "You are a helpful assistant",
  model: "inference/google/gemma-3"
});

// 生成响应
const response = await agent.generate("Hello!");

// 流式响应
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

:::info

Mastra 使用 OpenAI 兼容的 `/chat/completions` 端点。某些提供商特定功能可能不可用。查看 [Inference 文档](https://inference.net/models) 了解详情。

:::

## 模型

<ProviderModelsTable
  models={[
  {
    "model": "inference/google/gemma-3",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 125000,
    "maxOutput": 4096,
    "inputCost": 0.15,
    "outputCost": 0.3
  },
  {
    "model": "inference/meta/llama-3.1-8b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 16000,
    "maxOutput": 4096,
    "inputCost": 0.025,
    "outputCost": 0.025
  },
  {
    "model": "inference/meta/llama-3.2-11b-vision-instruct",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 16000,
    "maxOutput": 4096,
    "inputCost": 0.055,
    "outputCost": 0.055
  },
  {
    "model": "inference/meta/llama-3.2-1b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 16000,
    "maxOutput": 4096,
    "inputCost": 0.01,
    "outputCost": 0.01
  },
  {
    "model": "inference/meta/llama-3.2-3b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 16000,
    "maxOutput": 4096,
    "inputCost": 0.02,
    "outputCost": 0.02
  },
  {
    "model": "inference/mistral/mistral-nemo-12b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 16000,
    "maxOutput": 4096,
    "inputCost": 0.038,
    "outputCost": 0.1
  },
  {
    "model": "inference/osmosis/osmosis-structure-0.6b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 4000,
    "maxOutput": 2048,
    "inputCost": 0.1,
    "outputCost": 0.5
  },
  {
    "model": "inference/qwen/qwen-2.5-7b-vision-instruct",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 125000,
    "maxOutput": 4096,
    "inputCost": 0.2,
    "outputCost": 0.2
  },
  {
    "model": "inference/qwen/qwen3-embedding-4b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 32000,
    "maxOutput": 2048,
    "inputCost": 0.01,
    "outputCost": null
  }
]}
/>

## 高级配置

### 自定义请求头

```typescript title="src/mastra/agents/my-agent.ts"
const agent = new Agent({
  id: "custom-agent",
  name: "custom-agent",
  model: {
    url: "https://inference.net/v1",
    id: "inference/google/gemma-3",
    apiKey: process.env.INFERENCE_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### 动态模型选择

```typescript title="src/mastra/agents/my-agent.ts"
const agent = new Agent({
  id: "dynamic-agent",
  name: "Dynamic Agent",
  model: ({ requestContext }) => {
    const useAdvanced = requestContext.task === "complex";
    return useAdvanced
      ? "inference/qwen/qwen3-embedding-4b"
      : "inference/google/gemma-3";
  }
});
```


