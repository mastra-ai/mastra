# Logging and Tracing

Effective logging and tracing are crucial for understanding the behavior of your application.

Tracing is especially important for AI engineering. Teams building AI products find that visibility into inputs and outputs of every step of every run is crucial to improving accuracy. You get this with Mastra's telemetry.

You can log to console or send log drains to third party services like Upstash. You can send traces to your favorite observability service like Datadog, Honeycomb, as well as AI-specific observability services like Braintrust or Langfuse.

## Logging

In Mastra, logs can detail when certain functions run, what input data they receive, and how they respond.

### Basic Setup

Here’s a minimal example that sets up a **console logger** at the `INFO` level. This will print out informational messages and above (i.e., `INFO`, `WARN`, `ERROR`) to the console.

```typescript filename="mastra.config.ts" showLineNumbers copy
import { Mastra, createLogger } from '@mastra/core';

export const mastra = new Mastra({
  // Other Mastra configuration...
  logger: createLogger({
    type: 'CONSOLE',
    level: 'INFO',
  }),
});
```

In this configuration:

- `type: "CONSOLE"` specifies that logs should be output to the console.
- `level: "INFO"` sets the minimum severity of logs to record.

### Configuration

- For more details on the options you can pass to `createLogger()`, see the [createLogger reference documentation](/guide/reference/observability/createLogger.mdx).
- Once you have a `Logger` instance, you can call its methods (e.g., `.info()`, `.warn()`, `.error()`) in the [Logger instance reference documentation](/guide/reference/observability/logger.mdx).
- If you need to direct logs to multiple destinations—like both console and an external logging service—see the [combineLoggers reference documentation](/guide/reference/observability/create-combinnedlogger.mdx).
- If you want to send your logs to an external service for centralized collection, analysis, or storage, you can configure other logger types such as Upstash Redis. Consult the [createLogger reference documentation](/guide/reference/observability/createLogger.mdx) for details on parameters like `url`, `token`, and `key` when using the `UPSTASH` logger type.

## Telemetry

Mastra supports OpenTelemetry for tracing and monitoring your application. You can enable telemetry by adding the `telemetry` property to your Mastra configuration.

### Basic Configuration

Here's a simple example of enabling telemetry:

```ts filename="mastra.config.ts" showLineNumbers copy
export const mastra = new Mastra({
  // ... other config
  telemetry: {
    serviceName: 'my-app',
    enabled: true,
    sampling: {
      type: 'always_on',
    },
    export: {
      type: 'console',
    },
  },
});
```

### Automatic Instrumentation

When telemetry is enabled, Mastra automatically traces all core primitives including:

- Agent operations and steps
- LLM interactions
- Tool executions
- Integration calls
- Workflow runs
- Database operations

This gives you visibility into your application's behavior without any additional configuration.

### Example: Tracing an Agent Interaction

Here's what a traced agent interaction looks like in [Signoz](https://signoz.io):

<img
  src="/docs/signoz-telemetry-demo.png"
  alt="Agent interaction trace showing spans, LLM calls, and tool executions"
  style={{ maxWidth: '800px', width: '100%', margin: '8px 0' }}
  className="nextra-image"
  data-zoom
/>

### Configuration Options

The telemetry config accepts these properties:

```ts
type OtelConfig = {
  // Name to identify your service in traces (optional)
  serviceName?: string;

  // Enable/disable telemetry (defaults to true)
  enabled?: boolean;

  // Control how many traces are sampled
  sampling?: {
    type: 'ratio' | 'always_on' | 'always_off' | 'parent_based';
    probability?: number; // For ratio sampling
    root?: {
      probability: number; // For parent_based sampling
    };
  };

  // Where to send telemetry data
  export?: {
    type: 'otlp' | 'console';
    endpoint?: string;
    headers?: Record<string, string>;
  };
};
```

See the [OtelConfig reference documentation](/guide/reference/observability/otel-config.mdx) for more details.

### Using Environment Variables

You can configure the OTLP endpoint and headers through environment variables:

```env filename=".env" copy
OTEL_EXPORTER_OTLP_ENDPOINT=https://api.honeycomb.io
OTEL_EXPORTER_OTLP_HEADERS=x-honeycomb-team=your-api-key
```

Then in your config:

```ts filename="mastra.config.ts" showLineNumbers copy
export const mastra = new Mastra({
  // ... other config
  telemetry: {
    serviceName: 'my-app',
    enabled: true,
    export: {
      type: 'otlp',
      // endpoint and headers will be picked up from env vars
    },
  },
});
```

### Next.js Configuration

When developing locally with Next.js, you'll need to:

1. Install the instrumentation package:

```bash copy
npm install import-in-the-middle # or require-in-the-middle for CJS
```

2. Add it as an external dependency in your Next.js config:

```ts filename="next.config.ts" showLineNumbers copy
import type { NextConfig } from 'next';

const nextConfig: NextConfig = {
  serverExternalPackages: ['import-in-the-middle'],
};

export default nextConfig;
```

This configuration is only necessary for local development to ensure proper instrumentation during hot reloading.
