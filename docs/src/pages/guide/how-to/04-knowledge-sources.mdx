# RAG (Retrieval Augmented Generation)

Retrieval-augmented generation (RAG) lets you construct a knowledge base for agents. RAG is an ETL pipeline with specific querying techniques, including chunking, embedding, and vector search.

Mastra provides components for building RAG systems with document chunking, metadata extraction, and vector storage.

## Document Processing

The `MastraDocument` class handles document chunking and metadata extraction:

```ts showLineNumbers copy filename="src/mastra/document.ts"
import { MastraDocument } from "@mastra/rag";

const doc = new MastraDocument({
  text: "Your content here",
  metadata: {
    source: "example.com",
    author: "John Doe",
  },
});

// Basic chunking
await doc.chunk({
  type: "sentence", // 'sentence' | 'paragraph' | 'fixed'
  size: 512, // target chunk size
  overlap: 50, // overlap between chunks
});

// Chunking with metadata extraction (requires OpenAI)
await doc.chunk({
  type: "sentence",
  size: 512,
  extract: {
    title: true,
    summary: true,
    keywords: { count: 5 },
    questions: { count: 3 },
  },
  openAiKey: process.env.OPENAI_API_KEY,
});
```

## Vector Storage

Mastra supports multiple vector databases through a unified interface:

### PostgreSQL Vector Storage

```ts showLineNumbers copy filename="src/mastra/vector-configs/index.ts"
import { PgVector } from "@mastra/rag";

const store = new PgVector({
  connectionString: "postgresql://localhost:5432/mydb",
  tableName: "embeddings", // optional, defaults to "mastra_embeddings"
  dimension: 1536, // must match your embedding model
});

// Store chunks
await store.upsert({
  vectors: embeddings, // your embeddings array
  metadata: doc.chunks, // chunk metadata
  namespace: "docs", // optional organization
});

// Query
const results = await store.query({
  vector: queryEmbedding,
  limit: 5,
  namespace: "docs",
});
```

### Pinecone Storage

```typescript copy filename="src/mastra/vector-configs/index.ts" showLineNumbers
import { PineconeVector } from "@mastra/rag";

const store = new PineconeVector({
  apiKey: process.env.PINECONE_API_KEY,
  environment: "us-west1-gcp",
  indexName: "my-index",
});

// Store and query work the same as PgVector
await store.upsert({ vectors, metadata, namespace });
const results = await store.query({ vector, limit, namespace });
```

### Qdrant Storage

```typescript copy filename="src/mastra/vector-configs/index.ts" showLineNumbers
import { QdrantVector } from "@mastra/rag";

const store = new QdrantVector("http://localhost:6333/");

await store.upsert({ vectors, metadata, namespace });
const results = await store.query({ vector, limit, namespace });
```

## Configuration

Add vector store configuration to your Mastra config:

```ts filename="src/mastra/index.ts" showLineNumbers copy
const mastra = new Mastra({
  vector: {
    PINECONE: {
      apiKey: process.env.PINECONE_API_KEY,
    },
    PGVECTOR: {
      connectionString: process.env.DATABASE_URL,
    },
    QDRANT: {
      url: "http://localhost:6333/",
    },
  },
});
```

For more details on:

- Document processing: [Document API](https://mastra.ai/docs/guide/reference/rag/document)
- Vector stores: [Pgcvector](https://mastra.ai/docs/guide/reference/rag/pgvector), [Pinecone](https://mastra.ai/docs/guide/reference/rag/pinecone)
- Embeddings: [Embedding Models](/api/rag/embeddings)
