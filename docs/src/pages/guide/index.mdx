import { Callout, Steps } from 'nextra/components';

# Overview

Mastra is an opinionated Typescript framework that helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals. You can run Mastra on your local machine, or deploy to a serverless cloud.

The main Mastra features are:

Features|Description
--------|--------
[Agents](https://mastra.ai/docs/guide/how-to/01-creating-agents) | Agents are systems where the language model chooses a sequence of actions. In Mastra, agents provide LLM models with tools, workflows, and synced data. Agents can call your own functions or APIs of third-party integrations and access knowledge bases you build.
[Tools](https://mastra.ai/docs/guide/how-to/02-adding-tools) | Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. Each tool has a schema that defines its inputs, an executor function that implements its logic, and access to configured integrations.
[Workflows](https://mastra.ai/docs/guide/how-to/03-building-workflows) | Workflows are durable graph-based state machines. They have loops, branching, wait for human input, embed other workflows, do error handling, retries, parsing and so on. They can be built in code or with a visual editor. Each step in a workflow has built-in OpenTelemetry tracing. 
[RAG](https://mastra.ai/docs/guide/how-to/04-knowledge-sources) | Retrieval-augemented generation (RAG) lets you construct a knowledge base for agents. RAG is an ETL pipeline with specific querying techniques, including chunking, embedding, and vector search.
[Integrations & Syncs](https://mastra.ai/docs/guide/how-to/05-adding-integrations) | In Mastra, syncs are async functions that can be deployed as background tasks across different execution environments. Integrations are auto-generated, type-safe API clients for third-party services that can be used as tools for agents or steps in workflows. 
[Evals](https://mastra.ai/docs/guide/how-to/06-running-evals) | Evals are automated tests that evaluate LLM outputs using model-graded, rule-based, and statistical methods. Each eval returns a normalized score between 0-1 that can be logged and compared. Evals can be customized with your own prompts and scoring functions.

## Quick Start

### Prerequisites

- Node.js (version 20 or later)
- Docker (the daemon should be running)

### Installing Next.js

Start by creating a new Next.js App Router project in TypeScript. You can initialize one quickly with

```bash copy
npx create-next-app --ts --eslint --src-dir --tailwind --import-alias "@/*" --app
```

Once installed, follow the steps below:

<Steps>

### Install global CLI

```bash copy
npm install -g mastra
```

### Add the core package

From the root of your Next.js project:

```bash copy
npm install @mastra/core
```

### Initialize your project:

```bash copy
mastra init
```

Provision local resources:

```bash copy filename="terminal"
$ Enter your PostgreSQL connection string (postgresql://username:password@host:port/database) or press Enter to create a new instance:
$ Enter your Inngest server URL or press Enter to create a new instance:
```

### Run the Mastra dev server:

```bash copy
mastra dev
```

</Steps>

## Configuration

After initialization, you'll find an `mastra.config.ts` file in your project root. You can find the full list of configuration options in the [Mastra config docs](./reference/mastra-config.mdx) and a reference of the files Mastra owns in the [Local File Structure docs](./reference/local-project-structure.mdx).

## Deployment

Mastra's data syncing infrastructure is designed for Next.js sites running on serverless hosting providers like Vercel or Netlify.

Job queues are managed with [Inngest](https://inngest.com/), which can be self-hosted or run as a managed service.

Logs can be configured to be written to the console, written to the filesystem, or stored in [Upstash](https://upstash.com/).

[Full deployment docs](./reference/mastra-config.mdx) here.
