---
title: "Example: Metadata Filtering | Retrieval | RAG | Mastra Docs"
description: Example of implementing a RAG system in Mastra using metadata filters to search for relevant chunks in the vector store.
---

import { GithubLink } from "../../../components/github-link";

# Metadata Filtering

This example demonstrates how to implement a Retrieval-Augmented Generation (RAG) system using Mastra, OpenAI embeddings, and PGVector for vector storage.
This system uses metadata filters to search for relevant chunks in the vector store, reducing the amount of results returned.

## Overview

The system implements RAG using Mastra and OpenAI. Here's what it does:

1. Sets up a Mastra agent with gpt-4o-mini for response generation
2. Creates a vector query tool to manage vector store interactions
3. Chunks text documents into smaller segments
4. Creates embeddings for these chunks
5. Stores them in a PostgreSQL vector database
6. Retrieves relevant chunks based on queries using vector query tool
7. Generates context-aware responses using the Mastra agent

## Setup

### Environment Setup

Make sure to set up your environment variables:

```bash filename=".env"
POSTGRES_CONNECTION_STRING=your_connection_string_here
```

### Dependencies

Then, import the necessary dependencies:

```typescript copy showLineNumbers filename="src/mastra/index.ts"
import { Mastra, Agent, EmbedResult, EmbedManyResult } from "@mastra/core";
import { PgVector } from "@mastra/vector-pg";
import { createVectorQueryTool, embed, MDocument } from "@mastra/rag";
```

## Vector Query Tool Creation

Using createVectorQueryTool imported from @mastra/rag, you can create a tool that can query the vector database.

```typescript copy showLineNumbers{4} filename="src/mastra/index.ts"
const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  options: {
    provider: "OPEN_AI",
    model: "text-embedding-ada-002",
    maxRetries: 3,
  },
  topK: 3,
  vectorFilterType: "pg",
});
```

## Agent Configuration

Set up the Mastra agent that will handle the responses:

```typescript copy showLineNumbers{16} filename="src/mastra/index.ts"
export const ragAgent = new Agent({
  name: "RAG Agent",
  instructions:
    "You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.",
  model: {
    provider: "OPEN_AI",
    name: "gpt-4o-mini",
  },
  tools: { vectorQueryTool },
});
```

## Instantiate PgVector and Mastra

Instantiate PgVector and Mastra with all components:

```typescript copy showLineNumbers{27} filename="src/mastra/index.ts"
const pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector },
});

const agent = mastra.getAgent("ragAgent");
```

## Document Processing

Create a document and process it into chunks:

```typescript copy showLineNumbers{36} filename="src/mastra/index.ts"
const doc = MDocument.fromText(
  `The Impact of Climate Change on Global Agriculture...`,
);

const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
  extract: {
    keywords: true,
  },
});
```

## Creating and Storing Embeddings

Generate embeddings for the chunks and store them in the vector database:

```typescript copy showLineNumbers{48} filename="src/mastra/index.ts"
const { embeddings } = (await embed(chunks, {
  provider: "OPEN_AI",
  model: "text-embedding-ada-002",
  maxRetries: 3,
})) as EmbedManyResult<string>;

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex("embeddings", 1536);
await vectorStore.upsert(
  "embeddings",
  embeddings,
  chunks?.map((chunk: any) => ({
    text: chunk.text,
    ...chunk.metadata,
    nested: {
      keywords: chunk.metadata.excerptKeywords
        .replace("KEYWORDS:", "")
        .split(",")
        .map((k) => k.trim()),
      id: index,
    },
  })),
);
```

## Response Generation

Function to generate responses based on retrieved context:

```typescript copy showLineNumbers{65} filename="src/mastra/index.ts"
async function generateResponse(query: string, filter: any) {
  const buildFilterString = (f: any): string => {
    if ("type" in f) {
      return `type:${f.type} condition with filters: [${f.filters
        .map(buildFilterString)
        .join(", ")}]`;
    }
    return `keyword: ${f.keyword} operator: ${f.operator} value: ${f.value}`;
  };
  const filterDescription = buildFilterString(filter);
  const prompt = `
      Please answer the following question:
      ${query}

    Please base your answer only on the context provided in the tool using these filter conditions:
    ${filterDescription}
    If the context doesn't contain enough information to fully answer the question, please state that explicitly.
      `;

  // Call the agent to generate a response
  const completion = await agent.generate(prompt);

  return completion.text;
}
```

## Example Usage

```typescript copy showLineNumbers{89} filename="src/mastra/index.ts"
async function answerQueries(
  queries: {
    query: string;
    filter: any;
  }[],
) {
  for (const { query, filter } of queries) {
    try {
      // Generate and log the response
      const answer = await generateResponse(query, filter);
      console.log("\nQuery:", query);
      console.log("Response:", answer);
    } catch (error) {
      console.error(`Error processing query "${query}":`, error);
    }
  }
}

const queries = [
  {
    query: "What adaptation strategies are mentioned?",
    filter: {
      keyword: "nested.keywords",
      operator: "ilike",
      value: "adaptation",
    },
  },
  {
    query: "Show me recent sections",
    filter: {
      keyword: "nested.id",
      operator: "gt",
      value: "2",
    },
  },
  {
    query: "Find sections about drought and irrigation",
    filter: {
      type: "$and",
      filters: [
        {
          keyword: "text",
          operator: "ilike",
          value: "drought",
        },
        {
          keyword: "text",
          operator: "ilike",
          value: "irrigation",
        },
      ],
    },
  },
  {
    query: "Find sections about wheat or rice",
    filter: {
      type: "$or",
      filters: [
        {
          keyword: "text",
          operator: "ilike",
          value: "wheat",
        },
        {
          keyword: "text",
          operator: "ilike",
          value: "rice",
        },
      ],
    },
  },
];

await answerQueries(queries);
```

### Filter Types

PGVector supports these filter types:

1. Basic comparison operators:

```typescript
{
  "path.to.field": {
    eq: "value",     // Equals
    neq: "value",    // Not equals
    gt: 25,          // Greater than
    gte: 25,         // Greater than or equal
    lt: 25,          // Less than
    lte: 25          // Less than or equal
  }
}
```

2. Text search operators:

```typescript
{
  "path.to.field": {
    like: "value",    // Case-sensitive pattern matching
    ilike: "value"    // Case-insensitive pattern matching
  }
}
```

3. Collection operators:

```typescript
{
  "path.to.field": {
    in: ["value1", "value2"],     // Match any value in array
    contains: "value",            // JSONB containment
    exists: true                  // Check if field exists
  }
}
```

4. Logical operators:

```typescript
{
  type: "$and",  // or "$or"
  filters: [
    { "path.to.field": { ilike: "value1" } },
    { "path.to.field": { ilike: "value2" } }
  ]
}
```

### Available Operators

PGVector implements the following operators:

- Basic: `eq`, `neq`, `gt`, `gte`, `lt`, `lte`
- Text: `like`, `ilike`
- Collection: `in`, `contains`, `exists`
- Logical: `$and`, `$or`

<br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag"
  }
/>
