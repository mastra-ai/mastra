---
title: "Example: Context Precision | Evals | Mastra Docs"
description: Example of using the Context Precision metric to evaluate accuracy of context usage.
---

# Context Precision

This example demonstrates how to use Mastra's Context Precision metric to evaluate how accurately responses use provided context information.

## Overview

The example shows how to:

1. Set up a Mastra agent for generating responses
2. Configure the Context Precision metric
3. Evaluate context usage accuracy
4. Analyze precision scores

## Setup

### Environment Setup

Make sure to set up your environment variables:

```bash filename=".env"
OPENAI_API_KEY=your_api_key_here
```

### Dependencies

Import the necessary dependencies:

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from '@ai-sdk/openai';
import { Agent } from '@mastra/core/agent';
import { ContextPrecisionMetric } from '@mastra/evals/llm';
```

## Agent Creation

Create a Mastra agent for generating responses:

```typescript copy showLineNumbers{7} filename="src/index.ts"
const agent = new Agent({
  name: 'Example Agent',
  instructions: 'You are a helpful assistant that provides informative answers.',
  model: openai('gpt-4o-mini'),
});
```

## Metric Configuration

Set up the Context Precision metric with context:

```typescript copy showLineNumbers{7} filename="src/index.ts"
const metric = new ContextPrecisionMetric(openai('gpt-4o-mini'), {
  scale: 1,
  context: [
    "The Earth's core temperature is approximately 6,000°C.",
    "The core is primarily composed of iron and nickel.",
    "The core creates Earth's magnetic field.",
    "The core is divided into inner and outer regions.",
  ],
});
```

## Example Usage

### High Precision Example

Evaluate precise scientific information usage:

```typescript copy showLineNumbers filename="src/index.ts"
const context1 = [
  "The Earth's core temperature is approximately 6,000°C.",
  "The core is primarily composed of iron and nickel.",
  "The core creates Earth's magnetic field.",
  "The core is divided into inner and outer regions.",
];

const query1 = "What is Earth's core like?";
const response1 = await agent.generate(query1, { context: context1.join(' ') });

const result1 = await metric1.measure(query1, response1.text);
console.log('High Precision Result:', {
  score: result1.score,
  reason: result1.info.reason,
});
```

### Mixed Precision Example

Evaluate broader topic information usage:

```typescript copy showLineNumbers filename="src/index.ts"
const context2 = [
  "Renewable energy includes solar, wind, and hydroelectric power.",
  "Global energy consumption continues to rise.",
  "Fossil fuels remain a significant energy source.",
  "Energy efficiency measures can reduce consumption.",
];

const query2 = 'What are the main renewable energy sources?';
const response2 = await agent.generate(query2, { context: context2.join(' ') });

const result2 = await metric2.measure(query2, response2.text);
console.log('Mixed Precision Result:', {
  score: result2.score,
  reason: result2.info.reason,
});
```

## Understanding the Results

The metric provides:

1. A precision score between 0 and 1:
   - 1.0: Perfect precision - all context used accurately
   - 0.7-0.9: High precision - most context used accurately
   - 0.4-0.6: Moderate precision - mixed accuracy in context usage
   - 0.1-0.3: Low precision - inaccurate context usage
   - 0.0: No precision - context misused or ignored

2. Detailed reasoning about:
   - Accuracy of context usage
   - Relevance to the query
   - Information fidelity
   - Context integration quality

<br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision"
  }
/>
