---
title: "Example: Custom Eval | Evals | Mastra Docs"
description: Example of creating custom LLM-based evaluation metrics in Mastra.
---

import { GithubLink } from "../../../components/github-link";

# Custom Eval with LLM as a Judge

This example demonstrates how to create a custom LLM-based evaluation metric in Mastra to assess recipe completeness using an AI chef agent.

## Overview

The example shows how to:

1. Create a custom LLM-based metric class
2. Set up a specialized judge for evaluation
3. Define evaluation prompts
4. Use an agent to generate and evaluate recipes
5. Handle structured evaluation results

## Setup

### Environment Setup

Make sure to set up your environment variables:

```bash filename=".env"
OPENAI_API_KEY=your_api_key_here
```

### Dependencies

Import the necessary dependencies:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/metricJudge.ts"
import { type LanguageModel } from '@mastra/core/llm';
import { MastraAgentJudge } from '@mastra/evals/judge';
import { z } from 'zod';
```

## Defining Prompts

The evaluation system uses three different prompts, each serving a specific purpose:

#### 1. Instructions Prompt

This prompt sets the role and context for the judge:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/prompts.ts"
export const RECIPE_COMPLETENESS_INSTRUCTIONS = `You are a Master Chef that evaluates recipes for completeness. Your role is to ensure recipes include all essential information needed for successful cooking.`;
```

#### 2. Completeness Evaluation Prompt

This prompt creates a structured evaluation of recipe completeness, checking for specific components:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/prompts.ts"
export const generateCompletenessPrompt = ({
  input,
  output,
}: {
  input: string;
  output: string;
}) => `Analyze if this recipe includes all essential components for successful cooking.

Essential components to check:
1. Ingredient Quantities
   - All ingredients must have specific measurements
   - Example of incomplete: "add tomatoes"
   - Example of complete: "add 2 diced tomatoes"

2. Cooking Times
   - Each cooking step needs a specific duration
   - Example of incomplete: "cook until done"
   - Example of complete: "cook for 15-20 minutes"

3. Cooking Temperatures
   - All heating steps need specific temperatures
   - Example of incomplete: "bake in oven"
   - Example of complete: "bake at 350°F (175°C)"

User input: ${input}
Analyze this recipe:
${output}

Return your response in this format:
{
  "missing": ["list each missing element"],
  "verdict": "Complete or Incomplete"
}`;
```

#### 3. Reasoning Prompt

This prompt generates detailed explanations about why a recipe is considered complete or incomplete:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/prompts.ts"
export const generateReasonPrompt = ({
  input,
  output,
  missing,
  verdict,
}: {
  input: string;
  output: string;
  missing: string[];
  verdict: string;
}) => `Explain why this recipe is ${verdict} based on its completeness.

${missing.length > 0 ? `The recipe is missing: ${missing.join(', ')}` : 'The recipe includes all essential components'}

Example responses:
1. For incomplete recipe:
{
    "reason": "The recipe is incomplete because it lacks several essential components: flour quantity, baking temperature, and cooking time. These missing elements would make it difficult for someone to successfully recreate the dish."
}

2. For complete recipe:
{
    "reason": "The recipe is complete as it provides all necessary measurements, cooking times, and temperatures needed to successfully prepare the dish."
}

User input: ${input}

Recipe to analyze: ${output}

Return your response in this format:
{
    "reason": "The recipe is ${verdict} because [reason]"
}`;
```

## Creating the Judge

We can create a specialized judge that will evaluate recipe completeness. We can import the prompts defined above and use them in the judge:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/metricJudge.ts"
import { RECIPE_COMPLETENESS_INSTRUCTIONS, generateCompletenessPrompt, generateReasonPrompt } from './prompts';

export class RecipeCompletenessJudge extends MastraAgentJudge {
  constructor(model: LanguageModel) {
    super('Recipe Completeness', RECIPE_COMPLETENESS_INSTRUCTIONS, model);
  }

  async evaluate(
    input: string,
    output: string,
  ): Promise<{
    missing: string[];
    verdict: string;
  }> {
    const completenessPrompt = generateCompletenessPrompt({ input, output });
    const result = await this.agent.generate(completenessPrompt, {
      output: z.object({
        missing: z.array(z.string()),
        verdict: z.string(),
      }),
    });

    return result.object;
  }

  async getReason(args: { input: string; output: string; missing: string[]; verdict: string }): Promise<string> {
    const prompt = generateReasonPrompt(args);
    const result = await this.agent.generate(prompt, {
      output: z.object({
        reason: z.string(),
      }),
    });

    return result.object.reason;
  }
}
```

The judge class handles the core evaluation logic through two main methods:

- `evaluate()`: Analyzes recipe completeness and returns missing elements with verdict
- `getReason()`: Provides human-readable explanation for the evaluation results

## Creating the Metric

Create the metric class that uses the judge:

```typescript copy showLineNumbers filename="src/mastra/evals/recipe-completeness/index.ts"
export interface MetricResultWithInfo extends MetricResult {
  info: {
    reason: string;
    missing: string[];
  };
}

export class RecipeCompletenessMetric extends Metric {
  private judge: RecipeCompletenessJudge;
  private scale: number;

  constructor(model: LanguageModel, { scale = 1 }: RecipeCompletenessMetricOptions = {}) {
    super();
    this.judge = new RecipeCompletenessJudge(model);
    this.scale = scale;
  }

  async measure(input: string, output: string): Promise<MetricResultWithInfo> {
    const { verdict, missing } = await this.judge.evaluate(input, output);
    const score = this.calculateScore({ verdict });
    const reason = await this.judge.getReason({
      input,
      output,
      verdict,
      missing,
    });

    return {
      score,
      info: {
        missing,
        reason,
      },
    };
  }

  private calculateScore(verdict: { verdict: string }): number {
    return verdict.verdict.toLowerCase() === 'incomplete' ? 0 : 1;
  }
}
```

The metric class serves as the main interface for recipe evaluation with two key methods:

- `measure()`: Orchestrates the entire evaluation process and returns a comprehensive result
- `calculateScore()`: Converts the evaluation verdict to a binary score (1 for complete, 0 for incomplete)

## Setting Up the Agent

Create an agent and attach the metric:

```typescript copy showLineNumbers filename="src/mastra/agents/chefAgent.ts"
import { openai } from '@ai-sdk/openai';
import { Agent } from '@mastra/core/agent';

import { RecipeCompletenessMetric } from '../evals';

export const chefAgent = new Agent({
  name: 'chef-agent',
  instructions:
    'You are Michel, a practical and experienced home chef' +
    'You help people cook with whatever ingredients they have available.',
  model: openai('gpt-4o-mini'),
  evals: {
    recipeCompleteness: new RecipeCompletenessMetric(openai('gpt-4o-mini')),
  },
});
```

## Usage Example

Here's how to use the metric with an agent:

```typescript copy showLineNumbers filename="src/index.ts"
import { mastra } from './mastra';

const chefAgent = mastra.getAgent('chefAgent');
const metric = chefAgent.evals.recipeCompleteness;

// Example: Evaluate a recipe
const input = 'Can you give me a simple pasta recipe with exact measurements and timing?';
const response = await chefAgent.generate(input);
const result = await metric.measure(input, response.text);

console.log('Metric Result:', {
  score: result.score,
  missing: result.info.missing,
  reason: result.info.reason,
});

// Example Output:
// Metric Result: { score: 1, missing: [], reason: 'The recipe is complete as it provides all necessary measurements, cooking times, and temperatures needed to successfully prepare the dish.' }
```

## Understanding the Results

The metric provides:
- A score of 1 for complete recipes and 0 for incomplete ones
- List of missing essential components (if any)
- Detailed reasoning about the recipe's completeness
- Evaluation based on:
  - Ingredient quantities
  - Cooking times
  - Temperature specifications

<br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval"
  }
/>
