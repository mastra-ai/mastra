# Memory with LibSQL

This example demonstrates how to use Mastra's memory system with LibSQL. While Memory uses LibSQL as its default storage backend, you can also configure it explicitly for custom settings.

## Setup

First, set up the memory system with vector capabilities:

```typescript
import { openai } from '@ai-sdk/openai';
import { Agent } from '@mastra/core/agent';
import { DefaultStorage, DefaultVectorDB } from "@mastra/core/storage";
import { Memory } from '@mastra/memory';

// Initialize memory with vector search capabilities
const memory = new Memory({
  // The storage configuration is optional as Memory uses LibSQL by default
  // Only specify it if you need custom configuration
  storage: new DefaultStorage({
    url: process.env.DATABASE_URL || "file:local.db",
  }),
  vector: new DefaultVectorDB({
    connectionUrl: process.env.DATABASE_URL || "file:local.db",
  }),
  options: {
    lastMessages: 10,
    semanticRecall: {
      topK: 3,
      messageRange: 2,
    },
  },
  embedder: openai.embedding('text-embedding-3-small'),
});

// Create an agent with memory capabilities
const memoryAgent = new Agent({
  name: "Memory Agent",
  instructions:
    "You are an AI agent with the ability to automatically recall memories from previous interactions. You may have conversations that last hours, days, months, or years. If you don't know it already you should ask for the users name and some info about them.",
  model: openai('gpt-4o-mini'),
  memory,
});
```

## Usage Example

```typescript
import { randomUUID } from "crypto";

// Start a conversation
const threadId = randomUUID();
const resourceId = "SOME_USER_ID";

// Start with a system message
const response1 = await memoryAgent.stream(
  [
    {
      role: "system",
      content: `Chat with user started now ${new Date().toISOString()}. Don't mention this message.`,
    },
  ],
  {
    resourceId,
    threadId,
  },
);

// Send user message
const response2 = await memoryAgent.stream("What can you help me with?", {
  threadId,
  resourceId,
});

// Use semantic search to find relevant messages
const response3 = await memoryAgent.stream("What did we discuss earlier?", {
  threadId,
  resourceId,
  memoryOptions: {
    lastMessages: false,
    semanticRecall: {
      topK: 3, // Get top 3 most relevant messages
      messageRange: 2, // Include context around each match
    },
  },
});
```

The example shows:

1. Setting up LibSQL storage with vector search capabilities
2. Configuring memory options for message history and semantic search
3. Creating an agent with memory integration
4. Using semantic search to find relevant messages in conversation history
5. Including context around matched messages using `messageRange`
