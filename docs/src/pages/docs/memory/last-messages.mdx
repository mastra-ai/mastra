# Conversations and Turn-Based Interactions (Last Messages)

The most fundamental form of memory in Mastra is the ability to maintain conversation context through recent message history. This section covers how Mastra handles turn-based interactions using the "last messages" feature.

## Quick Start

Here's a minimal example of setting up an agent with last messages:

```typescript
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

// Create an agent with memory
const agent = new Agent({
  name: "ConversationAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory(), // Uses default setting of 40 most recent messages
});
```

## When to Use Last Messages

Last messages are the foundation of all memory functionality in Mastra. Even if you don't use more advanced memory features, implementing last messages alone provides essential conversational context for your agents.

This core feature enables agents to understand and respond to multi-turn conversations naturally. Without it, each message would be treated in isolation, forcing users to provide complete context with every interaction. With last messages enabled, your agents can follow conversation flow, understand references to previous statements, and maintain coherent discussions across multiple exchanges.

## How Last Messages Works

The "last messages" feature automatically captures and retrieves conversation history. Each time you call an agent with a `resourceId` and `threadId`, the memory system:

- Stores the current message automatically
- Retrieves recent messages from that thread (by default, the 40 most recent)
- Adds these messages to the agent's context window
- Enables the agent to respond with awareness of the conversation history
- Stores the agent's response and any tool calls for future context

As conversations grow longer, older messages drop out of the context window, maintaining a sliding window of recent context.

```text
                   ┌─────────────────────┐
                   │  New User Message   │
                   └─────────┬───────────┘
                             │
                             ▼
                   ┌─────────────────────┐
                   │  Agent with Memory  │
                   └─────────┬───────────┘
                             │ invokes
                             ▼
                ┌────────────────────────────┐
                │    Memory Last Messages    │
                │    Retrieval Function      │
                └────────────┬───────────────┘
                             │ queries
                             ▼
         ┌─────────────────────────────────────┐
         │       Thread Message Storage        │
         │  ───────────────────────────────    │
         │  Message 40 (oldest) - timestamp    │
         │  Message 39        - timestamp      │
         │  ...                                │
         │  Message 2         - timestamp      │
         │  Message 1 (newest) - timestamp     │
         └────────────────────┬────────────────┘
                              │ returns last 40 messages
                              ▼
           ┌───────────────────────────────┐
           │       Context Window          │
           │  ─────────────────────────    │
           │  System Instructions          │
           │  Last 40 Messages             │
           │  Current User Message         │
           └───────────────┬───────────────┘
                           │ sent to
                           ▼
                  ┌──────────────────┐
                  │    LLM Provider  │
                  └──────────────────┘
```

## Configuring Last Messages

You can set the number of last messages when creating your agent:

```typescript
// Specify a custom number of messages at agent creation
const agent = new Agent({
  name: "LimitedContextAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory({
    options: {
      lastMessages: 20, // Use 20 messages instead of default 40
    },
  }),
});
```

You can also override the setting for individual requests:

```typescript
// Change message count for a specific request
await agent.stream("Hello again", {
  resourceId: "user_123",
  threadId: "thread_456",
  memoryOptions: {
    lastMessages: 10, // Only use 10 messages for this specific request
  },
});
```

## Token Considerations

The message count directly impacts token usage and context window space. Different conversation types benefit from different settings:

**Recommended settings by conversation type:**

| Conversation Type   | Suggested Setting | Reasoning                                  |
| ------------------- | ----------------- | ------------------------------------------ |
| Simple Q&A          | 5-10 messages     | Short exchanges need minimal context       |
| Customer Service    | 15-20 messages    | Balance between history and token usage    |
| Complex Discussions | 30-40 messages    | Detailed context helps with complex topics |

**Note:** For one-off processing tasks like simple summarization, you can disable messages with `lastMessages: false`, though it's generally better to create an agent without memory for these cases.

For automatic token management, consider using the [Token Limiter memory processor](./token-management.mdx).

## Related Features

Last messages provide the foundation for conversational memory, but additional capabilities can complement this functionality:

- **[Similarity Search](./semantic-recall.mdx)**: Find relevant messages from anywhere in conversation history, not just recent messages
- **[Working Memory](./working-memory.mdx)**: Store persistent user information in a structured format
- **[Token Management](./token-management.mdx)**: Optimize token usage across different memory features
- **[Configuring Memory](./configuring-memory.mdx)**: Configure memory backends and settings

