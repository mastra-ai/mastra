# Building Chat UIs with Memory

Memory features are useful for creating conversational experiences in user interfaces. This section covers how to connect Mastra's memory system with frontend frameworks to build chat applications that maintain context across interactions.

## Quick Start

Before integrating memory into your frontend, ensure you have configured memory for your agent. See the [Getting Started](./getting-started.mdx) and [Configuring Memory](./configuring-memory.mdx) guides for setup details.

Here's a minimal example of integrating memory with a Next.js frontend using the AI SDK:

```typescript
// components/Chat.tsx
import { useChat } from "ai/react";

export function Chat({ threadId, resourceId }) {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat",
    // Pass just the latest message and custom IDs
    experimental_prepareRequestBody({ messages }) {
      return {
        message: messages.at(-1),
        threadId,
        resourceId
      };
    },
  });

  return (
    <div>
      <div>
        {messages.map((m) => (
          <div key={m.id}>{m.content}</div>
        ))}
      </div>
      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}

// app/api/chat/route.ts
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";

const agent = new Agent({
  name: "ChatAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory(),
});

export async function POST(request: Request) {
  // Get data from frontend
  const { message, threadId, resourceId } = await request.json();

  // Process with memory
  const stream = await agent.stream(message.content, {
    threadId,
    resourceId,
  });

  return stream.toDataStreamResponse();
}
```

## Common Integration Challenges

### Preventing Message Duplication

To prevent duplicate messages in memory, configure `useChat` to send only the latest message instead of the entire history:

```typescript
const { messages } = useChat({
  api: "/api/chat",
  experimental_prepareRequestBody({ messages }) {
    return {
      message: messages.at(-1),
      threadId: "thread_12345",
    };
  },
});
```

See the [AI SDK documentation on message persistence](https://sdk.vercel.ai/docs/ai-sdk-ui/chatbot-message-persistence) for more details.

### Svelte Example

**Important:** When using Svelte, you must extract only the most recent message on the server side to prevent duplicate messages in memory.

```typescript
// Svelte component
import { useChat } from "ai/svelte";

// In your component
const { messages, input, handleSubmit } = useChat({
  api: "/api/chat",
  body: {
    // Include the threadId and resourceId in every request
    threadId: "thread_12345",
    resourceId: "user_12345",
  },
});

// Server endpoint
export async function POST({ request }) {
  const { messages, threadId, resourceId } = await request.json();

  // IMPORTANT: Only use the most recent message to prevent duplicates
  const latestMessage = messages.at(-1);

  const stream = await agent.stream(latestMessage.content, {
    threadId,
    resourceId,
  });

  return new Response(stream.toDataStreamResponse());
}
```

For more on integrating with different frameworks, see our [AI SDK integration guide](/docs/frameworks/ai-sdk#usechat).

## Using Working Memory

When using working memory, configure it to use the tool-call mode to avoid working memory tags appearing in the UI:

```typescript
// Configure memory with tool-call mode
const memory = new Memory({
  options: {
    workingMemory: {
      enabled: true,
      use: "tool-call", // Prevents tags from appearing in the UI
    },
  },
});

// Create agent with this memory
const agent = new Agent({
  // Other configuration...
  memory: memory,
});
```

## Managing Threads

The `@mastra/client-js` package provides methods for managing memory threads directly from your frontend application. This is essential for building UIs where users can view, select, create, or delete their conversation histories.

### Using the Client Library

```typescript
import { MastraClient } from "@mastra/client-js";

// Initialize client
const client = new MastraClient({
  apiKey: process.env.MASTRA_API_KEY,
});

// Get all threads for a user (e.g., in a sidebar)
const threads = await client.getMemoryThreads({
  resourceId: "user_12345",
  agentId: "agent_12345", // Specify the agent context if needed
});

// Create a new thread when a user starts a new chat
const newThread = await client.createMemoryThread({
  title: "New Conversation", // Optional title
  metadata: { category: "support" }, // Optional metadata
  resourceId: "user_12345",
  agentId: "agent_12345",
});

// Get a specific thread instance to perform actions
const existingThread = client.getMemoryThread(newThread.id, "agent_12345");

// Delete a thread (e.g., user action)
await existingThread.delete();
```

For complete API details, refer to the [Client.js Memory API documentation](/docs/reference/client-js/memory).

### Building a Thread Management UI

You can use these client methods to build interfaces for users to manage their conversation threads:

```typescript
// Example React component for a thread list
import React, { useState, useEffect } from 'react';
import { MastraClient } from "@mastra/client-js";

function ThreadList({ userId, agentId, onSelectThread }) {
  const [threads, setThreads] = useState([]);
  // Ensure API key handling is secure and appropriate for frontend context
  const client = new MastraClient({ apiKey: process.env.NEXT_PUBLIC_MASTRA_API_KEY });

  useEffect(() => {
    async function loadThreads() {
      try {
        const userThreads = await client.getMemoryThreads({ resourceId: userId, agentId });
        setThreads(userThreads);
      } catch (error) {
        console.error("Failed to load threads:", error);
        // Handle error appropriately in UI
      }
    }
    if (userId && agentId) {
      loadThreads();
    }
  }, [userId, agentId, client]); // Added client to dependency array

  const handleCreateThread = async () => {
    try {
      const newThread = await client.createMemoryThread({ resourceId: userId, agentId });
      setThreads(prev => [...prev, newThread]);
      onSelectThread(newThread.id); // Switch to the new thread
    } catch (error) {
      console.error("Failed to create thread:", error);
      // Handle error appropriately in UI
    }
  };

  return (
    <div>
      <h2>Your Conversations</h2>
      <ul>
        {threads.map(thread => (
          <li key={thread.id}>
            <button onClick={() => onSelectThread(thread.id)}>
              {thread.title || `Conversation ${thread.id.substring(0, 8)}...`}
            </button>
            {/* Add delete button here */}
          </li>
        ))}
      </ul>
      <button onClick={handleCreateThread}>New Conversation</button>
    </div>
  );
}
```
This combined section now covers both the API interaction and the UI implementation aspects of thread management.

## Related Features

- **[Conversation History](./last-messages.mdx)**: For implementing recent conversation history in UIs
- **[Working Memory](./working-memory.mdx)**: For maintaining persistent user information
- **[Memory Threads](./memory-threads.mdx)**: For understanding thread management
- **[Client.js Memory API](/docs/reference/client-js/memory)**: For complete client-side memory management APIs
- **[Next.js Integration Guide](/docs/frameworks/next-js)**: For integrating Mastra into Next.js projects