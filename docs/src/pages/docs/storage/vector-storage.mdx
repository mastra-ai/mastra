---
title: Vector Storage | Mastra Docs
description: Guide on using vector storage in Mastra for efficient similarity search and embedding storage.
---

# Vector Storage

Mastra provides vector storage capabilities for semantic search and embedding management. This guide shows you how to use vector storage in your application.

## Overview

Mastra's vector storage system handles:

1. **Embeddings**: High-dimensional vector data
2. **Indexes**: Efficient similarity search structures
3. **Metadata**: Associated data for filtering and organization

Key features:
- Multiple database support
- Automatic index management
- Efficient similarity search
- Rich metadata filtering

## Quick Start

```ts showLineNumbers copy
import { LibSQLVector } from '@mastra/core/vector/libsql';

// Initialize vector storage
const store = new LibSQLVector({
  // Basic setup
  url: ':memory:',  // In-memory for development
  
  // Optional configuration
  config: {
    tableName: 'embeddings',
    batchSize: 1000,
  },
});

// Create an index
await store.createIndex({
  indexName: 'my-vectors',
  dimension: 1536,  // OpenAI text-embedding-3-small
});

// Store embeddings
await store.upsert({
  indexName: 'my-vectors',
  vectors: embeddings,
  metadata: chunks.map(chunk => ({
    text: chunk.text,
    source: chunk.source,
  })),
});

// Search similar vectors
const results = await store.search({
  indexName: 'my-vectors',
  vector: queryEmbedding,
  topK: 5,
});
```

## Storage Options

### 1. LibSQL (Default)

```ts showLineNumbers copy
// In-memory or file-based vector storage
const store = new LibSQLVector({
  url: ':memory:',  // or 'file:vectors.db'
  config: {
    tableName: 'embeddings',
    batchSize: 1000,
  },
});

// Features:
// - Zero-dependency setup
// - Automatic schema management
// - Transaction support
// - Local development
```

### 2. PostgreSQL
```ts showLineNumbers copy
import { PgVector } from '@mastra/pg';

// Production vector storage
const store = new PgVector({
  url: process.env.DATABASE_URL,
  pool: {
    min: 2,
    max: 10,
  },
  config: {
    // Index configuration
    indexType: 'hnsw',  // or 'ivfflat'
    m: 16,             // Max connections per node
    efConstruction: 100, // Build-time search depth
  },
});

// Features:
// - Production-grade storage
// - Advanced indexing
// - Cloud deployment
// - High availability
```

## Core Operations

### 1. Index Management
```ts showLineNumbers copy
// Create vector index
await store.createIndex({
  indexName: 'my-collection',
  dimension: 1536,  // text-embedding-3-small
  config: {
    metric: 'cosine',
    indexType: 'hnsw',
    m: 16,
    efConstruction: 100,
  },
});

// Delete index
await store.deleteIndex({
  indexName: 'my-collection',
});

// List indexes
const indexes = await store.listIndexes();
```

### 2. Vector Operations
```ts showLineNumbers copy
// Store vectors with metadata
await store.upsert({
  indexName: 'my-collection',
  vectors: embeddings,
  metadata: chunks.map(chunk => ({
    text: chunk.text,
    source: chunk.source,
    timestamp: new Date(),
  })),
});

// Search similar vectors
const results = await store.search({
  indexName: 'my-collection',
  vector: queryVector,
  topK: 5,
  filter: {
    source: 'documentation',
    timestamp: { $gt: new Date('2024-01-01') },
  },
});
```

### Storing Embeddings

Store embeddings with metadata:

```ts showLineNumbers copy
// Store embeddings with their metadata
await store.upsert({
  // Target index for storage
  indexName: 'my-collection',
  
  // Vector embeddings to store
  vectors: embeddings,  // Array of float32 arrays
  
  // Associated metadata for each vector
  metadata: chunks.map(chunk => ({
    // Original text for reconstruction
    text: chunk.text,       // Content that was embedded
    
    // Metadata for filtering and organization
    source: chunk.source,   // Where the text came from
    timestamp: new Date(),  // When it was embedded
    
    // Optional: Custom metadata for your use case
    category: chunk.category,
    language: chunk.language,
    version: chunk.version,
  })),
  
  // Optional: Performance settings
  batchSize: 1000,  // Vectors per batch
  onProgress: (progress) => {
    console.log(`Stored ${progress.completed}/${progress.total} vectors`);
  },
});

// The upsert operation:
// 1. Creates or updates vectors
// 2. Preserves all metadata
// 3. Maintains index consistency
// 4. Supports batch processing
```

### Similarity Search

Query vectors by similarity:

```ts showLineNumbers copy
// Search for similar vectors with filtering
const results = await store.search({
  // Target index to search
  indexName: 'my-collection',
  
  // Query vector (must match dimension)
  vector: queryEmbedding,  // float32 array
  
  // Number of results to return
  topK: 5,  // Returns 5 closest matches
  
  // Filter results by metadata
  filter: {
    // Simple equality filter
    source: 'documentation',
    
    // Advanced filtering
    timestamp: { 
      $gt: new Date('2024-01-01'),  // After date
    },
    category: { 
      $in: ['guide', 'tutorial'],    // Multiple values
    },
    language: 'en',                   // Exact match
  },
  
  // Optional: Search configuration
  config: {
    minScore: 0.8,    // Minimum similarity score
    efSearch: 100,     // Search depth (HNSW)
    nprobe: 10,        // Probes (IVF)
  },
});

// Results include:
// 1. Vector matches with scores
// 2. Associated metadata
// 3. Distance/similarity metrics
// 4. Original vector IDs
```

## Integration with Memory

### Default Configuration

Mastra's Memory system uses LibSQL vector storage by default:

```ts showLineNumbers copy
import { Memory } from '@mastra/core/memory';

// Initialize memory with vector storage
const memory = new Memory({
  // Uses built-in LibSQL vector storage
  options: {
    // Configure semantic search
    semanticRecall: {
      topK: 5,           // Number of similar messages
      messageRange: 2,   // Context window around matches
      
      // Advanced vector options
      vector: {
        dimension: 1536,   // Embedding dimension
        metric: 'cosine',  // Similarity metric
        minScore: 0.7,     // Minimum relevance
      },
      
      // Embedding configuration
      embedder: {
        model: 'bge-small-en-v1.5',  // Default model
        batchSize: 32,  // Embeddings per batch
      },
    },
  },
});

// This setup:
// 1. Creates vector tables
// 2. Initializes embedder
// 3. Configures similarity search
// 4. Sets up message retrieval
```

### Custom Vector Storage

Configure Memory with custom vector storage:

```ts showLineNumbers copy
import { Memory } from '@mastra/core/memory';
import { PgVector } from '@mastra/pg';

const memory = new Memory({
  vector: new PgVector(process.env.POSTGRES_URL),
  options: {
    semanticRecall: {
      topK: 5,
      messageRange: 2,
    },
  },
});
```

## Performance Optimization

### Index Configuration

Optimize index settings for your use case:

```ts showLineNumbers copy
await store.createIndex({
  indexName: 'my-collection',
  dimension: 1536,
  config: {
    // PostgreSQL specific
    indexType: 'ivfflat',
    lists: 100,
    probes: 10,
  },
});
```

### Batch Operations

Use batch operations for better performance:

```ts showLineNumbers copy
// Batch upsert
await store.upsert({
  indexName: 'my-collection',
  vectors: batchEmbeddings,
  metadata: batchMetadata,
  batchSize: 1000,
});

// Batch search
const results = await store.search({
  indexName: 'my-collection',
  vectors: batchQueryEmbeddings,
  topK: 5,
});
```

### Filtering

Use metadata filters to improve search efficiency:

```ts showLineNumbers copy
const results = await store.search({
  indexName: 'my-collection',
  vector: queryEmbedding,
  topK: 5,
  filter: {
    // Filter by metadata
    timestamp: { $gt: new Date('2024-01-01') },
    source: { $in: ['docs', 'chat'] },
    status: 'active',
  },
});
```

## Next Steps

- Learn about [Storage as Memory](./memory-storage.mdx)
- Configure [Storage Telemetry](./storage-telemetry.mdx)
- See [Vector Storage Examples](../../examples/vector-storage/)