---
title: "Reference: LLM.stream() | Streaming | LLM | Mastra Docs"
description: "Documentation for the `.stream()` method in LLM, which enables real-time streaming of responses."
---

# LLM.stream()

The `.stream()` method enables real-time streaming of responses from the language model. This method accepts `messages` and an optional `options` object as parameters, similar to `generate()`.

## Parameters

### `messages`

The `messages` parameter can be:

- A single string
- An array of strings  
- An array of message objects with `role` and `content` properties

#### Message Object Structure

```typescript
interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}
```

### `options` (Optional)

An optional object that can include:

<PropertiesTable
  content={[
    {
      name: 'output',
      type: 'string | JSONSchema7 | ZodSchema',
      isOptional: true,
      default: "'text'",
      description: 'Defines the output format. Can be "text" or a schema for structured output.',
    },
    {
      name: 'onFinish',
      type: '(result: string) => Promise<void> | void',
      isOptional: true,
      description: 'Callback function called when streaming is complete.',
    },
    {
      name: 'onStepFinish',
      type: '(step: string) => void',
      isOptional: true,
      description: 'Callback function called after each step during streaming.',
    },
    {
      name: 'maxSteps',
      type: 'number',
      isOptional: true,
      default: '5',
      description: 'Maximum number of steps allowed during streaming.',
    },
    {
      name: 'tools',
      type: 'ToolsInput',
      isOptional: true,
      description: 'Tools available for the LLM to use during streaming.',
    },
    {
      name: 'runId',
      type: 'string',
      isOptional: true,
      description: 'Unique identifier for the streaming run, useful for tracing and logging.',
    }
  ]}
/>

## Returns

The method returns a promise that resolves to an object containing one or more of the following properties:

<PropertiesTable
  content={[
    {
      name: 'textStream',
      type: 'AsyncIterable<string>',
      isOptional: true,
      description: 'An async iterable stream of text chunks. Present when output is "text".',
    },
    {
      name: 'objectStream',
      type: 'AsyncIterable<object>',
      isOptional: true,
      description: 'An async iterable stream of structured data. Present when a schema is provided.',
    },
    {
      name: 'object',
      type: 'Promise<object>',
      isOptional: true,
      description: 'A promise that resolves to the final structured output when using a schema.',
    }
  ]}
/>

## Examples

### Basic Text Streaming

```typescript
const stream = await llm.stream("Tell me a story about a brave knight.");

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### Structured Output Streaming

```typescript
const schema = {
  type: 'object',
  properties: {
    answer: { type: 'number' },
    explanation: { type: 'string' }
  },
  required: ['answer', 'explanation']
};

const response = await llm.stream("What is 2+2?", {
  output: schema,
  onFinish: text => console.log("Finished:", text)
});

for await (const chunk of response.textStream) {
  console.log(chunk);
}

const result = await response.object;
console.log("Final structured result:", result);
```