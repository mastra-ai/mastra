---
title: "Reference: TTS.stream() | Text to Speech (TTS) | Mastra Docs"
description: "Documentation for the `.stream()` method in TTS, which produces an audio response stream."
---

# TTS.stream()

The `stream()` method is used to interact with the TTS model to produce an audio response stream. This method accepts `text` and `voice` as parameters.

## Parameters


<PropertiesTable
  content={[
    {
      name: 'text',
      type: 'string',
      description: 'The messages to be processed by TTS.',
    },
    {
      name: 'voice',
      type: 'string',
      description: 'Voice ID to be used with generation.',
    },
  ]}
/>

## Returns

<PropertiesTable
  content={[
    {
      name: 'audioResult',
      type: 'Readable',
      isOptional: true,
      description: 'The generated audio stream',
    },
  ]}
/>

## Examples

### ElevenLabs Streaming

```typescript
import { ElevenLabsTTS } from '@mastra/tts'

 const tts = new ElevenLabsTTS({
    model: {
      name: 'eleven_multilingual_v2',
      apiKey: process.env.ELEVENLABS_API_KEY!,
    },
  });

const voices = await tts.voices();
const voiceId = voices?.[0]?.voice_id!;

const { audioResult } = await tts.stream({ text: "What is AI?", voice: voiceId });

// Create a write stream to simulate real-time playback
const outputPath = path.join(process.cwd(), '/test-outputs/streaming-output.mp3');
const writeStream = createWriteStream(outputPath);

let firstChunkTime: number | null = null;
let lastChunkTime: number | null = null;
let totalChunks = 0;

// Process chunks as they arrive
for await (const chunk of audioResult) {
    if (!firstChunkTime) {
    firstChunkTime = Date.now();
    }
    lastChunkTime = Date.now();
    totalChunks++;

    // Write chunk immediately as it arrives
    writeStream.write(chunk);

    // Log timing of chunk arrival
    console.log(`Received chunk ${totalChunks} at ${lastChunkTime - firstChunkTime!}ms`);
}

writeStream.end()
```

### OpenAI Streaming

```typescript
import { OpenAITTS } from '@mastra/tts'

 const tts = new OpenAITTS({
    model: {
      name: 'tts-1',
      apiKey: process.env.OPENAI_API_KEY!,
    },
  });

const voices = await tts.voices();
const voiceId = voices?.[0]?.voice_id!;

const { audioResult } = await tts.stream({ text: "What is AI?", voice: voiceId });

// Create a write stream to simulate real-time playback
const outputPath = path.join(process.cwd(), '/test-outputs/streaming-output.mp3');
const writeStream = createWriteStream(outputPath);

let firstChunkTime: number | null = null;
let lastChunkTime: number | null = null;
let totalChunks = 0;

// Process chunks as they arrive
for await (const chunk of audioResult) {
    if (!firstChunkTime) {
    firstChunkTime = Date.now();
    }
    lastChunkTime = Date.now();
    totalChunks++;

    // Write chunk immediately as it arrives
    writeStream.write(chunk);

    // Log timing of chunk arrival
    console.log(`Received chunk ${totalChunks} at ${lastChunkTime - firstChunkTime!}ms`);
}

writeStream.end()
```

### PlayAI Streaming

```typescript
import { PlayAITTS } from '@mastra/tts'

 const tts = new PlayAITTS({
    model: {
      name: 'PlayDialog',
      apiKey: process.env.PLAYAI_API_KEY!,
    },
    userId: process.env.PLAYAI_USER_ID!,
  });

const voices = await tts.voices();
const voiceId = voices?.[0]?.voice_id!;

const { audioResult } = await tts.stream({ text: "What is AI?", voice: voiceId });

// Create a write stream to simulate real-time playback
const outputPath = path.join(process.cwd(), '/test-outputs/streaming-output.mp3');
const writeStream = createWriteStream(outputPath);

let firstChunkTime: number | null = null;
let lastChunkTime: number | null = null;
let totalChunks = 0;

// Process chunks as they arrive
for await (const chunk of audioResult) {
    if (!firstChunkTime) {
    firstChunkTime = Date.now();
    }
    lastChunkTime = Date.now();
    totalChunks++;

    // Write chunk immediately as it arrives
    writeStream.write(chunk);

    // Log timing of chunk arrival
    console.log(`Received chunk ${totalChunks} at ${lastChunkTime - firstChunkTime!}ms`);
}

writeStream.end()
```

### Azure Streaming

```typescript
import { AzureTTS } from '@mastra/tts'

const tts = new AzureTTS({
  model: {
    name: 'en-US-JennyNeural',
    apiKey: process.env.AZURE_API_KEY,
    region: process.env.AZURE_REGION,
  },
});

const { audioResult } = await tts.stream({ text: "What is AI?" });

// Create a write stream
const outputPath = path.join(process.cwd(), '/test-outputs/azure-stream.mp3');
const writeStream = createWriteStream(outputPath);

// Pipe the audio stream to the file
audioResult.pipe(writeStream);
```

### Deepgram Streaming

```typescript
import { DeepgramTTS } from '@mastra/tts'

const tts = new DeepgramTTS({
  model: {
    name: 'aura',
    voice: 'asteria-en',
    apiKey: process.env.DEEPGRAM_API_KEY,
  },
});

const { audioResult } = await tts.stream({ text: "What is AI?" });

// Create a write stream
const outputPath = path.join(process.cwd(), '/test-outputs/deepgram-stream.mp3');
const writeStream = createWriteStream(outputPath);

// Pipe the audio stream to the file
audioResult.pipe(writeStream);
```

### Google Streaming

```typescript
import { GoogleTTS } from '@mastra/tts'

const tts = new GoogleTTS({
  model: {
    name: 'en-US-Standard-A',
    credentials: process.env.GOOGLE_CREDENTIALS,
  },
});

const { audioResult } = await tts.stream({ text: "What is AI?" });

// Create a write stream
const outputPath = path.join(process.cwd(), '/test-outputs/google-stream.mp3');
const writeStream = createWriteStream(outputPath);

// Pipe the audio stream to the file
audioResult.pipe(writeStream);
```

### IBM Streaming

```typescript
import { IbmTTS } from '@mastra/tts'

const tts = new IbmTTS({
  model: {
    voice: 'en-US_AllisonV3Voice',
    apiKey: process.env.IBM_API_KEY,
  },
});

const { audioResult } = await tts.stream({ text: "What is AI?" });

// Create a write stream
const outputPath = path.join(process.cwd(), '/test-outputs/ibm-stream.mp3');
const writeStream = createWriteStream(outputPath);

// Pipe the audio stream to the file
audioResult.pipe(writeStream);
```

### Murf Streaming

```typescript
import { MurfTTS } from '@mastra/tts'

const tts = new MurfTTS({
  model: {
    name: 'GEN2',
    voice: 'en-US-natalie',
    apiKey: process.env.MURF_API_KEY,
  },
});

const { audioResult } = await tts.stream({ text: "What is AI?" });

// Create a write stream
const outputPath = path.join(process.cwd(), '/test-outputs/murf-stream.mp3');
const writeStream = createWriteStream(outputPath);

// Pipe the audio stream to the file
audioResult.pipe(writeStream);
```