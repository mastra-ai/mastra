---
title: "Storing Embeddings in A Vector Database | Mastra Docs"
description: Guide on vector storage options in Mastra, including embedded and dedicated vector databases for similarity search.
---

## Storing Embeddings in A Vector Database

After generating embeddings, you need to store them in a database that supports vector similarity search. Mastra provides flexible options for vector storage, supporting both embedded and dedicated vector databases.

## Choosing a Vector Database

When selecting a vector database, consider:

- **Infrastructure:** Do you want to use your existing PostgreSQL database (with PgVector) or a dedicated vector database (Pinecone, Qdrant)?
- **Scale**: How many vectors will you store and query? Dedicated solutions like Pinecone often handle larger scales better.
- **Query Performance**: Need sub-second queries over millions of vectors? Consider specialized databases like Qdrant.
- **Management**: Are you comfortable managing another database, or prefer using your existing PostgreSQL setup? 

## Supported databases

### PostgreSQL with PgVector 

Best for teams already using PostgreSQL who want to minimize infrastructure complexity: 

``` ts showLineNumbers copy

import { PgVector } from '@mastra/vector-pg';

const pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING);

// Create an index (dimension = 1536 for text-embedding-ada-002)
await pgVector.createIndex("embeddings", 1536);

// Store embeddings with metadata
await pgVector.upsert(
  "embeddings",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
``` 

### Pinecone

Ideal for production deployments needing scalability: 


``` ts showLineNumbers copy

import { PineconeVector } from '@mastra/vector-pinecone';

const pinecone = new PineconeVector(process.env.PINECONE_API_KEY);

// Create an index
await pinecone.createIndex("my-index", 1536);

// Store embeddings
await pinecone.upsert(
  "my-index",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### Qdrant

Best for high-performance vector search: 

``` ts showLineNumbers copy

import { QdrantVector } from '@mastra/vector-qdrant';

const qdrant = new QdrantVector({
  url: process.env.QDRANT_URL,
  apiKey: process.env.QDRANT_API_KEY
});

// Create collection
await qdrant.createIndex("my-collection", 1536);

// Store embeddings
await qdrant.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### Chroma

``` ts showLineNumbers copy

import { ChromaVector } from '@mastra/vector-chroma';

const chroma = new ChromaVector();

// Create collection
await chroma.createIndex("my-collection", 1536);

// Store embeddings
await chroma.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### Astra DB

``` ts showLineNumbers copy

import { AstraVector } from '@mastra/vector-astra';

const astra = new AstraVector({
  token: process.env.ASTRA_DB_TOKEN,
  endpoint: process.env.ASTRA_DB_ENDPOINT,
  keyspace: process.env.ASTRA_DB_KEYSPACE,
});

// Create collection
await astra.createIndex("my-collection", 1536);

// Store embeddings
await astra.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### LibSQL

``` ts showLineNumbers copy

import { LibSQLVector } from '@mastra/vector-libsql';

const libsql = new LibSQLVector(process.env.DATABASE_URL);

// Create collection
await libsql.createIndex("my-collection", 1536);

// Store embeddings
await libsql.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### Upstash

``` ts showLineNumbers copy

import { UpstashVector } from '@mastra/vector-upstash';

const upstash = new UpstashVector({
  url: process.env.UPSTASH_URL,
  token: process.env.UPSTASH_TOKEN,
});

// Create collection
await upstash.createIndex("my-collection", 1536);

// Store embeddings
await upstash.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

### Cloudflare Vectorize

``` ts showLineNumbers copy

import { CloudflareVector } from '@mastra/vector-vectorize';

const vectorize = new CloudflareVector({
  accountId: process.env.CF_ACCOUNT_ID,
  apiToken: process.env.CF_API_TOKEN,
});

// Create collection
await vectorize.createIndex("my-collection", 1536);

// Store embeddings
await vectorize.upsert(
  "my-collection",
  embeddings,
  chunks.map(chunk => ({ text: chunk.text }))
);
```

## Adding Metadata

All vector stores support adding metadata to your vectors, which enables filtering during retrieval:

``` ts showLineNumbers copy
// Store embeddings with rich metadata
await vectorStore.upsert(
  "embeddings",
  embeddings,
  chunks.map(chunk => ({
    text: chunk.text,
    source: chunk.source,
    category: chunk.category,
    timestamp: new Date().toISOString()
  }))
);
```

## Performance Considerations

- **Indexing:** Create appropriate indexes before bulk insertions 
- **Batch Size:** Use batch operations for large insertions
- **Metadata:** Only store metadata you'll query against
- **Dimensions:** Match embedding dimensions to your model (eg., 1536 for `text-embedding-ada-002`)

## Examples
For complete examples of different vector store implementations, see:

- [Insert Embedding in PgVector](../../examples/rag/insert-embedding-in-pgvector.mdx)
- [Insert Embedding in Pinecone](../../examples/rag/insert-embedding-in-pinecone.mdx)
- [Insert Embedding in Qdrant](../../examples/rag/insert-embedding-in-qdrant.mdx)
- [Insert Embedding in Chroma](../../examples/rag/insert-embedding-in-chroma.mdx)
- [Insert Embedding in Astra DB](../../examples/rag/insert-embedding-in-astra.mdx)
- [Insert Embedding in LibSQL](../../examples/rag/insert-embedding-in-libsql.mdx)
- [Insert Embedding in Upstash](../../examples/rag/insert-embedding-in-upstash.mdx)
- [Insert Embedding in Cloudflare Vectorize](../../examples/rag/insert-embedding-in-vectorize.mdx)
- [Basic RAG with Vector Storage](../../examples/rag/basic-rag.mdx)
