## Chunking and Embedding Documents

Before processing, create a `MDocument` instance from your content. You can initialize it from text, HTML, Markdown, or JSON:

```ts
const docFromText = MDocument.fromText("Your plain text content...");

const docFromHTML = MDocument.fromHTML("<html>Your HTML content...</html>");

const docFromMarkdown = MDocument.fromMarkdown("# Your Markdown content...");

const docFromJSON = MDocument.fromJSON(`{ "key": "value" }`);
```

Each method returns a `MDocument` ready for processing.

## Step 1: Document Processing

Use `chunk` to split the document into manageable pieces. Mastra supports seven chunking strategies (`recursive`, `character`, `token`, `markdown`, `html`, `json`, and `latex`), each optimized for different document types and with configurable options for chunk size and overlap.

You can also enable metadata extraction, which uses LLM calls behind the scenes to provide titles, summaries, keywords, and potential Q&A pairs.

**Example:**

```ts showLineNumbers copy
import { MDocument } from "@mastra/rag";
const doc = MDocument.fromText("Your plain text content...");

const chunks = doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
});
```

This splits the document into chunks and extracts metadata. There are a variety of chunking strategies and options, which we go into in the [chunk documentation](/docs/reference/rag/chunk.mdx). Metadata is preserved in the chunks, which you can use for retrieval.

**Note:** Metadata extraction may use LLM calls behind the scenes, so ensure `OPENAI_API_KEY` is set.

## Step 2: Embedding

Transform chunks into embeddings using an embedding model:

```ts showLineNumbers copy
import { embed } from "@mastra/rag";

const embeddings = await embed(chunks, {
  provider: "OPEN_AI",
  model: "text-embedding-ada-002",
});

// Embed a single chunk if needed:
const singleEmbedding = await embed(chunks[0], {
  provider: "OPEN_AI",
  model: "text-embedding-ada-002",
});
```

Embeddings are arrays of numbers representing the semantic meaning of the text. They enable similarity searches in a vector database.
