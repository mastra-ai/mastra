import { Callout, Steps, Tabs } from "nextra/components";

# Installation

To run Mastra, you need access to an LLM. Typically, you'll want to get an API key from an LLM provider such as [OpenAI](https://platform.openai.com/), [Anthropic](https://console.anthropic.com/settings/keys), or [Google Gemini](https://ai.google.dev/gemini-api/docs). You can also run Mastra with a local LLM using [Ollama](https://ollama.ai/).

## Prerequisites

- Node.js `v20.0` or higher
- Access to a [supported large language model (LLM)](/guide/reference/llm/providers-and-models.mdx).

## Automatic Installation

<Steps>

### Create a New Project

We recommend starting a new Mastra project using `create-mastra`, which will scaffold your project. To create
a project, run:

<Tabs items={["npx", "npm", "yarn", "pnpm"]}>
  <Tabs.Tab>
  
```bash copy 
npx create-mastra@latest
```

  </Tabs.Tab>
  <Tabs.Tab>
```bash copy 
npm create mastra
```
  </Tabs.Tab>
  <Tabs.Tab>
```bash copy 
yarn create mastra
```
</Tabs.Tab>
  <Tabs.Tab>
```bash copy 
pnpm create mastra
```
</Tabs.Tab>
</Tabs>

On installation, you'll be guided through the following prompts:

```bash
What do you want to name your project? my-mastra-app
Choose components to install:
  ◯ Agents (recommended)
  ◯ Tools
  ◯ Workflows
Select default provider:
  ◯ OpenAI (recommended)
  ◯ Anthropic
  ◯ Groq
Would you like to include example code? No / Yes
```

After the prompts, `create-mastra` will set up your project directory with TypeScript, install dependencies, and configure your selected components and LLM provider.

### Set Up your API Key

Add the API key for your configured LLM provider in your `.env` file.

```env
OPENAI_API_KEY=<your-openai-key>
```

</Steps>
Note: If you prefer to run the command with flags (non-interactive mode) and include the example code, you can use:
```bash copy
npx create-mastra@latest --components agents,tools --llm openai --example
```
This allows you to specify your preferences upfront without being prompted.

## Manual Installation

<br/>
<Steps>

If you prefer to set up your Mastra project manually, follow these steps:

### Create a New Project

Create a project directory and navigate into it:

```bash copy
mkdir hello-mastra
cd hello-mastra
```

Then, initialize a TypeScript project including the `@mastra/core` package:

```bash copy npm2yarn
npm init -y
npm install typescript tsx @types/node zod --save-dev
npm install @mastra/core@alpha
npx tsc --init
```

### Set Up your API Key

Create a `.env` file in your project root directory and add your API key:

```env
OPENAI_API_KEY=<your-openai-key>
```

Replace your_openai_api_key with your actual API key.

### Create an Agent

First, create a `cat-one` agent file:

```bash copy
touch src/mastra/agents/cat-one.ts
```

Then, add the following code to `src/mastra/agents/cat-one.ts`:

```ts filename="src/mastra/agents/cat-one.ts" showLineNumbers
import { Agent } from "@mastra/core";

export const catOne = new Agent({
  name: "cat-one",
  model: {
    provider: "OPEN_AI",
    name: "gpt-4o",
    toolChoice: "auto",
  },
  instructions: `You are a feline expert with comprehensive knowledge of all cat species, from domestic breeds to wild big cats. As a lifelong cat specialist, you understand their behavior, biology, social structures, and evolutionary history in great depth.`,
  tools: {},
});
```

### Register Agent

Finally, create the Mastra entry point in `src/mastra/index.ts` and register agent:

```ts filename="src/mastra/index.ts" showLineNumbers
import { Mastra } from "@mastra/core";
import { catOne } from "./agents/cat-one";

export const mastra = new Mastra({
  agents: { catOne },
});
```

This registers your agent with Mastra so that `mastra dev` can discover and serve it.

</Steps>

## Add to Existing Project

<Steps>

### Install the CLI

If you have an existing project and want to add Mastra, first install the mastra CLI.

<Tabs items={["npm", "yarn", "pnpm"]}>
  <Tabs.Tab>

```bash copy
npm i -g mastra
```

  </Tabs.Tab>
  <Tabs.Tab>
```bash copy 
yarn i -g mastra
```
</Tabs.Tab>
  <Tabs.Tab>
```bash copy 
pnpm i -g mastra
```
</Tabs.Tab>
</Tabs>

### Initialize Mastra

To then intialize mastra in your project by following out interactive setup, run:

```bash copy
mastra init
```

### Set Up your API Key

Add the API key for your configured LLM provider in your `.env` file.

```env
OPENAI_API_KEY=<your-openai-key>
```

</Steps>
Note: If you prefer to run the command with flags (non-interactive mode) and include the example code, you can use:
```bash copy
mastra init --dir src/mastra --components agents,tools --llm openai --example
```
This allows you to specify your preferences upfront without being prompted.

## Start the Mastra Server

Mastra provides commands to serve your agents via REST endpoints

### Development Server

Run the following command to start the Mastra server:

```bash copy
npx mastra dev
```

If you have the mastra CLI installed globally, run:

```bash copy
mastra dev
```

This command creates REST API endpoints for your agents.

### Test the Endpoint

You can test the agent's endpoint using `curl` or `fetch`:

<Tabs items={['curl', 'fetch']}>
  <Tabs.Tab>
```bash copy
curl -X POST http://localhost:4111/api/agents/catOne/generate \
-H "Content-Type: application/json" \
-d '{"messages": ["What do cats like to eat?"]}'
```
  </Tabs.Tab>
  <Tabs.Tab>
```js copy showLineNumbers
fetch('http://localhost:4111/api/agents/catOne/generate', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    messages: ['What do cats like to eat?'],
  }),
})
  .then(response => response.json())
  .then(data => {
    console.log('Agent response:', data.text);
  })
  .catch(error => {
    console.error('Error:', error);
  });
```
  </Tabs.Tab>
</Tabs>

## Run from the command line

If you'd like to directly call agents from the command line, you can create a script to get an agent and call it:

```ts filename="src/index.ts" showLineNumbers
import { mastra } from "./mastra";

async function main() {
  const agent = mastra.getAgent("catOne");

  const result = await agent.generate("What do cats like to eat?");

  console.log("Agent response:", result.text);
}

main();
```

Then, run the script to test that everything is set up correctly:

```bash copy
npx bun src/index.ts
```

This should output the agent's response to your console.

---
