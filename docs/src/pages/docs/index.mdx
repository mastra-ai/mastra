---
title: "Introduction | Mastra Docs"
description: "Mastra is an opinionated Typescript framework that helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals."
---

# Introduction

Mastra is an opinionated Typescript framework that helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations and evals. You can run Mastra on your local machine, or deploy to a serverless cloud.

The main Mastra features are:

| Features                                         | Description                                                                                                                       |
| ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------- |
| [LLM Models](/docs/llm-models/00-overview.mdx)   | Mastra supports a variety of LLM providers, including OpenAI, Anthropic, Google Gemini.                                           |
| [Agents](/docs/agents/00-overview.mdx)           | Agents are systems where the language model chooses a sequence of actions.                                                        |
| [Tools](/docs/agents/02-adding-tools.mdx)        | Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. |
| [Workflows](/docs/workflows/00-overview.mdx)     | Workflows are durable graph-based state machines with built-in tracing. They can execute complex sequences of LLM operations.     |
| [RAG](/docs/rag/overview.mdx)                    | Retrieval-augemented generation (RAG) lets you construct a knowledge base for your agents.                                        |
| [Integrations](/docs/local-dev/integrations.mdx) | In Mastra, integrations are auto-generated, type-safe API clients for third-party services.                                       |
| [Evals](/docs/08-running-evals)                  | Evals are automated tests that evaluate LLM outputs using model-graded, rule-based, and statistical methods.                      |
