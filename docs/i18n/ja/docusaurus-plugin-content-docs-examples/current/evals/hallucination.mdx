---
title: "例: 幻覚評価 | Evals | Mastra ドキュメント"
description: 応答内の事実矛盾を評価するために「Hallucination」指標を用いる例。
---

<div id="hallucination-evaluation">
  # 幻覚評価
</div>

:::note
Scorers API は現在ベータ版です。改善に積極的に取り組んでおり、皆さまのフィードバックを歓迎します。ご質問や機能リクエストは [Discord](https://discord.gg/mastra) までお寄せください。
:::

`HallucinationMetric` を使用して、応答が提供されたコンテキストのいずれかの部分と矛盾していないかを評価します。このメトリックは `query` と `response` を受け取り、スコアと理由を含む `info` オブジェクトを返します。

<div id="installation">
  ## インストール
</div>

```bash copy
npm install @mastra/evals
```


<div id="no-hallucination-example">
  ## 幻覚なしの例
</div>

この例では、回答は提供された文脈と完全に整合しています。すべての主張は事実に即して正しく、元資料によって直接裏付けられているため、幻覚スコアは低くなります。

```typescript title="src/example-no-hallucination.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { HallucinationMetric } from "@mastra/evals/llm";

const metric = new HallucinationMetric(openai("gpt-4o-mini"), {
  context: [
    "iPhoneは2007年に初めて発売されました。",
    "Steve JobsがMacworldで発表しました。",
    "初代モデルは3.5インチのスクリーンを搭載していました。",
  ],
});

const query = "初代iPhoneはいつ発売されましたか?";
const response =
  "iPhoneは2007年に初めて発売され、Steve JobsがMacworldで発表しました。初代iPhoneは3.5インチのスクリーンを搭載していました。";

const result = await metric.measure(query, response);

console.log(result);
```


<div id="no-hallucination-output">
  ### 幻覚のない出力
</div>

矛盾がないため、応答のスコアは0になります。すべての記述は文脈と整合しており、新たな情報や捏造された情報は含まれていません。

```typescript
{
  score: 0,
  info: {
    reason: 'スコアが0なのは、コンテキスト内のいずれの記述も出力によって矛盾しなかったためです。'
  }
}
```


<div id="mixed-hallucination-example">
  ## 混合型ハルシネーションの例
</div>

この例では、応答には正確な主張と不正確な主張が混在しています。いくつかの詳細は文脈に合致している一方で、数値の水増しや誤った場所の記載など、文脈と明確に矛盾するものもあります。これらの矛盾により、ハルシネーションスコアが上昇します。

```typescript title="src/example-mixed-hallucination.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { HallucinationMetric } from "@mastra/evals/llm";

const metric = new HallucinationMetric(openai("gpt-4o-mini"), {
  context: [
    "最初のスター・ウォーズ映画は1977年に公開されました。",
    "ジョージ・ルーカスが監督しました。",
    "この映画は世界中で7億7500万ドルを稼ぎました。",
    "この映画はチュニジアとイングランドで撮影されました。",
  ],
});

const query = "最初のスター・ウォーズ映画について教えてください。";
const response =
  "最初のスター・ウォーズ映画は1977年に公開され、ジョージ・ルーカスが監督しました。興行収入は10億ドル以上を記録し、完全にカリフォルニアで撮影されました。";

const result = await metric.measure(query, response);

console.log(result);
```


<div id="mixed-hallucination-output">
  ### 混在したハルシネーション出力
</div>

この評価指標は、応答の一部が文脈と矛盾しているため、中程度のスコアを付与します。いくつかの事実は正しい一方で、他は不正確または捏造であり、全体としての信頼性を損ないます。

```typescript
{
  score: 0.5,
  info: {
    reason: 'スコアが0.5なのは、出力中の4件の記述のうち2件がコンテキスト内の主張と矛盾しており、正確な情報と不正確な情報が拮抗していることを示しているためです。'
  }
}
```


<div id="complete-hallucination-example">
  ## 典型的なハルシネーションの例
</div>

この例では、応答が文脈中のあらゆる重要な事実と矛盾しています。いずれの主張も検証できず、提示された詳細はすべて事実と異なります。

```typescript title="src/example-complete-hallucination.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { HallucinationMetric } from "@mastra/evals/llm";

const metric = new HallucinationMetric(openai("gpt-4o-mini"), {
  context: [
    "ライト兄弟は1903年に初飛行を行った。",
    "飛行時間は12秒だった。",
    "飛行距離は120フィートだった。",
  ],
});

const query = "ライト兄弟が初めて飛行したのはいつですか?";
const response =
  "ライト兄弟は1908年に歴史的な初飛行を達成した。飛行時間は約2分で、距離はほぼ1マイルだった。";

const result = await metric.measure(query, response);

console.log(result);
```


<div id="complete-hallucination-output">
  ### 完全な幻覚出力
</div>

この指標はスコアを1とします。レスポンス内のすべての記述がコンテキストと矛盾しているためです。詳細は全般的に捏造されているか、不正確です。

```typescript
{
  score: 1,
  info: {
    reason: 'スコアが1.0なのは、出力中の3つの記述がいずれも文脈と真っ向から矛盾しているためです。最初の飛行は1908年ではなく1903年、所要時間は約2分ではなく12秒、移動距離は1マイル近くではなく120フィートでした。'
  }
}
```


<div id="metric-configuration">
  ## メトリクスの構成
</div>

事実に基づくソース資料を表す `context` 配列を指定して、`HallucinationMetric` インスタンスを作成できます。最大スコアを設定するための `scale` など、任意のパラメータを追加で構成することもできます。

```typescript
const metric = new HallucinationMetric(openai("gpt-4o-mini"), {
  context: [""],
  scale: 1,
});
```

> 設定オプションの一覧については、[HallucinationMetric](/reference/evals/hallucination)を参照してください。


<div id="understanding-the-results">
  ## 結果の理解
</div>

`HallucinationMetric` は以下の形式で結果を返します：

```typescript
{
  score: number,
  info: {
    reason: 文字列
  }
}
```


<div id="hallucination-score">
  ### 幻覚スコア
</div>

0〜1の範囲の幻覚スコア:

- **0.0**: 幻覚なし — すべての主張が文脈と一致。
- **0.3–0.4**: 低度の幻覚 — いくつか矛盾がある。
- **0.5–0.6**: 中程度の幻覚 — 複数の矛盾がある。
- **0.7–0.8**: 高度の幻覚 — 多くの矛盾がある。
- **0.9–1.0**: 完全な幻覚 — ほとんど、またはすべての主張が文脈と矛盾する。

<div id="hallucination-info">
  ### 幻覚（Hallucination）情報
</div>

スコアの説明。内容には次が含まれます:

- どの記述が文脈と整合しているか／矛盾しているか
- 矛盾の深刻度と発生頻度
- 事実からの乖離の程度
- 応答の総合的な正確性と信頼性

<GithubLink
  outdated={true}
  marginTop="mt-16"
  link="https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination"
/>