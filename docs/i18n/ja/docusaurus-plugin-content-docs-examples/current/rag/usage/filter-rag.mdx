---
title: "例：エージェント駆動のメタデータフィルタリング | RAG | Mastra ドキュメント"
description: RAG システムで Mastra のエージェントを用いて、ドキュメント検索向けのメタデータフィルタを構築・適用する例。
---

import GithubLink from "@site/src/components/GithubLink";


# エージェント主導のメタデータフィルタリング

この例では、Mastra、OpenAI の埋め込み表現、そしてベクトルストレージとしての PGVector を用いて、Retrieval-Augmented Generation（RAG）システムを実装する方法を示します。
このシステムでは、エージェントがユーザーのクエリからメタデータフィルタを生成し、ベクトルストア内で関連するチャンクを検索することで、返却される結果を絞り込みます。

## 概要

このシステムは、Mastra と OpenAI を用いてメタデータのフィルタリングを実装しています。主な処理は次のとおりです:

1. クエリの意図を理解しフィルタ要件を特定するため、gpt-4o-mini を用いた Mastra エージェントをセットアップする
2. メタデータのフィルタリングとセマンティック検索に対応するベクトルクエリツールを作成する
3. ドキュメントをメタデータと埋め込み付きのチャンクに分割・処理する
4. 効率的な検索のために、ベクトルとメタデータを PGVector に保存する
5. メタデータフィルタとセマンティック検索を組み合わせてクエリを処理する

ユーザーが質問したとき:

- エージェントがクエリを分析して意図を把握する
- 適切なメタデータフィルタ（例: トピック、日付、カテゴリ）を構築する
- ベクトルクエリツールを用いて最も関連性の高い情報を見つける
- フィルタ後の結果に基づいて文脈に沿った応答を生成する

## セットアップ

### 環境のセットアップ

環境変数が設定されていることを確認してください：

```bash title=".env"
OPENAI_API_KEY=your_openai_api_key_here
POSTGRES_CONNECTION_STRING=your_connection_string_here
```


### 依存関係

次に、必要な依存関係をインポートします。

```typescript copy showLineNumbers title="index.ts"
import { openai } from "@ai-sdk/openai";
import { Mastra } from "@mastra/core";
import { Agent } from "@mastra/core/agent";
import { PgVector, PGVECTOR_PROMPT } from "@mastra/pg";
import { createVectorQueryTool, MDocument } from "@mastra/rag";
import { embedMany } from "ai";
```


## ベクタークエリツールの作成

@mastra/rag からインポートした createVectorQueryTool を使うと、メタデータのフィルタリングに対応したツールを作成できます。各ベクターストアには、サポートされるフィルター演算子と構文を定義する固有のプロンプトがあります。

```typescript copy showLineNumbers{9} title="index.ts"
const vectorQueryTool = createVectorQueryTool({
  id: "vectorQueryTool",
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
  enableFilter: true,
});
```

各プロンプトには次が含まれます:

* 対応している演算子（比較、配列、論理、要素）
* 各演算子の使用例
* ストア固有の制約とルール
* 複雑なクエリの例


## ドキュメント処理

ドキュメントを作成し、メタデータ付きのチャンクに分割して処理します：

```typescript copy showLineNumbers{17} title="index.ts"
const doc = MDocument.fromText(
  `気候変動が世界の農業に与える影響...`,
);

const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
  extract: {
    keywords: true, // 各チャンクからキーワードを抽出します
  },
});
```


### チャンクをメタデータに変換する

フィルタ可能なメタデータにチャンクを変換します：

```typescript copy showLineNumbers{31} title="index.ts"
const chunkMetadata = chunks?.map((chunk: any, index: number) => ({
  text: chunk.text,
  ...chunk.metadata,
  nested: {
    keywords: chunk.metadata.excerptKeywords
      .replace("KEYWORDS:", "")
      .split(",")
      .map((k) => k.trim()),
    id: index,
  },
}));
```


## エージェントの構成

エージェントは、ユーザーのクエリを理解し、適切なメタデータフィルターに変換できるよう構成されています。

エージェントには、ベクタークエリツールと、次を含むシステムプロンプトの両方が必要です：

* 利用可能なフィルターフィールドのメタデータ構造
* フィルター操作と構文に関するベクターストア用のプロンプト

```typescript copy showLineNumbers{43} title="index.ts"
export const ragAgent = new Agent({
  name: "RAG Agent",
  model: openai("gpt-4o-mini"),
  instructions: `
  あなたは提供されたコンテキストに基づいて質問に答える有用なアシスタントです。回答は簡潔かつ関連性の高いものにしてください。

  メタデータを検索してコンテキストをフィルタリングしてください。
  
  メタデータは以下のように構造化されています:

  {
    text: string,
    excerptKeywords: string,
    nested: {
      keywords: string[],
      id: number,
    },
  }

  ${PGVECTOR_PROMPT}

  重要: 質問に答えるよう求められた場合は、ツールで提供されたコンテキストのみに基づいて回答してください。
  コンテキストに質問へ完全に答えるための十分な情報が含まれていない場合は、その旨を明示的に述べてください。
  `,
  tools: { vectorQueryTool },
});
```

エージェントの指示は次のことを目的としています:

* ユーザーのクエリを処理してフィルター要件を特定する
* メタデータ構造を用いて関連情報を見つける
* vectorQueryTool と提供されたベクターストア用プロンプトを使って適切なフィルターを適用する
* フィルター済みのコンテキストに基づいて応答を生成する

> 注: ベクターストアごとに固有のプロンプトが用意されています。詳しくは [Vector Store Prompts](/docs/rag/retrieval#vector-store-prompts) を参照してください。


## PgVector と Mastra を初期化する

次のコンポーネントを使って PgVector と Mastra を初期化します:

```typescript copy showLineNumbers{69} title="index.ts"
const pgVector = new PgVector({
  connectionString: process.env.POSTGRES_CONNECTION_STRING!,
});

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector },
});
const agent = mastra.getAgent("ragAgent");
```


## 埋め込みの作成と保存

埋め込みを生成し、メタデータとともに保存します:

```typescript copy showLineNumbers{78} title="index.ts"
const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});

// 埋め込みとメタデータを一緒に保存
await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunkMetadata,
});
```

`upsert` 操作は、ベクトル埋め込みと関連するメタデータの両方を保存し、セマンティック検索とメタデータによるフィルタリングを組み合わせた検索を可能にします。


## メタデータベースのクエリ

メタデータのフィルターを使って、さまざまなクエリを試してみましょう：

```typescript copy showLineNumbers{96} title="index.ts"
const queryOne = "言及されている適応戦略は何ですか?";
const answerOne = await agent.generate(queryOne);
console.log("\nQuery:", queryOne);
console.log("Response:", answerOne.text);

const queryTwo =
  '最近のセクションを表示してください。"nested.id"フィールドを確認し、2より大きい値を返してください。';
const answerTwo = await agent.generate(queryTwo);
console.log("\nQuery:", queryTwo);
console.log("Response:", answerTwo.text);

const queryThree =
  '正規表現演算子を使用して"text"フィールドを検索し、"temperature"を含むセクションを見つけてください。';
const answerThree = await agent.generate(queryThree);
console.log("\nQuery:", queryThree);
console.log("Response:", answerThree.text);
```

<br />

<br />

<hr className="dark:border-[#404040] border-gray-300" />

<br />

<br />

<GithubLink
  link={
"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag"
}
/>
