---
title: "リファレンス: createVectorQueryTool() | Tools & MCP | Mastra ドキュメント"
description: フィルタリングやリランキング機能を備え、ベクターストアに対するセマンティック検索を容易にする Mastra の Vector Query Tool のドキュメント。
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";


<div id="createvectorquerytool">
  # createVectorQueryTool()
</div>

`createVectorQueryTool()` 関数は、ベクターストアに対するセマンティック検索用のツールを作成します。フィルタ、リランキング、データベース固有の設定に対応し、さまざまなベクターストアのバックエンドと統合できます。

<div id="basic-usage">
  ## 基本的な使い方
</div>

```typescript
import { openai } from "@ai-sdk/openai";
import { createVectorQueryTool } from "@mastra/rag";

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```


<div id="parameters">
  ## パラメーター
</div>

:::note

**パラメーター要件:** ほとんどのフィールドは作成時にデフォルトとして設定できます。
一部のフィールドはランタイムのコンテキストまたは入力で上書きできます。作成時と実行時の両方で必須フィールドが欠けている場合はエラーが発生します。なお、`model`、`id`、`description` は作成時にのみ設定できます。

:::

<PropertiesTable
  content={[
    {
      name: "id",
      type: "string",
      description:
        "ツールのカスタム ID。デフォルト: 'VectorQuery {vectorStoreName} {indexName} Tool'。（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "description",
      type: "string",
      description:
        "ツールのカスタム説明。デフォルト: 'Access the knowledge base to find information needed to answer user questions'（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "model",
      type: "EmbeddingModel",
      description:
        "ベクトル検索に使用する埋め込みモデル。（作成時のみ設定可能）",
      isOptional: false,
    },
    {
      name: "vectorStoreName",
      type: "string",
      description:
        "クエリ対象のベクトルストア名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "indexName",
      type: "string",
      description:
        "ベクトルストア内のインデックス名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "enableFilter",
      type: "boolean",
      description:
        "メタデータに基づく結果のフィルタリングを有効にします。（作成時のみ設定可能。ただし、実行時コンテキストでフィルタが指定された場合は自動的に有効化されます）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeVectors",
      type: "boolean",
      description:
        "結果に埋め込みベクトルを含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeSources",
      type: "boolean",
      description:
        "結果に取得オブジェクト全体を含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "true",
    },
    {
      name: "reranker",
      type: "RerankConfig",
      description:
        "結果の再ランク付けに関するオプション。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "databaseConfig",
      type: "DatabaseConfig",
      description:
        "クエリ最適化のためのデータベース固有の設定オプション。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "providerOptions",
      type: "Record<string, Record<string, any>>",
      description:
        "埋め込みモデル向けのプロバイダー固有オプション（例: outputDimensionality）。**重要**: AI SDK の EmbeddingModelV2 にのみ対応します。V1 モデルでは、モデル作成時にオプションを設定してください。",
      isOptional: true,
    },
  ]}
/>

<div id="databaseconfig">
  ### DatabaseConfig
</div>

`DatabaseConfig` 型では、クエリ操作に自動適用されるデータベース固有の設定を指定できます。これにより、各種ベクターストアが提供する独自の機能や最適化を活用できます。

<PropertiesTable
  content={[
    {
      name: "pinecone",
      type: "PineconeConfig",
      description: "Pinecone ベクターストア向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "namespace",
              description: "ベクターを整理するための Pinecone の namespace",
              isOptional: true,
              type: "string",
            },
            {
              name: "sparseVector",
              description: "ハイブリッド検索用のスパースベクター",
              isOptional: true,
              type: "{ indices: number[]; values: number[]; }",
            },
          ],
        },
      ],
    },
    {
      name: "pgvector",
      type: "PgVectorConfig",
      description:
        "pgvector 拡張機能を用いた PostgreSQL 向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "minScore",
              description: "結果の類似度スコアの下限しきい値",
              isOptional: true,
              type: "number",
            },
            {
              name: "ef",
              description:
                "HNSW の検索パラメータ — 精度と速度のトレードオフを制御",
              isOptional: true,
              type: "number",
            },
            {
              name: "probes",
              description:
                "IVFFlat の probe パラメータ — 検索時に走査するセル数",
              isOptional: true,
              type: "number",
            },
          ],
        },
      ],
    },
    {
      name: "chroma",
      type: "ChromaConfig",
      description: "Chroma ベクターストア向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "where",
              description: "メタデータのフィルタリング条件",
              isOptional: true,
              type: "Record<string, any>",
            },
            {
              name: "whereDocument",
              description: "ドキュメント内容のフィルタリング条件",
              isOptional: true,
              type: "Record<string, any>",
            },
          ],
        },
      ],
    },
  ]}
/>

<div id="rerankconfig">
  ### RerankConfig
</div>

<PropertiesTable
  content={[
    {
      name: "model",
      type: "MastraLanguageModel",
      description: "リランキングに使用する言語モデル",
      isOptional: false,
    },
    {
      name: "options",
      type: "RerankerOptions",
      description: "リランキング処理のオプション",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "weights",
              description:
                "スコアリング要素の重み（semantic: 0.4、vector: 0.4、position: 0.2）",
              isOptional: true,
              type: "WeightConfig",
            },
            {
              name: "topK",
              description: "返却する上位結果数",
              isOptional: true,
              type: "number",
              defaultValue: "3",
            },
          ],
        },
      ],
    },
  ]}
/>

<div id="returns">
  ## 返り値
</div>

このツールは、次のプロパティを持つオブジェクトを返します:

<PropertiesTable
  content={[
    {
      name: "relevantContext",
      type: "string",
      description: "最も関連性の高いドキュメントのチャンクから結合したテキスト",
    },
    {
      name: "sources",
      type: "QueryResult[]",
      description:
        "取得結果（リトリーバル）オブジェクトの完全版の配列。各オブジェクトには、元のドキュメント、チャンク、類似度スコアを参照するために必要な情報がすべて含まれます。",
    },
  ]}
/>

<div id="queryresult-object-structure">
  ### QueryResult オブジェクトの構成
</div>

```typescript
{
  id: string;         // 一意のチャンク／ドキュメント識別子
  metadata: any;      // すべてのメタデータフィールド（ドキュメントID など）
  vector: number[];   // 埋め込みベクトル（利用可能な場合）
  score: number;      // この取得における類似度スコア
  document: string;   // チャンク／ドキュメントの全文（利用可能な場合）
}
```


<div id="default-tool-description">
  ## 既定のツールの説明
</div>

既定の説明は次の点に重点を置いています：

- 蓄積された知識から関連情報を見つけること
- ユーザーの質問に回答すること
- 事実ベースの内容を取得すること

<div id="result-handling">
  ## 結果の処理
</div>

このツールはユーザーのクエリに応じて返す結果数を決定し、既定では10件を返します。必要に応じてクエリの要件に合わせて調整できます。

<div id="example-with-filters">
  ## フィルターを使った例
</div>

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  enableFilter: true,
});
```

フィルタリングが有効な場合、ツールはクエリを処理して、セマンティック検索と組み合わせて使用するメタデータフィルターを構築します。処理の流れは次のとおりです。

1. ユーザーが「&#39;version&#39; フィールドが 2.0 より大きいコンテンツを見つけて」といった特定のフィルター要件を含むクエリを送信します
2. エージェントがクエリを解析し、適切なフィルターを構築します:
   ```typescript
   {
      "version": { "$gt": 2.0 }
   }
   ```

このエージェント駆動のアプローチでは、次のことを行います:

* 自然言語のクエリをフィルター仕様に変換
* ベクトルストア固有のフィルター構文を実装
* クエリの用語をフィルター演算子に変換

フィルター構文の詳細やストア固有の機能については、[Metadata Filters](../rag/metadata-filters) ドキュメントを参照してください。

エージェント駆動のフィルタリングの動作例については、[Agent-Driven Metadata Filtering](/examples/rag/usage/filter-rag) を参照してください。


<div id="example-with-reranking">
  ## リランクの例
</div>

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "milvus",
  indexName: "documentation",
  model: openai.embedding("text-embedding-3-small"),
  reranker: {
    model: openai("gpt-4o-mini"),
    options: {
      weights: {
        semantic: 0.5, // セマンティック関連性の重み
        vector: 0.3, // ベクトル類似度の重み
        position: 0.2, // 元の位置の重み
      },
      topK: 5,
    },
  },
});
```

リランキングは次の要素を組み合わせて結果の品質を高めます:

* セマンティック関連性: LLM によるテキスト類似度のスコアリング
* ベクトル類似度: 元のベクトル距離スコア
* ポジションバイアス: 元の結果の並び順を考慮
* クエリ分析: クエリ特性に基づく調整

リランカーは初回のベクトル検索結果を処理し、関連性を最適化した並べ替え済みのリストを返します。


<div id="example-with-custom-description">
  ## カスタム説明の例
</div>

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  description:
    "会社の方針や手順に関する質問に答えるため、文書アーカイブを検索して関連情報を見つける",
});
```

この例では、情報検索という本来の目的を保ちながら、特定のユースケースに合わせてツールの説明をカスタマイズする方法を示します。


<div id="database-specific-configuration-examples">
  ## データベース別の設定例
</div>

`databaseConfig` パラメータを使うと、各ベクターデータベース固有の機能や最適化を活用できます。これらの設定はクエリ実行時に自動適用されます。

<Tabs>
  <TabItem value="pinecone" label="Pinecone">
    ### Pinecone の設定

    ```typescript
    const pineconeQueryTool = createVectorQueryTool({
      vectorStoreName: "pinecone",
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "production",  // 環境ごとにベクターを整理
          sparseVector: {           // ハイブリッド検索を有効化
            indices: [0, 1, 2, 3],
            values: [0.1, 0.2, 0.15, 0.05]
          }
        }
      }
    });
    ```

    **Pinecone の特長:**
    - **Namespace**: 同一インデックス内でデータセットを分離
    - **Sparse Vector**: 密・疎の埋め込みを組み合わせて検索品質を向上
    - **ユースケース**: マルチテナントアプリケーション、ハイブリッドセマンティック検索

  </TabItem>

  <TabItem value="pgvector" label="pgVector">
    ### pgVector の設定

    ```typescript
    const pgVectorQueryTool = createVectorQueryTool({
      vectorStoreName: "postgres",
      indexName: "embeddings",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pgvector: {
          minScore: 0.7,    // 類似度 70% 以上の結果のみ返す
          ef: 200,          // 値が高いほど精度は向上、検索は遅くなる
          probes: 10        // IVFFlat 用: probes を増やすほど再現率が向上
        }
      }
    });
    ```

    **pgVector の特長:**
    - **minScore**: 低品質なマッチを除外
    - **ef (HNSW)**: HNSW インデックスの精度と速度のバランスを調整
    - **probes (IVFFlat)**: IVFFlat インデックスの再現率と速度のバランスを調整
    - **ユースケース**: パフォーマンスチューニング、品質フィルタリング

  </TabItem>

  <TabItem value="chroma" label="Chroma">
    ### Chroma の設定

    ```typescript
    const chromaQueryTool = createVectorQueryTool({
      vectorStoreName: "chroma",
      indexName: "documents",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        chroma: {
          where: {                    // メタデータによるフィルタリング
            "category": "technical",
            "status": "published"
          },
          whereDocument: {            // ドキュメント内容によるフィルタリング
            "$contains": "API"
          }
        }
      }
    });
    ```

    **Chroma の特長:**
    - **where**: メタデータフィールドでフィルタ
    - **whereDocument**: ドキュメント内容でフィルタ
    - **ユースケース**: 高度なフィルタリング、内容ベース検索

  </TabItem>

  <TabItem value="multiple-configs" label="Multiple Configs">
    ### 複数データベースの設定

    ```typescript
    // 複数のデータベースを設定（動的なストアに便利）
    const multiDbQueryTool = createVectorQueryTool({
      vectorStoreName: "dynamic-store", // 実行時に設定される
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "default"
        },
        pgvector: {
          minScore: 0.8,
          ef: 150
        },
        chroma: {
          where: { "type": "documentation" }
        }
      }
    });
    ```

    **マルチ設定の利点:**
    - 1 つのツールで複数のベクターストアをサポート
    - データベース固有の最適化を自動適用
    - 柔軟なデプロイシナリオに対応

  </TabItem>
</Tabs>

<div id="runtime-configuration-override">
  ### 実行時の構成オーバーライド
</div>

さまざまなシナリオに対応するため、実行時にデータベース構成を上書きできます。

```typescript
import { RuntimeContext } from "@mastra/core/runtime-context";

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    pinecone: {
      namespace: "development",
    },
  },
});

// 実行時にオーバーライド
const runtimeContext = new RuntimeContext();
runtimeContext.set("databaseConfig", {
  pinecone: {
    namespace: "production", // 本番環境の名前空間に切り替え
  },
});

const response = await agent.generate("デプロイに関する情報を検索", {
  runtimeContext,
});
```

このアプローチにより、次のことが可能になります。

* 環境（dev/staging/prod）の切り替え
* 負荷に応じたパフォーマンスパラメーターの調整
* リクエスト単位での異なるフィルタリング戦略の適用


<div id="example-using-runtime-context">
  ## 例：ランタイムコンテキストの利用
</div>

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```

ランタイムコンテキストを使用する場合、必要なパラメータは実行時にランタイムコンテキスト経由で指定してください。

```typescript
const runtimeContext = new RuntimeContext<{
  vectorStoreName: string;
  indexName: string;
  topK: number;
  filter: VectorFilter;
  databaseConfig: DatabaseConfig;
}>();
runtimeContext.set("vectorStoreName", "my-store");
runtimeContext.set("indexName", "my-index");
runtimeContext.set("topK", 5);
runtimeContext.set("filter", { category: "docs" });
runtimeContext.set("databaseConfig", {
  pinecone: { namespace: "runtime-namespace" },
});
runtimeContext.set("model", openai.embedding("text-embedding-3-small"));

const response = await agent.generate(
  "ナレッジベースからドキュメントを検索してください。",
  {
    runtimeContext,
  },
);
```

ランタイムコンテキストの詳細については、以下をご覧ください。

* [Agent Runtime Context](/docs/server-db/runtime-context)
* [Tool Runtime Context](/docs/tools-mcp/overview#using-runtimecontext)


<div id="usage-without-a-mastra-server">
  ## Mastra サーバーなしでの利用
</div>

このツールは、クエリに一致するドキュメントを取得するために単体で利用できます。

```typescript copy showLineNumbers title="src/index.ts"
import { openai } from "@ai-sdk/openai";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { createVectorQueryTool } from "@mastra/rag";
import { PgVector } from "@mastra/pg";

const pgVector = new PgVector({
  connectionString: process.env.POSTGRES_CONNECTION_STRING!,
});

const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector", // ストアを渡しているため省略可能
  vectorStore: pgVector,
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
});

const runtimeContext = new RuntimeContext();
const queryResult = await vectorQueryTool.execute({
  context: { queryText: "foo", topK: 1 },
  runtimeContext,
});

console.log(queryResult.sources);
```


<div id="tool-details">
  ## ツールの詳細
</div>

このツールは次のように作成されます：

- **ID**: `VectorQuery {vectorStoreName} {indexName} Tool`
- **入力スキーマ**: queryText と filter のオブジェクトが必要
- **出力スキーマ**: relevantContext の文字列を返す

<div id="related">
  ## 関連項目
</div>

- [rerank()](../rag/rerank)
- [createGraphRAGTool](./graph-rag-tool)