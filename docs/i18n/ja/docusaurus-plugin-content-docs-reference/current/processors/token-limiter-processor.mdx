---
title: "リファレンス: TokenLimiterProcessor | プロセッサ | Mastra ドキュメント"
description: "Mastra の TokenLimiterProcessor に関するドキュメント。AI 応答のトークン数を制限します。"
---

<div id="tokenlimiterprocessor">
  # TokenLimiterProcessor
</div>

`TokenLimiterProcessor` は、AI の応答に含まれるトークン数を制限する**出力プロセッサ**です。トークンのカウントを行い、上限超過時の扱い（切り詰めや中止など）を設定できるため、レスポンスの長さを制御できます。ストリーミング／非ストリーミングのいずれのシナリオにも対応します。

<div id="usage-example">
  ## 使い方の例
</div>

```typescript copy
import { TokenLimiterProcessor } from "@mastra/core/processors";

const processor = new TokenLimiterProcessor({
  limit: 1000,
  strategy: "truncate",
  countMode: "cumulative",
});
```


<div id="constructor-parameters">
  ## コンストラクターの引数
</div>

<PropertiesTable
  content={[
    {
      name: "options",
      type: "number | Options",
      description:
        "トークン上限を指定する単純な数値、または設定オプションのオブジェクト",
      isOptional: false,
    },
  ]}
/>

<div id="options">
  ### オプション
</div>

<PropertiesTable
  content={[
    {
      name: "limit",
      type: "number",
      description: "レスポンスで許容するトークンの最大数",
      isOptional: false,
    },
    {
      name: "encoding",
      type: "TiktokenBPE",
      description:
        "使用するエンコーディング（省略可）。デフォルトは gpt-4o によって使用される o200k_base",
      isOptional: true,
      default: "o200k_base",
    },
    {
      name: "strategy",
      type: "'truncate' | 'abort'",
      description:
        "トークン上限到達時の動作: 'truncate' はチャンクの出力を止め、'abort' は abort() を呼び出してストリームを停止する",
      isOptional: true,
      default: "'truncate'",
    },
    {
      name: "countMode",
      type: "'cumulative' | 'part'",
      description:
        "ストリームの先頭からカウントするか、現在の部分のみをカウントするか: 'cumulative' は開始時点からの全トークンを、'part' は現在の部分のトークンのみをカウントする",
      isOptional: true,
      default: "'cumulative'",
    },
  ]}
/>

<div id="returns">
  ## 戻り値
</div>

<PropertiesTable
  content={[
    {
      name: "name",
      type: "string",
      description: "プロセッサ名は 'token-limiter' に設定されています",
      isOptional: false,
    },
    {
      name: "processOutputStream",
      type: "(args: { part: ChunkType; streamParts: ChunkType[]; state: Record<string, any>; abort: (reason?: string) => never }) => Promise<ChunkType | null>",
      description:
        "ストリーミング中の出力パーツを処理し、トークン数を制限します",
      isOptional: false,
    },
    {
      name: "processOutputResult",
      type: "(args: { messages: MastraMessageV2[]; abort: (reason?: string) => never }) => Promise<MastraMessageV2[]>",
      description:
        "非ストリーミング時の最終出力結果を処理し、トークン数を制限します",
      isOptional: false,
    },
    {
      name: "reset",
      type: "() => void",
      description:
        "トークンカウンタをリセットします（テストやプロセッサの再利用に便利）",
      isOptional: false,
    },
    {
      name: "getCurrentTokens",
      type: "() => number",
      description: "現在のトークン数を取得します",
      isOptional: false,
    },
    {
      name: "getMaxTokens",
      type: "() => number",
      description: "最大トークン数（上限）を取得します",
      isOptional: false,
    },
  ]}
/>

<div id="extended-usage-example">
  ## 拡張された使用例
</div>

```typescript title="src/mastra/agents/limited-agent.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { TokenLimiterProcessor } from "@mastra/core/processors";

export const agent = new Agent({
  name: "limited-agent",
  instructions: "あなたは親切なアシスタントです",
  model: openai("gpt-4o-mini"),
  outputProcessors: [
    new TokenLimiterProcessor({
      limit: 1000,
      strategy: "truncate",
      countMode: "cumulative",
    }),
  ],
});
```


<div id="related">
  ## 関連
</div>

- [入力プロセッサ](/docs/agents/guardrails)
- [出力プロセッサ](/docs/agents/guardrails)