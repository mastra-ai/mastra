---
title: "リファレンス: voice.answer() | Voice | Mastra ドキュメント"
description: "リアルタイム音声プロバイダーで利用可能な answer() メソッドのドキュメント。音声プロバイダーに応答生成を指示するメソッドです。"
---

<div id="voiceanswer">
  # voice.answer()
</div>

`answer()` メソッドは、リアルタイム音声プロバイダーで AI に応答生成を指示するために使用します。特に、ユーザー入力を受け取ったあとに AI に明示的な応答を促す必要がある音声同士の会話で有用です。

<div id="usage-example">
  ## 使い方の例
</div>

```typescript
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { getMicrophoneStream } from "@mastra/node-audio";
import Speaker from "@mastra/node-speaker";

const speaker = new Speaker({
  sampleRate: 24100, // オーディオのサンプルレート（Hz）— MacBook Proでの高音質の標準
  channels: 1, // モノラル出力（ステレオなら2）
  bitDepth: 16, // 音質用のビット深度 — CD品質の標準（16ビット解像度）
});

// リアルタイム音声プロバイダを初期化
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-4o",
    apiKey: process.env.OPENAI_API_KEY,
  },
  speaker: "alloy", // 既定のボイス
});
// リアルタイムサービスに接続
await voice.connect();
// 応答用のイベントリスナーを登録
voice.on("speaker", (stream) => {
  // 音声応答を処理
  stream.pipe(speaker);
});
// ユーザーの音声入力を送信
const microphoneStream = getMicrophoneStream();
await voice.send(microphoneStream);
// AIに応答を指示
await voice.answer();
```


<div id="parameters">
  ## パラメータ
</div>

<br />

<PropertiesTable
  content={[
    {
      name: "options",
      type: "Record<string, unknown>",
      description: "レスポンスに対するプロバイダ固有のオプション",
      isOptional: true,
    },
  ]}
/>

<div id="return-value">
  ## 戻り値
</div>

レスポンスがトリガーされると解決される `Promise<void>` を返します。

<div id="notes">
  ## 注意事項
</div>

- このメソッドは、音声同士のやり取り（speech-to-speech）に対応したリアルタイム音声プロバイダーでのみ実装されています
- この機能をサポートしない音声プロバイダーで呼び出すと、警告をログに出力し、即座に処理を終了します
- 応答音声は通常、直接返されるのではなく「speaking」イベントとして出力されます
- 対応プロバイダーでは、AI に生成させる代わりに特定の応答をこのメソッドで送信できます
- このメソッドは、会話の流れを構築するために `send()` と併用されるのが一般的です